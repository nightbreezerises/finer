Namespace(config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/flower102_all.yml', alpha=0.7, N_tta=10, num_per_category='3', num_runs=10)
Number of GPUs: 1
Device ID: 0 Device Name: NVIDIA RTX A6000
['Artichoke Flower', 'White Camellia', 'Lotus Flower', 'Pink Purple Gradient Flower', 'Grapefruit-sized Purple Flower', 'Rhombus Petal Flower', 'Poinsettia', 'Rosette Blue Flower', 'White-Purple Center Flower', 'Purple Floret Circle', 'Intense Red Varietal', 'Zantedeschia', 'Rosette Leaved Ball Flower', 'Yellow Ringed Flower', 'Yellow-centered Daisy', 'Ruffled Petal Fern Flower', 'Lotus with Yellow Stamens', 'Ruffled Sunflower', 'Yellow-flowered Asteraceae', 'Zigzag Stem Flower', 'Purple-White Iris', 'Red Hibiscus', 'Asymmetrical Rosette Flower', 'White-yellow center flower', 'Thistle Flower', 'Intense Yellow Petal Flower', 'Gladiolus', 'Medium-sized Daylily', 'Small Petal Ring', 'White-Centered Red Poppy', 'Asymmetrical Daisy', 'Small Yellow Petal Flower', 'Dandelion-like Yellow Flower', 'Spiral Arranged Carnation', 'Blue Bud Flower', 'White and Purple Ring Lily', 'Fern-leaf Petal Blossom', 'Orange Gladiolus', 'Fern Leaf', 'Ruffled Edge Purple Flower', 'Small Daisy', 'Five-petaled Pink Daisy', 'Oblong Petal Bud', 'Yellow Drooping Flower', 'Calla Lily', 'White Ringflower', 'Ruffled Peony Orchid', 'Zigzag Stem Plant', 'Single Asymmetrical Yellow Flower', 'Corn Poppy', 'Pelargonium', 'Rosette Crocus', 'Single leaf white flower', 'Sunset iris', 'Intensely Colored Ruffled Flower', 'Spring Crocus', 'Red Centered Oblong Petal Flower', 'Yellow Striped Daisy', 'Lily-sized Blue Flower', 'Water Lily', 'Symmetrical Oblong Petal Flower', 'Large white flower with yellow center', 'White-Stamen Lily', 'Pink gerbera', 'Graded Yellow-Red Rosette', 'Intense Petals', 'Fernlike Rosette Flower', 'Asymmetrical Pink Flower', 'White Poppy with Yellow Center', 'Small Purple Center Flower', 'Aquilegia', 'Small Purple Petal Flower', 'Asymmetrical Clematis', 'White-Yellow Center Flower', 'Yellow-Orange Garden Flower', 'Symmetrical Petal Flower', 'Iris sabdariffa', 'Rosette Yellow Flower', 'White Orchid', 'Red and white amaryllis', 'Yellow Hibiscus', 'Hibiscus-like Flower', 'Bee-attracting flower', 'Small Purple Lily', 'Red Ruffle Daisy', 'Yellow and Orange Iris', 'Daisy', 'Carnation', 'Small Blue-Purple Flower', 'Yellow-Orange Trumpet Flower', 'Zigzag Petal Foxglove', 'Pink Rosette Flower', 'Ruffled Petal Rhododendron', 'Striped Carnation', 'Yellow Heart-shaped Flower', 'Asymmetrical Purple Flower', 'White Starflower', 'Orange and Yellow Flower', 'Yellow-Centered Violet', 'Asymmetrical Five-Petaled Flower', 'Thorny Purple Flower', 'Asymmetrical Lily Amaryllis', 'Red Rosette', 'Pink Daisy', 'Fern-like Crocus', 'Small circular arranged flower', 'Intense Purple Crocus', 'Purple Petal Star', 'Ringed Center Pink Flower', 'Pink and White Flower', 'White-centered Lily', 'Rosette Fern Orchid', 'Orchidaceae', 'Ruffled Daisy', 'Ruffled Pink Flower', 'Intensely Colored Daisy', 'Small White Flower with Yellow Center', 'Wild Primrose', 'Yellow flower', 'Oblong-Leafed Blue Lily', 'Blue Ringflower', 'Sword Lily', 'Small White Flower', 'Red and Yellow Ringflower', 'Thistle flower', 'Wavy Fern Flower', 'White-Yellow Woodland Blossom', 'Orange Ruffled Petal Flower', 'Pink Tulip', 'Rosette Blue Petal', 'Asymmetrical Oblong Flower', 'Ringed White Center Flower', 'Meadow Crocus', 'White-Ringed Tulip', 'Yellow-orange iris', 'Purple Passion Flower', 'Large Pink-Edged Flower', 'Small Green Leaf Flower', 'Intense Color Flower', 'White Centered Pink Flower', 'Intense Red Petal Flower', 'Pink Orchid', 'Intensely Colored Symmetrical Flower', 'Intense Red Petals', 'Small Bud Flower', 'Ruffled Petal Lily', 'Intense Orange Center Daisy', 'Rosette Petal', 'Camellia', 'Tulip', 'Pink Ringed Flower', 'Red Dahlia', 'Spotted Daffodil', 'Pink Gradient Petal Flower', 'Echinacea', 'Ruffled Petal Red Flower', 'Small Fernlike Blossom', 'Wavy Margined Purple Lily', 'Drooping Yellow Center Flower', 'Rosette Petal Flower', 'Yellow Centered Pink Daisy', 'White Carnation', 'Green Centered Hellebore', 'Asymmetrical Petal Flower', 'Yellow Tulip', 'Morning Glory', 'Red and Yellow Lily', 'Orange Dahlia', 'Small Round Orange Flower', 'Fern-Like Pink', 'Ruffled petal flower', 'Medium-sized Asymmetrical Orchid', 'Zigzag Rosette', 'Fern-leafed Pink Flower', 'Purple Crocus', 'Tiger Lily', 'Yellow Centered Symmetrical', 'Rosette Cluster Blossom', 'Crocus', 'Bellis Perennis', 'Smooth-leaved Bellflower', 'Woodsy Rosette Flower', 'Yellow Spider Flower', 'Intense Bluebud', 'Red Flower', 'Yellow Center Orchid', 'Small Oblong Flower', 'Cymbidium', 'Large Petal Magnolia', 'Ruffled Petal Rosette Plant', 'Rosette Orchid', 'Symmetrical Petal Rosette', 'Pink and White Rosette Flower', 'Fern-like Stamen Flower', 'White-Centered Red', 'Large Oblong Petal Flower', 'Red and White Bud Flower', 'Rosette Fern-like Amaryllis', 'White-Centered Pink', 'Gradient Purple Flower', 'White and pink gradient flower', 'Rosette Leaf Daisy', 'Ruffled petal white flower with yellow center', 'White Rosette Flower', 'Intensely Colored Gradient Flower', 'Pink water lily', 'Blue Starflower', 'Yellow-Red Daffodil', 'Pink Daylily', 'Purple Rosette Flower with White Center', 'Circle Petal Daisy', 'Pink-centered Cluster Flower', 'Small Purple and White Flower', 'Yellow Iris', 'Sunflower, Helianthus annuus, Daisy family', 'Pink Centered Magnolia', 'Fern Petals', 'Fern Leafed Pink Flower', 'Small White and Yellow Flower', 'Purple Lily Flower', 'Star Patterned Flower', 'Geranium', 'Spiral-Leaved Carnation', 'White-Ringed Purple Flower', 'Pink Petal Ring Flower', 'Asymmetrical Petal Lily', 'Symmetrical Heart-shaped Yellow Flower', 'Pink Heart Flower', 'Campanula', 'Red Rosette Flower', 'Fern-like Rosette Blossom', 'Large-flowered Camellia', 'Bluebell', 'Small Orange Ringflower', 'Symmetrical Pink Flower', 'Rosette Leafed Yellow-Orange Flower', 'Lotus flower', 'White-Yellow Centered Flower', 'Summer Geranium', 'Pink-Purple Gradient Flower', 'Ovate Rosette', 'Star-shaped Poinsettia', 'Small Pink Grass Flower', 'Field Poppy', 'Large Pink Lily', 'Colorful Gradient Blossom', 'Small Gradient Flower', 'Yellow Ring Flower', 'Pink Trumpet Flower', 'White and Yellow Centered Pink Flower', 'Echinacea Echinacea', 'Ruffled Rose', 'Large Green Leafed Flower', 'Daisy Flower', 'Nelumbo Nucifera', 'Fern-like Pink Flower', 'Spiky Blue Petal Flower', 'Zigzag Petal Rose', 'Yellow Water Lily', 'White Center Ring Flower', 'Yellow Centered Ruffled Petal Flower', 'Fern-Like Pink and White Flower', 'Lily-shaped purple flower', 'White-Yellow Symmetrical Flower', 'Small White Center Flower', 'Blue Centered Purple Flower', 'Purple Pea Flower', 'Small Rosetted Flower', 'Small-sized Lily', 'Lily of the Valley', 'Yellow-Orange Dahlia', 'Large-Sized Dahlia', 'Yellow Dandelion', 'Intense Yellow-Red Bloom', 'Orange Rose', 'Curved Bud Purple Flower', 'Parallel Venation Green Flower', 'Crane Flower', 'Oblong Leafed Yellow Flower', 'White-Striped Iris', 'Yellow Centered Orchid', "Cyclamen'sunburst", 'Orange-yellow gerbera', 'Zigzag stem flower', 'Wild Poppy', 'White Trumpet Lily', 'Hibiscus', 'Lily with Ruffled Petals', 'Gradient Petal Lily', 'White and Purple Ring Flower', 'Bud Ring Flower', 'Purple and White Rosette Flower', 'Pink Ruffled Rosette', 'Greenish Tinged Petalled', 'White Daffodil', 'Fernleaf plant with red stem and wavy green leaves', 'Intense Blue Petal Ring', 'Grassy Pink Petal', 'Yellow and White Ring Flower', 'Zantedeschia aethiopica', 'Pink Cyclamen', 'Red and yellow ray flower', 'Rosette Leaf Pink Flower', 'Red Rose', 'Fern-like Leaf Foxglove', 'Christmas star', 'Tulipa spottedensis', 'Clustered Pink and White Bud', 'Wavy Margined Bud', 'Yellow Sunflower', 'Ruffled Petal Ring Flower', 'Rosette leaf amaryllis', 'Trumpet Flowers', 'Green Centered Ruffled', 'Black Dot White Flower', 'Pink and White Petal Flower', 'Daffodil-like Yellow Flower', 'Yellow-Centered Red Flower', 'Medium Intensity Pink Flower', 'Intense Pink Petal Cluster', 'Wildflower Dandelion', 'Small White Ring Flower', 'Euphorbia pulcherrima', 'Rosette Flower', 'Pink Lily', 'Dandelion', 'Green Veined Daffodil', 'Pink Lotus', 'White and Yellow Ringflower', 'Small Bee-Pollinated Flower', 'Pink Rhododendron', 'Ruffled Petal Rosette', 'Trumpet Flower', 'Pink Ringflower', 'Arum Lily', 'Gradient Petal Hibiscus', 'Orange Ring Petal Flower', 'Ruffled Petal Hibiscus', 'Rosette Leafed Red Flower', 'Purple and White Flower', 'Bird of Paradise', 'Symmetrical Rosette', 'Purple Bellflower', 'Smooth-leaved viola', 'Smooth-leaved purple flower', 'Yellow circle flower', 'Columbine', 'Star Patterned Iris', 'Single Petal Pink and Yellow Flower', 'Pink Ruffle Flower', 'Intense Red and White Centered Flower', 'Orange Poppy', 'Zigzag Petal Iris', 'Meadow Buttercup', 'Pink Water Lily', 'Small Rosette Blue Flower', 'Ruffled Petal Nasturtium', 'Clustered Blue Bud', 'Small Orchid', 'Pink Hibiscus', 'Pink Ring Flower', 'Spotted Petal Lily', 'Rosette Marigold', 'Lily Flower', 'Pink and White Orchid', 'Strelitzia', 'Green-stemmed Petal', 'Intense Pink Petal Rosette', 'Small Yellow Flower with Gradient', 'Star-shaped Center Flower', 'Small Petal Circle', 'Ruffled Petal Hellebore', 'Rosette Leaf Flower', 'White Star Flower', 'Yellow-Centered Purple Flower', 'Large Pink Rosette Flower', 'Large White Flower', 'Purple and White Drooping Flower', 'Ringed Center White Flower', 'Red Ringed Bud', 'Wild Pink Rosette', 'Blue-Centered Pink Flower', 'Zigzag Petal Flower', 'Yellow Ruffled Flower', 'Spiky Leaf Flower', 'Purple Ruffled Petal Flower', 'Asymmetrical Flower', 'Yellow Ringed Drooping Flower', 'Purple Rosette', 'White and Pink Petal Ring', 'Purple Lily with Butterfly', 'Small Ringed Petal Flower', 'Meadow Dandelion', 'Asiatic Lotus', 'Dark Purple Rosette Flower', 'Blue Sphere Flower', 'Large Orange Flower', 'White Gerbera Daisy', 'Small Yellow and Red Centered Flower', 'Yellow-Red Striped Flower', 'Medium-Sized Yellow Flower', 'Symmetrical Petal Ring', 'White Iris', 'Yellow and Red Ruffled Flower', 'Ring-centered Yellow Flower', 'Small Fern-like Flower', 'Purple Tulip', 'Purple Sphere Flower', 'Asymmetrical Rosette', 'Ruffled Pink Sphere Flower', 'Pink Hellebore', 'Rosette Margined Tulip', 'Rosette Leaf Hibiscus', 'White-Ringed Lily', 'Large Gradient Flower', 'Small Red Rosette', 'Small Pink and White Flower', 'Yellow-centered Orange Flower', 'Asymmetrical viola', 'Nasturtium', 'Curved Petal Pink Flower', 'Rosette Leafed Yellow Flower', 'Dotted Petal Lily', 'Intense Orange Petal Flower', 'Blue Ring Flower', 'Large Flower with Color Variation', 'White Centered Purple Wildflower', 'Spotted Lily Flower', 'Purple Ringflower', 'Pink Rosette', 'Purple peony-like flower', 'Large Dahlia', 'Asteraceae', 'Clematis Silver Swan', 'Purple rosette flower', 'Orange Lily', 'Asymmetrical Bluebell', 'White Lotus', 'Fern-leaved Forget-me-not', 'Large White Petal Orchid', 'Ruffled Petal Pink Flower', 'Eschscholzia californica', 'Black Eyed Susan', 'Small Fern-leafed Blue Flower', 'Large Petal Flower', 'Purple Rosette Flower', 'Fern-like Rosette Flower', 'Large Rose', 'Ringed Center Violet', 'Purple Foxglove', 'Smooth Green Rosette', 'White Flower with Yellow Centers', 'Cyclamen', 'Orange Daffodil', 'Rosette Iris', 'Small red and yellow flower with asymmetrical petals', 'Intense Yellow Petal Plant', 'Intense Pink and White Clematis', 'Rosette Leaf Orchid', 'White and Pink Rosette Orchid', 'Red Daffodil', 'Red Ringed Flower', 'Small White Centered Flower', 'Purple Lily', 'Black-eyed Susan', 'Purple Pot Flower', 'Narcissus', 'Intense Purple Bud Bloom', 'Purple White Ring Flower', 'Viola', 'Orange-Yellow Gradient Flowers', 'Pink rosette flower', 'White-Ringed Viola', 'Small orange gerbera', 'Phalaenopsis', 'Golden Sunflower', 'Small Ringflower', 'Purple Daffodil', 'Purple Cluster Flower', 'Red Stamen Flower', 'Small White and Purple Veined Flower', 'White Ringed Flower', 'Small Rosette Leaf Flower', 'Rosette Ring Flower', 'Lily Ring Flower', 'Small Blue Daffodil', 'Fern-like Petal Flower', 'Gradient Lily', 'Blue Bellflower', 'Red Daisy with Yellow Center', 'Rosy Sunflower', 'Ray Flower', 'Red-Orange Trumpet', 'Pink and White Star Amaryllis', 'Orange Daisy', 'Yellow Centered Petal Flower', 'Black Centered Pink Flower', 'White and Pink Rosette Flower', 'Fernleaf Lily', 'Purple Petal Orchid', 'Smooth Stemmed Pink Flower', 'Wavy Margined Leaf Flower', 'Purple Petunia', 'Yellow-centered Camellia', 'Small oblong petal flower', 'White Ringed Blueflower', 'Single-bud purple flower', 'White poppy with yellow center', 'Golden Rudbeckia', 'Golf Ball Orchid', 'Small Fern Leaf Flower', 'Rosette gerbera', 'Corn Lily', 'Pink Clematis', 'Yellow-Centered Iris', 'Yellow Coneflower', 'Purple and White Petunia', 'Orange-Blue Flower', 'Symmetrical Rose', 'Asymmetrical Petalled Blossom', 'Yellow-Red Ruffled Flower', 'Intense Purple Center Flower', 'Large Yellow Iris', 'Spotted Lily', 'Fern Leafed Pink Blossom', 'White Poinsettia', 'Rainy Rose', 'Ringed Purple Flower', 'Fern-like Blue Petal Flower', 'Fern-Leafed Rosette Flower', 'Large Velvety Petal Flower', 'White Calla Lily', 'Pink Ring Disc', 'Small Yellow Flower', 'Smooth Stalked Flower', 'Small Yellow-centered Flower', 'Yellow and Orange Ray Flower', 'Yellow-centered Blossom', 'Intense Red Oblong', 'White Trumpet Flower', 'Pink and White Daisy', 'Christmas flower', 'Bouquet of Small Pink Flowers', 'Rosette Petal Daisy', 'Red Ringed Daisy', 'Large Pink Flower', 'Lily Pad Flower', 'Intense Orange Garden Flower', 'Striped Oblong Orchid', 'Lilyflora variegata', 'White Sunflower', 'Yellow Ringflower', 'Ringed Petal Pink Flower', 'White-Dotted Lily', 'Yellow Centered Small White', 'White Hellebore', 'Intensely Colored Petal Cluster', 'Ruffled Petal Daisy', 'Lemon Marigold', 'Zigzag Ruffled Petal Flower', 'White Magnolia', 'Red and Yellow Rosette', 'Intense Blue Starflower', 'Daffodil', 'Rosette-shaped Pink and Yellow Flower', 'Symmetrical Star Flower', 'White Ruffled Rosette', 'Green Centered White Flower', 'Symmetrical Ruffled Petal Flower', 'Ruffled Edge Iris', 'Sunflower', 'Red Geranium', 'Asymmetrical Purple Petal Flower', 'Yellow Centered Poppy', 'Ringed Purple and White Flower', 'Pink and White Striped Orchid', 'White and Blue Dandelion', 'Rosette Lily', 'Asymmetrical Yellow-Centered Flower', 'Petunia flower', 'Red Poppy', 'Small Symmetrical Petal Flower', 'Large Daisy with Red Stripes', 'Yellow Rosette Flower', 'Purple-Flowered Daisy', 'Asymmetrical Red Flower', 'Orange Ring Flower', 'Fern Leaf Pink Flower', 'Dandelion-like flower', 'Drooping Yellow Petal', 'Purple and yellow viola', 'Smooth Leaf Daisy', 'Gradient-Petal Aster', 'Pink Coneflower', 'Lily with Black Dots', 'Pansy', 'Papaver rhoeas', 'Orange-Centered Crocus', 'Yellow-centered Rosette', 'Small Centerblue', 'Yellow ring petal flower', 'Helianthus', 'Sunburst Geranium', 'Orange-Yellow Ring Flower', 'Yellow Daisy', 'Amaryllis', 'Pink and White Ringed Flower', 'Orange Spotted Lily', 'Spiky Purple Leafed Flower', 'Ruffled Petal Flower', 'Orange Bud Flower', 'Apricot Gradient Blossom', 'Wild Violet', 'Purpurea punctata', 'Large Pink Petal Flower', 'White Daisy', 'Ruffled Bluebell', 'Zigzag Stem Pink Flower', 'Purple Daisy', 'Rhododendron', 'Large-flowered Clematis', 'Blue Garden Sphere', 'Lily', 'Woodland Bluebell', 'White-Centered Pink Flower', 'Fern Leafed Rosette Flower', 'Daffodil, Narcissus, Jonquil', 'Green-veined Poinsettia', 'Long Stem Pink Petal Flower', 'Red Ring Flower', 'Rosette Leaf Blossom', 'Dahlia', 'Small Yellow-centered Pink Flower', 'Small Bud-like Flower', 'Rosette Ruffled Flower', 'Wavy-leafed Purple Flower', 'White and Pink Petal Flower', 'Cranesbill', 'Lily-shaped Purple Flower', 'Pink Flower', 'Small Round Petal Flower', 'Purple and White Dotted Flower', 'Rosette Petal Rhombus', 'Gerbera daisy', 'Fernleaf Pinkbud', 'Lily-flowered purple flower', 'Lily-Spotted Purple Flower', 'Pink Yellow-centered Flower', 'Purple and Yellow Viola', 'Smooth Stemmed Daisy', 'Round Petalled Flower', 'Dark Purple Disc Flower', 'Purple Ruffled Flower', 'Yellow Centered Daisy', 'Rosette Bluebell', 'Dainty Meadow Flower', 'Blue Lily', 'Large Purple Petal Flower', 'Bee-Adorned Pink Flower', 'Blue Ringed Petal Flower', 'Red and yellow drooping flower with a yellow center', 'Small Ringed Lily', 'Grassland Rosette Blossom', 'Rosette Arrangement Flower', 'White Daisy with Yellow Center', 'Medium-sized Rose', 'Obong Leafed Petal Flower', 'Ruffled Yellow Iris', 'Red Gradient Flower', 'Rosette Hellebore', 'Yellow-Centered Pink Bloom', 'Big Sunburst Flower', 'Gradient Petalled Flower', 'Small Ruffled Petal Flower', 'Small Rose', 'Ruffled Lily', 'Ring of Red', 'Red and Yellow Rosette Flower', 'White Rose', 'Small Rosette Flower', 'Ruffled Peony Iris', 'Yellow-centered Pink Disc Flower', 'Hellebore', 'Fernlike Pink Flower', 'Asymmetrical Yellow and White Petal Flower', 'Bellflower', 'Small Rosette Thistle', 'Asymmetrical Garden Flower', 'Blue Morning Glory', 'Asymmetrical Ring Flowers', 'Ringed Center Petal Blossom', 'Water lily', 'Spotted Petunia', 'Spiral Leaf Flower', 'Protea', 'Fernlike Petal Flower', 'Large-Flowered Carnation', 'Velvety Petal Rosette', 'Striped star amaryllis', 'Purple Artichoke Flower']
0it [00:00, ?it/s]1it [00:00,  3.14it/s]2it [00:00,  3.41it/s]3it [00:00,  3.63it/s]4it [00:01,  3.07it/s]5it [00:01,  3.51it/s]6it [00:01,  3.11it/s]7it [00:02,  3.18it/s]8it [00:02,  3.21it/s]9it [00:02,  3.14it/s]10it [00:03,  2.38it/s]11it [00:03,  2.46it/s]12it [00:04,  2.45it/s]13it [00:04,  2.60it/s]14it [00:04,  2.62it/s]15it [00:05,  2.79it/s]16it [00:05,  3.16it/s]17it [00:05,  3.43it/s]18it [00:05,  3.71it/s]19it [00:06,  3.61it/s]20it [00:06,  3.32it/s]21it [00:06,  3.20it/s]22it [00:07,  3.38it/s]23it [00:07,  3.43it/s]24it [00:07,  3.62it/s]25it [00:07,  3.68it/s]26it [00:08,  3.98it/s]27it [00:08,  4.37it/s]28it [00:08,  4.32it/s]29it [00:08,  4.51it/s]30it [00:08,  4.46it/s]31it [00:09,  4.86it/s]32it [00:09,  4.50it/s]33it [00:09,  3.79it/s]34it [00:10,  3.36it/s]35it [00:10,  3.82it/s]36it [00:10,  4.17it/s]37it [00:10,  4.80it/s]38it [00:11,  3.71it/s]39it [00:11,  3.75it/s]40it [00:11,  3.92it/s]41it [00:11,  3.75it/s]42it [00:12,  3.48it/s]43it [00:12,  3.66it/s]44it [00:12,  3.45it/s]45it [00:13,  2.22it/s]46it [00:14,  1.78it/s]47it [00:15,  1.41it/s]48it [00:16,  1.24it/s]49it [00:17,  1.20it/s]50it [00:18,  1.12it/s]51it [00:19,  1.02it/s]52it [00:20,  1.03s/it]53it [00:21,  1.03s/it]54it [00:22,  1.02s/it]55it [00:23,  1.03s/it]56it [00:24,  1.04s/it]57it [00:25,  1.02s/it]58it [00:26,  1.01s/it]59it [00:27,  1.03it/s]60it [00:28,  1.12it/s]61it [00:29,  1.15it/s]62it [00:30,  1.12it/s]63it [00:31,  1.10it/s]64it [00:31,  1.16it/s]65it [00:32,  1.36it/s]66it [00:32,  1.82it/s]68it [00:32,  2.70it/s]69it [00:33,  2.57it/s]70it [00:33,  2.65it/s]71it [00:33,  2.73it/s]72it [00:34,  2.56it/s]73it [00:34,  2.90it/s]74it [00:34,  3.60it/s]75it [00:35,  3.28it/s]76it [00:35,  3.03it/s]77it [00:35,  2.65it/s]78it [00:36,  2.95it/s]79it [00:36,  3.45it/s]80it [00:36,  3.76it/s]81it [00:36,  3.85it/s]82it [00:37,  2.31it/s]83it [00:38,  2.38it/s]84it [00:38,  2.37it/s]85it [00:38,  2.53it/s]86it [00:39,  2.68it/s]87it [00:39,  2.78it/s]88it [00:39,  3.26it/s]89it [00:40,  3.09it/s]90it [00:40,  2.99it/s]91it [00:40,  2.99it/s]92it [00:41,  2.38it/s]93it [00:41,  2.04it/s]94it [00:42,  1.94it/s]95it [00:43,  1.58it/s]96it [00:43,  2.03it/s]97it [00:43,  2.60it/s]98it [00:43,  3.15it/s]99it [00:44,  3.23it/s]100it [00:44,  2.53it/s]101it [00:45,  2.21it/s]102it [00:45,  2.23it/s]103it [00:46,  2.09it/s]104it [00:46,  1.95it/s]105it [00:47,  1.85it/s]106it [00:48,  1.80it/s]107it [00:48,  1.97it/s]108it [00:49,  1.92it/s]109it [00:49,  1.79it/s]110it [00:50,  1.87it/s]111it [00:50,  2.23it/s]112it [00:50,  2.17it/s]113it [00:51,  2.22it/s]114it [00:52,  1.68it/s]115it [00:53,  1.39it/s]116it [00:54,  1.23it/s]117it [00:54,  1.35it/s]118it [00:55,  1.25it/s]119it [00:56,  1.21it/s]120it [00:56,  1.58it/s]121it [00:57,  1.99it/s]122it [00:57,  2.40it/s]123it [00:57,  2.83it/s]124it [00:57,  2.94it/s]125it [00:58,  3.18it/s]126it [00:58,  3.53it/s]127it [00:58,  3.60it/s]128it [00:58,  4.29it/s]129it [00:58,  4.92it/s]130it [00:59,  4.26it/s]131it [00:59,  4.00it/s]132it [00:59,  4.10it/s]133it [00:59,  4.08it/s]134it [01:00,  4.41it/s]136it [01:00,  6.33it/s]138it [01:00,  7.89it/s]140it [01:00,  9.17it/s]142it [01:00,  9.72it/s]144it [01:00,  9.99it/s]146it [01:01,  7.65it/s]148it [01:01,  8.38it/s]150it [01:01,  9.15it/s]152it [01:01,  9.70it/s]154it [01:02,  9.99it/s]156it [01:02, 10.39it/s]158it [01:02, 10.49it/s]160it [01:02, 10.75it/s]162it [01:02, 10.50it/s]164it [01:02, 10.77it/s]166it [01:03, 10.47it/s]168it [01:03, 10.44it/s]170it [01:03,  8.72it/s]172it [01:03,  9.67it/s]174it [01:04, 10.46it/s]176it [01:04, 11.25it/s]178it [01:04, 11.04it/s]180it [01:04,  9.34it/s]182it [01:04,  9.55it/s]184it [01:05,  9.65it/s]186it [01:05, 10.04it/s]188it [01:05, 10.54it/s]190it [01:05, 11.71it/s]192it [01:05, 12.59it/s]194it [01:05, 12.75it/s]196it [01:05, 13.16it/s]198it [01:06, 12.98it/s]200it [01:06, 12.98it/s]202it [01:06, 13.03it/s]204it [01:06, 13.20it/s]206it [01:06, 13.12it/s]208it [01:06, 13.54it/s]210it [01:06, 14.42it/s]212it [01:07, 14.09it/s]214it [01:07, 14.06it/s]216it [01:07, 13.48it/s]218it [01:07, 13.76it/s]220it [01:07, 13.93it/s]222it [01:07, 13.58it/s]224it [01:07, 14.10it/s]226it [01:08, 13.83it/s]228it [01:08, 13.77it/s]230it [01:08, 14.44it/s]232it [01:08, 13.95it/s]234it [01:08, 13.87it/s]236it [01:08, 12.62it/s]238it [01:09, 12.53it/s]240it [01:09, 12.13it/s]242it [01:09, 11.49it/s]244it [01:09, 11.46it/s]246it [01:09, 11.53it/s]248it [01:09, 11.08it/s]250it [01:10, 11.04it/s]252it [01:10, 10.32it/s]254it [01:10, 11.61it/s]256it [01:10, 12.36it/s]258it [01:10, 12.49it/s]260it [01:11, 10.50it/s]262it [01:11, 11.73it/s]264it [01:11, 12.49it/s]266it [01:11, 12.82it/s]268it [01:11, 13.13it/s]270it [01:11, 13.90it/s]272it [01:11, 14.22it/s]274it [01:12, 14.21it/s]276it [01:12, 13.81it/s]278it [01:12, 13.39it/s]280it [01:12, 10.79it/s]282it [01:12, 11.08it/s]284it [01:12, 11.06it/s]286it [01:13, 10.91it/s]288it [01:13, 10.86it/s]290it [01:13, 10.69it/s]292it [01:13, 10.38it/s]294it [01:14,  8.53it/s]295it [01:14,  8.57it/s]296it [01:14,  8.26it/s]297it [01:14,  8.26it/s]298it [01:14,  8.37it/s]299it [01:14,  8.17it/s]300it [01:14,  8.10it/s]301it [01:14,  8.28it/s]302it [01:15,  8.30it/s]303it [01:15,  7.71it/s]304it [01:15,  7.73it/s]305it [01:15,  4.50it/s]306it [01:15,  4.92it/s]306it [01:15,  4.03it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:04<01:52,  4.71s/it]  8%|▊         | 2/25 [00:05<00:51,  2.25s/it] 12%|█▏        | 3/25 [00:05<00:28,  1.32s/it] 16%|█▌        | 4/25 [00:05<00:19,  1.08it/s] 20%|██        | 5/25 [00:05<00:13,  1.50it/s] 24%|██▍       | 6/25 [00:06<00:10,  1.84it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.31it/s] 32%|███▏      | 8/25 [00:06<00:06,  2.55it/s] 36%|███▌      | 9/25 [00:06<00:05,  3.00it/s] 40%|████      | 10/25 [00:07<00:04,  3.08it/s] 44%|████▍     | 11/25 [00:07<00:04,  3.47it/s] 48%|████▊     | 12/25 [00:07<00:03,  3.81it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.09it/s] 56%|█████▌    | 14/25 [00:08<00:02,  4.30it/s] 60%|██████    | 15/25 [00:08<00:02,  4.47it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.59it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.68it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.74it/s] 76%|███████▌  | 19/25 [00:09<00:01,  4.79it/s] 80%|████████  | 20/25 [00:09<00:01,  4.82it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.84it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.86it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.87it/s] 96%|█████████▌| 24/25 [00:10<00:00,  4.88it/s]100%|██████████| 25/25 [00:10<00:00,  2.42it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:03<01:28,  3.71s/it]  8%|▊         | 2/25 [00:04<00:46,  2.00s/it] 12%|█▏        | 3/25 [00:04<00:25,  1.18s/it] 16%|█▌        | 4/25 [00:05<00:17,  1.20it/s] 20%|██        | 5/25 [00:05<00:12,  1.65it/s] 24%|██▍       | 6/25 [00:05<00:09,  1.99it/s] 28%|██▊       | 7/25 [00:05<00:07,  2.47it/s] 32%|███▏      | 8/25 [00:05<00:05,  2.93it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.35it/s] 40%|████      | 10/25 [00:06<00:04,  3.71it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.01it/s] 48%|████▊     | 12/25 [00:06<00:03,  4.25it/s] 52%|█████▏    | 13/25 [00:06<00:02,  4.43it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.56it/s] 60%|██████    | 15/25 [00:07<00:02,  4.66it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.73it/s] 68%|██████▊   | 17/25 [00:07<00:01,  4.78it/s] 72%|███████▏  | 18/25 [00:07<00:01,  4.82it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.84it/s] 80%|████████  | 20/25 [00:08<00:01,  4.86it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:08<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:08<00:00,  4.90it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.90it/s]100%|██████████| 25/25 [00:09<00:00,  2.68it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5088530778884888


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 61.96129451943405
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.6858673953719
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 59.58462361716346


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 50.88530731201172
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  4.62it/s]2it [00:00,  4.51it/s]3it [00:00,  2.70it/s]4it [00:01,  2.29it/s]5it [00:02,  1.98it/s]6it [00:02,  2.28it/s]7it [00:02,  2.55it/s]8it [00:03,  2.55it/s]9it [00:03,  2.16it/s]10it [00:04,  1.92it/s]11it [00:04,  1.86it/s]12it [00:05,  1.93it/s]13it [00:05,  2.10it/s]14it [00:06,  2.35it/s]15it [00:06,  2.15it/s]16it [00:07,  2.28it/s]17it [00:07,  2.13it/s]18it [00:08,  2.12it/s]19it [00:08,  2.02it/s]20it [00:09,  1.84it/s]21it [00:09,  1.82it/s]22it [00:10,  1.80it/s]23it [00:10,  1.93it/s]24it [00:11,  2.27it/s]25it [00:11,  2.02it/s]26it [00:12,  2.02it/s]27it [00:12,  2.20it/s]28it [00:13,  2.07it/s]29it [00:13,  2.12it/s]30it [00:14,  2.20it/s]31it [00:14,  2.13it/s]32it [00:15,  2.00it/s]33it [00:15,  2.41it/s]34it [00:15,  2.47it/s]35it [00:16,  2.09it/s]36it [00:16,  1.98it/s]37it [00:17,  1.86it/s]38it [00:18,  1.83it/s]39it [00:18,  2.23it/s]40it [00:18,  2.33it/s]41it [00:19,  2.37it/s]42it [00:19,  2.23it/s]43it [00:20,  2.30it/s]44it [00:20,  2.35it/s]45it [00:20,  2.60it/s]46it [00:21,  2.45it/s]47it [00:21,  2.50it/s]48it [00:22,  2.28it/s]49it [00:22,  2.10it/s]50it [00:22,  2.42it/s]51it [00:23,  2.19it/s]52it [00:23,  2.14it/s]53it [00:24,  2.48it/s]54it [00:24,  3.01it/s]55it [00:24,  2.97it/s]56it [00:25,  2.82it/s]57it [00:25,  3.48it/s]58it [00:25,  3.80it/s]59it [00:25,  3.99it/s]60it [00:25,  4.71it/s]61it [00:26,  4.89it/s]62it [00:26,  3.18it/s]63it [00:27,  2.56it/s]64it [00:27,  2.40it/s]65it [00:27,  2.49it/s]66it [00:28,  2.42it/s]67it [00:28,  2.62it/s]68it [00:29,  2.25it/s]69it [00:29,  2.07it/s]70it [00:30,  2.41it/s]71it [00:30,  2.55it/s]72it [00:30,  2.37it/s]73it [00:31,  2.35it/s]74it [00:31,  2.30it/s]75it [00:32,  2.05it/s]76it [00:32,  2.10it/s]77it [00:33,  2.04it/s]78it [00:33,  2.08it/s]79it [00:34,  2.06it/s]80it [00:34,  2.20it/s]81it [00:35,  2.06it/s]82it [00:35,  2.18it/s]83it [00:36,  2.31it/s]84it [00:36,  2.19it/s]85it [00:36,  2.35it/s]86it [00:37,  2.26it/s]87it [00:37,  2.34it/s]88it [00:38,  2.12it/s]89it [00:38,  2.40it/s]90it [00:39,  2.29it/s]91it [00:39,  2.27it/s]92it [00:40,  2.23it/s]93it [00:40,  2.07it/s]94it [00:41,  2.07it/s]95it [00:41,  2.06it/s]96it [00:41,  2.27it/s]97it [00:42,  2.20it/s]98it [00:42,  2.18it/s]99it [00:43,  2.12it/s]100it [00:44,  1.93it/s]101it [00:44,  2.12it/s]102it [00:44,  2.46it/s]103it [00:44,  2.75it/s]104it [00:45,  2.61it/s]105it [00:45,  2.25it/s]106it [00:46,  2.09it/s]107it [00:46,  2.26it/s]108it [00:47,  2.24it/s]109it [00:47,  2.07it/s]110it [00:48,  2.14it/s]111it [00:48,  1.93it/s]112it [00:49,  2.29it/s]113it [00:49,  2.55it/s]114it [00:49,  3.13it/s]115it [00:49,  3.58it/s]116it [00:50,  2.85it/s]117it [00:50,  3.12it/s]118it [00:50,  3.54it/s]119it [00:51,  3.77it/s]120it [00:51,  3.39it/s]121it [00:51,  2.91it/s]122it [00:52,  2.83it/s]123it [00:52,  2.66it/s]124it [00:53,  2.74it/s]125it [00:53,  2.50it/s]126it [00:54,  2.06it/s]127it [00:54,  2.00it/s]128it [00:55,  2.26it/s]129it [00:55,  2.34it/s]130it [00:55,  2.54it/s]131it [00:56,  2.30it/s]132it [00:56,  2.06it/s]133it [00:57,  1.88it/s]134it [00:57,  2.04it/s]135it [00:58,  2.07it/s]136it [00:59,  1.88it/s]137it [00:59,  1.93it/s]138it [00:59,  2.43it/s]139it [00:59,  2.91it/s]140it [01:00,  3.46it/s]141it [01:00,  3.91it/s]142it [01:00,  4.40it/s]143it [01:00,  3.44it/s]144it [01:01,  3.06it/s]145it [01:01,  3.81it/s]146it [01:01,  4.53it/s]148it [01:01,  5.88it/s]149it [01:01,  5.58it/s]150it [01:02,  4.46it/s]151it [01:02,  3.10it/s]152it [01:03,  2.62it/s]153it [01:03,  2.30it/s]154it [01:04,  2.40it/s]155it [01:04,  2.54it/s]156it [01:05,  2.37it/s]157it [01:05,  2.35it/s]158it [01:05,  2.30it/s]159it [01:06,  2.14it/s]160it [01:07,  1.89it/s]161it [01:07,  1.93it/s]162it [01:08,  1.88it/s]163it [01:08,  1.88it/s]164it [01:09,  2.28it/s]165it [01:09,  2.30it/s]166it [01:10,  2.07it/s]167it [01:10,  2.04it/s]168it [01:11,  1.78it/s]169it [01:11,  1.68it/s]170it [01:12,  1.64it/s]171it [01:13,  1.59it/s]172it [01:13,  1.58it/s]173it [01:14,  1.75it/s]174it [01:14,  1.86it/s]175it [01:14,  2.41it/s]176it [01:15,  2.38it/s]177it [01:15,  2.33it/s]178it [01:16,  2.23it/s]179it [01:16,  2.18it/s]180it [01:17,  2.20it/s]181it [01:17,  2.06it/s]182it [01:17,  2.48it/s]183it [01:18,  2.46it/s]184it [01:19,  1.59it/s]185it [01:20,  1.28it/s]186it [01:21,  1.37it/s]187it [01:21,  1.50it/s]188it [01:22,  1.74it/s]189it [01:22,  2.05it/s]191it [01:22,  3.32it/s]193it [01:22,  4.60it/s]195it [01:22,  5.81it/s]196it [01:23,  6.33it/s]198it [01:23,  7.48it/s]199it [01:23,  7.74it/s]201it [01:23,  8.86it/s]202it [01:23,  9.06it/s]204it [01:23,  9.88it/s]206it [01:24,  9.98it/s]208it [01:24, 10.95it/s]210it [01:24, 11.64it/s]212it [01:24, 12.00it/s]214it [01:24, 11.35it/s]216it [01:24, 10.82it/s]218it [01:25, 10.57it/s]220it [01:25, 10.97it/s]222it [01:25, 10.87it/s]224it [01:25, 11.22it/s]226it [01:25, 10.87it/s]228it [01:25, 11.05it/s]230it [01:26, 11.20it/s]232it [01:26, 10.68it/s]234it [01:26, 11.10it/s]236it [01:26, 11.08it/s]238it [01:26, 11.22it/s]240it [01:27, 10.83it/s]242it [01:27, 10.46it/s]244it [01:27, 11.17it/s]246it [01:27, 11.96it/s]248it [01:27, 11.09it/s]250it [01:27, 10.88it/s]252it [01:28, 11.36it/s]254it [01:28, 11.01it/s]256it [01:28, 10.99it/s]258it [01:28, 10.82it/s]260it [01:28, 10.92it/s]262it [01:29, 11.21it/s]264it [01:29, 10.91it/s]266it [01:29, 10.87it/s]268it [01:29, 10.73it/s]270it [01:29, 11.07it/s]272it [01:30,  6.07it/s]273it [01:30,  4.95it/s]274it [01:31,  4.91it/s]276it [01:31,  6.43it/s]278it [01:31,  7.70it/s]280it [01:31,  8.87it/s]282it [01:31,  9.68it/s]284it [01:31, 10.06it/s]286it [01:32, 10.71it/s]288it [01:32, 10.94it/s]290it [01:32,  9.42it/s]292it [01:32,  7.20it/s]293it [01:33,  6.46it/s]294it [01:33,  5.56it/s]295it [01:33,  5.24it/s]296it [01:33,  4.82it/s]297it [01:34,  4.18it/s]298it [01:34,  4.02it/s]299it [01:34,  3.98it/s]300it [01:35,  3.50it/s]301it [01:35,  3.90it/s]302it [01:35,  3.76it/s]303it [01:35,  4.33it/s]304it [01:35,  4.51it/s]305it [01:36,  4.75it/s]306it [01:36,  4.74it/s]306it [01:36,  3.18it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:05<02:15,  5.64s/it]  8%|▊         | 2/25 [00:05<00:56,  2.44s/it] 12%|█▏        | 3/25 [00:06<00:31,  1.42s/it] 16%|█▌        | 4/25 [00:06<00:19,  1.06it/s] 20%|██        | 5/25 [00:06<00:13,  1.48it/s] 24%|██▍       | 6/25 [00:06<00:09,  1.94it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.41it/s] 32%|███▏      | 8/25 [00:07<00:05,  2.88it/s] 36%|███▌      | 9/25 [00:07<00:04,  3.30it/s] 40%|████      | 10/25 [00:07<00:04,  3.67it/s] 44%|████▍     | 11/25 [00:07<00:03,  3.97it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.22it/s] 52%|█████▏    | 13/25 [00:08<00:02,  4.40it/s] 56%|█████▌    | 14/25 [00:08<00:02,  4.54it/s] 60%|██████    | 15/25 [00:08<00:02,  4.65it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.73it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.78it/s] 72%|███████▏  | 18/25 [00:09<00:01,  4.82it/s] 76%|███████▌  | 19/25 [00:09<00:01,  4.85it/s] 80%|████████  | 20/25 [00:09<00:01,  4.87it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:10<00:00,  4.90it/s] 96%|█████████▌| 24/25 [00:10<00:00,  4.91it/s]100%|██████████| 25/25 [00:10<00:00,  2.37it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:50,  4.59s/it]  8%|▊         | 2/25 [00:05<00:51,  2.24s/it] 12%|█▏        | 3/25 [00:05<00:28,  1.31s/it] 16%|█▌        | 4/25 [00:05<00:18,  1.15it/s] 20%|██        | 5/25 [00:05<00:12,  1.58it/s] 24%|██▍       | 6/25 [00:05<00:09,  2.05it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.53it/s] 32%|███▏      | 8/25 [00:06<00:05,  2.99it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.39it/s] 40%|████      | 10/25 [00:06<00:04,  3.74it/s] 44%|████▍     | 11/25 [00:07<00:03,  4.02it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.25it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.42it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.55it/s] 60%|██████    | 15/25 [00:07<00:02,  4.64it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.71it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.75it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.79it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.82it/s] 80%|████████  | 20/25 [00:08<00:01,  4.84it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.86it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.87it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.87it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.88it/s]100%|██████████| 25/25 [00:09<00:00,  2.51it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.511996865272522


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 62.80696048137908
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 80.1992089740136
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 61.06190866087121


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 51.19968795776367
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  1.00it/s]2it [00:01,  1.72it/s]3it [00:01,  2.35it/s]4it [00:01,  2.34it/s]5it [00:02,  2.17it/s]6it [00:03,  1.84it/s]7it [00:04,  1.32it/s]8it [00:05,  1.20it/s]9it [00:06,  1.08it/s]10it [00:07,  1.10it/s]11it [00:08,  1.09it/s]12it [00:09,  1.04it/s]13it [00:10,  1.01s/it]14it [00:11,  1.10s/it]15it [00:13,  1.32s/it]16it [00:15,  1.42s/it]17it [00:16,  1.49s/it]18it [00:18,  1.54s/it]19it [00:20,  1.57s/it]20it [00:21,  1.60s/it]21it [00:23,  1.62s/it]22it [00:25,  1.60s/it]23it [00:26,  1.62s/it]24it [00:28,  1.66s/it]25it [00:29,  1.60s/it]26it [00:31,  1.59s/it]27it [00:32,  1.52s/it]28it [00:34,  1.53s/it]29it [00:35,  1.50s/it]30it [00:37,  1.46s/it]31it [00:39,  1.55s/it]32it [00:40,  1.57s/it]33it [00:42,  1.58s/it]34it [00:43,  1.60s/it]35it [00:45,  1.62s/it]36it [00:47,  1.65s/it]37it [00:49,  1.69s/it]38it [00:50,  1.67s/it]39it [00:52,  1.69s/it]40it [00:54,  1.68s/it]41it [00:55,  1.65s/it]42it [00:57,  1.66s/it]43it [00:58,  1.61s/it]44it [01:00,  1.59s/it]45it [01:02,  1.63s/it]46it [01:03,  1.66s/it]47it [01:05,  1.65s/it]48it [01:07,  1.66s/it]49it [01:08,  1.54s/it]50it [01:09,  1.37s/it]51it [01:10,  1.23s/it]52it [01:11,  1.19s/it]53it [01:12,  1.14s/it]54it [01:13,  1.26s/it]55it [01:14,  1.19s/it]56it [01:16,  1.33s/it]57it [01:17,  1.28s/it]58it [01:18,  1.21s/it]59it [01:20,  1.25s/it]60it [01:21,  1.25s/it]61it [01:22,  1.13s/it]62it [01:23,  1.11s/it]63it [01:24,  1.05s/it]64it [01:25,  1.09s/it]65it [01:26,  1.06s/it]66it [01:27,  1.02it/s]67it [01:28,  1.04s/it]68it [01:29,  1.17s/it]69it [01:31,  1.38s/it]70it [01:33,  1.57s/it]71it [01:35,  1.77s/it]72it [01:38,  1.95s/it]73it [01:40,  2.05s/it]74it [01:42,  2.09s/it]75it [01:45,  2.24s/it]76it [01:47,  2.27s/it]77it [01:50,  2.34s/it]78it [01:52,  2.36s/it]79it [01:55,  2.37s/it]80it [01:57,  2.40s/it]81it [02:00,  2.48s/it]82it [02:02,  2.46s/it]83it [02:04,  2.39s/it]84it [02:06,  2.32s/it]85it [02:09,  2.31s/it]86it [02:11,  2.15s/it]87it [02:12,  2.04s/it]88it [02:14,  1.90s/it]89it [02:16,  1.82s/it]90it [02:18,  1.89s/it]91it [02:19,  1.78s/it]92it [02:21,  1.74s/it]93it [02:22,  1.62s/it]94it [02:24,  1.69s/it]95it [02:26,  1.67s/it]96it [02:27,  1.66s/it]97it [02:29,  1.66s/it]98it [02:30,  1.65s/it]99it [02:32,  1.63s/it]100it [02:34,  1.64s/it]101it [02:35,  1.64s/it]102it [02:37,  1.57s/it]103it [02:39,  1.71s/it]104it [02:41,  1.87s/it]105it [02:43,  1.94s/it]106it [02:45,  1.95s/it]107it [02:47,  1.89s/it]108it [02:49,  1.83s/it]109it [02:50,  1.78s/it]110it [02:52,  1.85s/it]111it [02:54,  1.94s/it]112it [02:56,  1.87s/it]113it [02:58,  1.82s/it]114it [03:00,  1.78s/it]115it [03:01,  1.79s/it]116it [03:03,  1.83s/it]117it [03:05,  1.81s/it]118it [03:07,  1.80s/it]119it [03:09,  1.79s/it]120it [03:10,  1.74s/it]121it [03:12,  1.75s/it]122it [03:14,  1.75s/it]123it [03:15,  1.72s/it]124it [03:17,  1.80s/it]125it [03:19,  1.87s/it]126it [03:22,  1.95s/it]127it [03:23,  1.94s/it]128it [03:25,  1.86s/it]129it [03:26,  1.70s/it]130it [03:28,  1.60s/it]131it [03:29,  1.59s/it]132it [03:30,  1.44s/it]133it [03:31,  1.32s/it]134it [03:33,  1.24s/it]135it [03:34,  1.24s/it]136it [03:36,  1.42s/it]137it [03:37,  1.37s/it]138it [03:38,  1.31s/it]139it [03:39,  1.26s/it]140it [03:40,  1.17s/it]141it [03:41,  1.17s/it]142it [03:43,  1.34s/it]143it [03:44,  1.27s/it]144it [03:45,  1.22s/it]145it [03:46,  1.20s/it]146it [03:48,  1.17s/it]147it [03:49,  1.14s/it]148it [03:50,  1.09s/it]149it [03:51,  1.06s/it]150it [03:52,  1.20s/it]151it [03:53,  1.24s/it]152it [03:55,  1.37s/it]153it [03:57,  1.45s/it]154it [03:59,  1.56s/it]155it [04:00,  1.49s/it]156it [04:02,  1.54s/it]157it [04:03,  1.56s/it]158it [04:05,  1.59s/it]159it [04:06,  1.58s/it]160it [04:08,  1.52s/it]161it [04:09,  1.39s/it]162it [04:10,  1.30s/it]163it [04:11,  1.24s/it]164it [04:13,  1.40s/it]165it [04:15,  1.66s/it]166it [04:17,  1.75s/it]167it [04:19,  1.72s/it]168it [04:20,  1.65s/it]169it [04:22,  1.72s/it]170it [04:24,  1.86s/it]171it [04:26,  1.80s/it]172it [04:28,  1.77s/it]173it [04:29,  1.76s/it]174it [04:31,  1.80s/it]175it [04:33,  1.77s/it]176it [04:35,  1.77s/it]177it [04:37,  1.79s/it]178it [04:39,  1.92s/it]179it [04:41,  2.05s/it]180it [04:43,  2.06s/it]181it [04:45,  2.06s/it]182it [04:47,  1.84s/it]183it [04:48,  1.82s/it]184it [04:50,  1.74s/it]185it [04:52,  1.82s/it]186it [04:54,  1.76s/it]187it [04:55,  1.72s/it]188it [04:57,  1.70s/it]189it [04:59,  1.81s/it]190it [05:00,  1.76s/it]191it [05:02,  1.74s/it]192it [05:04,  1.72s/it]193it [05:05,  1.68s/it]194it [05:07,  1.58s/it]195it [05:08,  1.52s/it]196it [05:10,  1.62s/it]197it [05:12,  1.82s/it]198it [05:14,  1.85s/it]199it [05:16,  1.90s/it]200it [05:18,  1.94s/it]201it [05:21,  2.03s/it]202it [05:23,  2.12s/it]203it [05:25,  2.13s/it]204it [05:27,  2.18s/it]205it [05:29,  2.18s/it]206it [05:32,  2.18s/it]207it [05:34,  2.20s/it]208it [05:36,  2.22s/it]209it [05:38,  2.22s/it]210it [05:41,  2.20s/it]211it [05:43,  2.22s/it]212it [05:45,  2.19s/it]213it [05:47,  2.18s/it]214it [05:49,  2.21s/it]215it [05:51,  2.08s/it]216it [05:53,  1.96s/it]217it [05:55,  1.90s/it]218it [05:57,  1.98s/it]219it [05:59,  1.93s/it]220it [06:00,  1.88s/it]221it [06:02,  1.85s/it]222it [06:04,  1.79s/it]223it [06:06,  1.90s/it]224it [06:08,  1.88s/it]225it [06:09,  1.83s/it]226it [06:11,  1.69s/it]227it [06:12,  1.53s/it]228it [06:13,  1.33s/it]229it [06:13,  1.01it/s]230it [06:13,  1.33it/s]231it [06:14,  1.65it/s]233it [06:14,  2.44it/s]234it [06:14,  2.71it/s]235it [06:14,  2.85it/s]236it [06:15,  3.25it/s]237it [06:15,  3.71it/s]238it [06:15,  4.10it/s]239it [06:15,  4.61it/s]240it [06:15,  3.94it/s]241it [06:16,  2.20it/s]242it [06:17,  2.38it/s]243it [06:17,  2.95it/s]244it [06:17,  3.13it/s]245it [06:18,  2.63it/s]246it [06:18,  2.04it/s]247it [06:19,  1.75it/s]248it [06:20,  1.59it/s]249it [06:21,  1.33it/s]250it [06:22,  1.08it/s]251it [06:23,  1.04it/s]252it [06:24,  1.03it/s]253it [06:25,  1.06it/s]254it [06:26,  1.13it/s]255it [06:27,  1.16it/s]256it [06:28,  1.17it/s]257it [06:29,  1.15it/s]258it [06:29,  1.12it/s]259it [06:30,  1.12it/s]260it [06:31,  1.14it/s]261it [06:32,  1.03it/s]262it [06:34,  1.14s/it]263it [06:36,  1.28s/it]264it [06:37,  1.34s/it]265it [06:38,  1.33s/it]266it [06:40,  1.44s/it]267it [06:42,  1.48s/it]268it [06:43,  1.49s/it]269it [06:45,  1.52s/it]270it [06:46,  1.51s/it]271it [06:48,  1.49s/it]272it [06:49,  1.52s/it]273it [06:51,  1.58s/it]274it [06:53,  1.58s/it]275it [06:54,  1.55s/it]276it [06:56,  1.58s/it]277it [06:57,  1.57s/it]278it [06:59,  1.58s/it]279it [07:01,  1.64s/it]280it [07:02,  1.69s/it]281it [07:04,  1.69s/it]282it [07:06,  1.65s/it]283it [07:07,  1.64s/it]284it [07:09,  1.52s/it]285it [07:09,  1.30s/it]286it [07:10,  1.01s/it]287it [07:10,  1.25it/s]288it [07:10,  1.68it/s]290it [07:10,  2.71it/s]292it [07:10,  3.79it/s]294it [07:11,  4.82it/s]296it [07:11,  5.67it/s]298it [07:11,  6.53it/s]299it [07:11,  6.63it/s]301it [07:11,  7.73it/s]302it [07:12,  8.02it/s]304it [07:12,  9.06it/s]306it [07:12,  9.72it/s]306it [07:12,  1.41s/it]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:59,  4.96s/it]  8%|▊         | 2/25 [00:05<00:49,  2.16s/it] 12%|█▏        | 3/25 [00:05<00:28,  1.29s/it] 16%|█▌        | 4/25 [00:05<00:18,  1.16it/s] 20%|██        | 5/25 [00:05<00:12,  1.60it/s] 24%|██▍       | 6/25 [00:06<00:09,  2.08it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.55it/s] 32%|███▏      | 8/25 [00:06<00:05,  3.01it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.42it/s] 40%|████      | 10/25 [00:06<00:03,  3.77it/s] 44%|████▍     | 11/25 [00:07<00:03,  4.05it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.27it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.44it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.56it/s] 60%|██████    | 15/25 [00:07<00:02,  4.65it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.72it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.77it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.80it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.82it/s] 80%|████████  | 20/25 [00:08<00:01,  4.84it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.85it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.85it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.86it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.87it/s]100%|██████████| 25/25 [00:10<00:00,  2.50it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288027763367
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:06<02:44,  6.84s/it]  8%|▊         | 2/25 [00:07<01:16,  3.34s/it] 12%|█▏        | 3/25 [00:07<00:41,  1.91s/it] 16%|█▌        | 4/25 [00:08<00:26,  1.24s/it] 20%|██        | 5/25 [00:08<00:17,  1.15it/s] 24%|██▍       | 6/25 [00:08<00:12,  1.56it/s] 28%|██▊       | 7/25 [00:08<00:08,  2.00it/s] 32%|███▏      | 8/25 [00:08<00:06,  2.46it/s] 36%|███▌      | 9/25 [00:09<00:05,  2.91it/s] 40%|████      | 10/25 [00:09<00:04,  3.32it/s] 44%|████▍     | 11/25 [00:09<00:03,  3.68it/s] 48%|████▊     | 12/25 [00:09<00:03,  3.98it/s] 52%|█████▏    | 13/25 [00:10<00:02,  4.19it/s] 56%|█████▌    | 14/25 [00:10<00:02,  4.37it/s] 60%|██████    | 15/25 [00:10<00:02,  4.50it/s] 64%|██████▍   | 16/25 [00:10<00:01,  4.61it/s] 68%|██████▊   | 17/25 [00:10<00:01,  4.68it/s] 72%|███████▏  | 18/25 [00:11<00:01,  4.71it/s] 76%|███████▌  | 19/25 [00:11<00:01,  4.71it/s] 80%|████████  | 20/25 [00:11<00:01,  4.73it/s] 84%|████████▍ | 21/25 [00:11<00:00,  4.71it/s] 88%|████████▊ | 22/25 [00:11<00:00,  4.77it/s] 92%|█████████▏| 23/25 [00:12<00:00,  4.80it/s] 96%|█████████▌| 24/25 [00:12<00:00,  4.83it/s]100%|██████████| 25/25 [00:12<00:00,  1.99it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5093708038330078


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.81288146972656
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 62.4491787282485
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.92897979477146
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 60.21892889581585


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 50.93708038330078
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.34s/it]2it [00:02,  1.13s/it]3it [00:03,  1.08s/it]4it [00:04,  1.08s/it]5it [00:05,  1.21s/it]6it [00:07,  1.29s/it]7it [00:08,  1.34s/it]8it [00:10,  1.42s/it]9it [00:11,  1.36s/it]10it [00:13,  1.39s/it]11it [00:14,  1.55s/it]12it [00:17,  1.75s/it]13it [00:19,  1.90s/it]14it [00:21,  1.96s/it]15it [00:23,  1.97s/it]16it [00:25,  2.01s/it]17it [00:27,  2.05s/it]18it [00:29,  1.98s/it]19it [00:31,  2.05s/it]20it [00:33,  2.10s/it]21it [00:36,  2.12s/it]22it [00:38,  2.15s/it]23it [00:40,  2.20s/it]24it [00:42,  2.22s/it]25it [00:44,  2.17s/it]26it [00:47,  2.18s/it]27it [00:49,  2.17s/it]28it [00:51,  2.14s/it]29it [00:53,  2.14s/it]30it [00:55,  2.18s/it]31it [00:57,  2.10s/it]32it [00:59,  2.09s/it]33it [01:01,  2.07s/it]34it [01:03,  2.07s/it]35it [01:06,  2.09s/it]36it [01:08,  2.10s/it]37it [01:09,  2.00s/it]38it [01:11,  1.97s/it]39it [01:13,  2.00s/it]40it [01:15,  1.95s/it]41it [01:17,  1.87s/it]42it [01:19,  1.84s/it]43it [01:21,  1.87s/it]44it [01:22,  1.84s/it]45it [01:24,  1.87s/it]46it [01:26,  1.84s/it]47it [01:27,  1.69s/it]48it [01:28,  1.48s/it]49it [01:29,  1.31s/it]50it [01:30,  1.20s/it]51it [01:31,  1.20s/it]52it [01:33,  1.28s/it]53it [01:34,  1.25s/it]54it [01:35,  1.26s/it]55it [01:36,  1.10s/it]56it [01:37,  1.07s/it]57it [01:38,  1.01s/it]58it [01:40,  1.17s/it]59it [01:41,  1.12s/it]60it [01:42,  1.13s/it]61it [01:43,  1.21s/it]62it [01:44,  1.15s/it]63it [01:45,  1.10s/it]64it [01:46,  1.03s/it]65it [01:47,  1.01s/it]66it [01:48,  1.03it/s]67it [01:49,  1.04it/s]68it [01:50,  1.05it/s]69it [01:51,  1.02s/it]70it [01:52,  1.16s/it]71it [01:54,  1.34s/it]72it [01:56,  1.53s/it]73it [01:58,  1.71s/it]74it [02:00,  1.78s/it]75it [02:02,  1.79s/it]76it [02:04,  1.80s/it]77it [02:06,  1.86s/it]78it [02:08,  1.89s/it]79it [02:10,  1.91s/it]80it [02:12,  1.97s/it]81it [02:14,  2.03s/it]82it [02:16,  2.00s/it]83it [02:18,  1.97s/it]84it [02:20,  1.96s/it]85it [02:21,  1.89s/it]86it [02:23,  1.88s/it]87it [02:26,  1.97s/it]88it [02:28,  2.00s/it]89it [02:30,  2.04s/it]90it [02:32,  2.03s/it]91it [02:33,  1.94s/it]92it [02:35,  1.87s/it]93it [02:37,  1.82s/it]94it [02:39,  1.79s/it]95it [02:40,  1.79s/it]96it [02:42,  1.73s/it]97it [02:44,  1.85s/it]98it [02:46,  1.87s/it]99it [02:48,  1.81s/it]100it [02:49,  1.73s/it]101it [02:51,  1.68s/it]102it [02:52,  1.66s/it]103it [02:54,  1.59s/it]104it [02:56,  1.68s/it]105it [02:57,  1.61s/it]106it [02:59,  1.54s/it]107it [03:00,  1.59s/it]108it [03:02,  1.58s/it]109it [03:03,  1.38s/it]110it [03:03,  1.01s/it]111it [03:03,  1.26it/s]112it [03:04,  1.52it/s]113it [03:04,  1.84it/s]114it [03:04,  2.13it/s]115it [03:04,  2.21it/s]116it [03:05,  2.16it/s]117it [03:05,  2.48it/s]118it [03:06,  2.75it/s]119it [03:06,  2.51it/s]120it [03:06,  2.62it/s]121it [03:07,  2.13it/s]122it [03:08,  1.39it/s]123it [03:09,  1.32it/s]124it [03:09,  1.59it/s]125it [03:10,  1.82it/s]126it [03:10,  1.96it/s]127it [03:11,  2.31it/s]128it [03:11,  2.59it/s]129it [03:11,  2.87it/s]130it [03:12,  2.61it/s]131it [03:12,  2.52it/s]132it [03:12,  2.55it/s]133it [03:13,  2.31it/s]134it [03:13,  2.78it/s]135it [03:14,  2.35it/s]136it [03:15,  1.41it/s]137it [03:16,  1.41it/s]138it [03:16,  1.72it/s]139it [03:16,  2.03it/s]140it [03:17,  2.02it/s]141it [03:17,  1.98it/s]142it [03:18,  1.92it/s]143it [03:19,  1.52it/s]144it [03:20,  1.34it/s]145it [03:21,  1.19it/s]146it [03:22,  1.23it/s]147it [03:22,  1.21it/s]148it [03:23,  1.17it/s]149it [03:24,  1.16it/s]150it [03:25,  1.44it/s]151it [03:25,  1.78it/s]152it [03:26,  1.29it/s]153it [03:28,  1.04it/s]154it [03:29,  1.06s/it]155it [03:30,  1.22s/it]156it [03:31,  1.15s/it]157it [03:33,  1.27s/it]158it [03:34,  1.36s/it]159it [03:36,  1.40s/it]160it [03:37,  1.35s/it]161it [03:38,  1.31s/it]162it [03:40,  1.40s/it]163it [03:41,  1.41s/it]164it [03:43,  1.54s/it]165it [03:45,  1.56s/it]166it [03:46,  1.52s/it]167it [03:48,  1.52s/it]168it [03:49,  1.51s/it]169it [03:51,  1.51s/it]170it [03:52,  1.54s/it]171it [03:54,  1.50s/it]172it [03:55,  1.46s/it]173it [03:57,  1.42s/it]174it [03:58,  1.40s/it]175it [04:00,  1.47s/it]176it [04:01,  1.55s/it]177it [04:03,  1.53s/it]178it [04:04,  1.51s/it]179it [04:06,  1.50s/it]180it [04:07,  1.45s/it]181it [04:09,  1.55s/it]182it [04:11,  1.63s/it]183it [04:12,  1.58s/it]184it [04:14,  1.55s/it]185it [04:15,  1.51s/it]186it [04:17,  1.53s/it]187it [04:18,  1.46s/it]188it [04:19,  1.27s/it]189it [04:20,  1.23s/it]190it [04:20,  1.04s/it]191it [04:21,  1.24it/s]192it [04:21,  1.51it/s]193it [04:21,  1.84it/s]194it [04:22,  2.13it/s]195it [04:22,  2.21it/s]196it [04:22,  2.21it/s]197it [04:23,  2.47it/s]198it [04:23,  2.58it/s]199it [04:23,  2.75it/s]200it [04:24,  2.00it/s]201it [04:25,  2.24it/s]202it [04:25,  2.54it/s]203it [04:25,  2.79it/s]204it [04:26,  2.59it/s]205it [04:26,  1.92it/s]206it [04:27,  2.15it/s]207it [04:27,  2.49it/s]208it [04:27,  2.65it/s]209it [04:28,  2.95it/s]210it [04:28,  3.16it/s]211it [04:28,  3.06it/s]212it [04:29,  2.98it/s]213it [04:29,  2.69it/s]214it [04:29,  3.10it/s]215it [04:30,  3.12it/s]216it [04:30,  3.46it/s]217it [04:30,  2.50it/s]218it [04:32,  1.59it/s]219it [04:33,  1.16it/s]220it [04:34,  1.07it/s]221it [04:34,  1.45it/s]223it [04:35,  2.11it/s]224it [04:36,  1.64it/s]225it [04:37,  1.40it/s]226it [04:38,  1.28it/s]227it [04:39,  1.17it/s]228it [04:40,  1.13it/s]229it [04:40,  1.13it/s]230it [04:41,  1.16it/s]231it [04:43,  1.07s/it]232it [04:44,  1.17s/it]233it [04:46,  1.28s/it]234it [04:47,  1.33s/it]235it [04:49,  1.36s/it]236it [04:50,  1.45s/it]237it [04:52,  1.46s/it]238it [04:53,  1.45s/it]239it [04:55,  1.45s/it]240it [04:56,  1.55s/it]241it [04:58,  1.57s/it]242it [05:00,  1.56s/it]243it [05:01,  1.53s/it]244it [05:03,  1.56s/it]245it [05:04,  1.54s/it]246it [05:06,  1.51s/it]247it [05:07,  1.54s/it]248it [05:09,  1.56s/it]249it [05:10,  1.57s/it]250it [05:12,  1.58s/it]251it [05:14,  1.55s/it]252it [05:15,  1.54s/it]253it [05:17,  1.54s/it]254it [05:18,  1.48s/it]255it [05:19,  1.45s/it]256it [05:21,  1.48s/it]257it [05:22,  1.44s/it]258it [05:23,  1.39s/it]259it [05:24,  1.27s/it]260it [05:25,  1.17s/it]261it [05:26,  1.03s/it]262it [05:27,  1.04it/s]263it [05:28,  1.03s/it]264it [05:29,  1.06s/it]265it [05:30,  1.08s/it]266it [05:31,  1.06s/it]267it [05:32,  1.25it/s]268it [05:32,  1.60it/s]269it [05:32,  1.80it/s]270it [05:33,  1.50it/s]271it [05:33,  1.74it/s]272it [05:34,  2.19it/s]273it [05:34,  2.64it/s]274it [05:34,  2.96it/s]275it [05:34,  3.14it/s]276it [05:35,  3.12it/s]277it [05:35,  3.20it/s]278it [05:35,  3.71it/s]279it [05:35,  3.91it/s]280it [05:36,  3.31it/s]281it [05:36,  2.78it/s]282it [05:36,  3.31it/s]283it [05:37,  3.12it/s]284it [05:37,  2.82it/s]285it [05:38,  1.85it/s]286it [05:39,  2.12it/s]287it [05:39,  2.54it/s]288it [05:39,  2.33it/s]289it [05:40,  2.59it/s]290it [05:40,  2.47it/s]291it [05:41,  2.23it/s]292it [05:41,  2.25it/s]293it [05:42,  1.85it/s]294it [05:42,  1.66it/s]295it [05:43,  1.72it/s]296it [05:44,  1.77it/s]297it [05:45,  1.41it/s]298it [05:45,  1.64it/s]299it [05:45,  1.73it/s]300it [05:46,  1.77it/s]301it [05:47,  1.60it/s]302it [05:47,  1.57it/s]303it [05:48,  1.71it/s]304it [05:48,  1.87it/s]305it [05:48,  2.39it/s]306it [05:49,  2.79it/s]306it [05:49,  1.14s/it]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:05<02:22,  5.95s/it]  8%|▊         | 2/25 [00:06<00:59,  2.57s/it] 12%|█▏        | 3/25 [00:06<00:32,  1.49s/it] 16%|█▌        | 4/25 [00:06<00:20,  1.02it/s] 20%|██        | 5/25 [00:06<00:14,  1.42it/s] 24%|██▍       | 6/25 [00:06<00:10,  1.88it/s] 28%|██▊       | 7/25 [00:07<00:07,  2.35it/s] 32%|███▏      | 8/25 [00:07<00:06,  2.81it/s] 36%|███▌      | 9/25 [00:07<00:04,  3.24it/s] 40%|████      | 10/25 [00:07<00:04,  3.61it/s] 44%|████▍     | 11/25 [00:08<00:03,  3.92it/s] 48%|████▊     | 12/25 [00:08<00:03,  4.16it/s] 52%|█████▏    | 13/25 [00:08<00:02,  4.34it/s] 56%|█████▌    | 14/25 [00:08<00:02,  4.48it/s] 60%|██████    | 15/25 [00:08<00:02,  4.58it/s] 64%|██████▍   | 16/25 [00:09<00:01,  4.65it/s] 68%|██████▊   | 17/25 [00:09<00:01,  4.71it/s] 72%|███████▏  | 18/25 [00:09<00:01,  4.75it/s] 76%|███████▌  | 19/25 [00:09<00:01,  4.77it/s] 80%|████████  | 20/25 [00:09<00:01,  4.77it/s] 84%|████████▍ | 21/25 [00:10<00:00,  4.74it/s] 88%|████████▊ | 22/25 [00:10<00:00,  4.77it/s] 92%|█████████▏| 23/25 [00:10<00:00,  4.79it/s] 96%|█████████▌| 24/25 [00:10<00:00,  4.81it/s]100%|██████████| 25/25 [00:10<00:00,  2.28it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:05<02:23,  5.98s/it]  8%|▊         | 2/25 [00:06<00:59,  2.58s/it] 12%|█▏        | 3/25 [00:06<00:32,  1.50s/it] 16%|█▌        | 4/25 [00:06<00:21,  1.02s/it] 20%|██        | 5/25 [00:06<00:14,  1.38it/s] 24%|██▍       | 6/25 [00:07<00:10,  1.82it/s] 28%|██▊       | 7/25 [00:07<00:07,  2.29it/s] 32%|███▏      | 8/25 [00:07<00:06,  2.76it/s] 36%|███▌      | 9/25 [00:07<00:05,  3.19it/s] 40%|████      | 10/25 [00:07<00:04,  3.56it/s] 44%|████▍     | 11/25 [00:08<00:03,  3.87it/s] 48%|████▊     | 12/25 [00:08<00:03,  4.13it/s] 52%|█████▏    | 13/25 [00:08<00:02,  4.33it/s] 56%|█████▌    | 14/25 [00:08<00:02,  4.48it/s] 60%|██████    | 15/25 [00:08<00:02,  4.60it/s] 64%|██████▍   | 16/25 [00:09<00:01,  4.68it/s] 68%|██████▊   | 17/25 [00:09<00:01,  4.73it/s] 72%|███████▏  | 18/25 [00:09<00:01,  4.77it/s] 76%|███████▌  | 19/25 [00:09<00:01,  4.80it/s] 80%|████████  | 20/25 [00:09<00:01,  4.83it/s] 84%|████████▍ | 21/25 [00:10<00:00,  4.84it/s] 88%|████████▊ | 22/25 [00:10<00:00,  4.85it/s] 92%|█████████▏| 23/25 [00:10<00:00,  4.84it/s] 96%|█████████▌| 24/25 [00:10<00:00,  4.83it/s]100%|██████████| 25/25 [00:11<00:00,  2.26it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5102049112319946


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 62.17271100992031
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.98232140490667
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 60.345270303958785


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 51.02049255371094
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  2.08it/s]2it [00:00,  2.13it/s]3it [00:01,  2.19it/s]4it [00:01,  2.69it/s]5it [00:02,  2.61it/s]6it [00:02,  2.19it/s]7it [00:03,  1.47it/s]8it [00:04,  1.61it/s]9it [00:04,  1.92it/s]10it [00:04,  2.03it/s]11it [00:05,  2.35it/s]13it [00:05,  3.76it/s]15it [00:05,  5.06it/s]17it [00:05,  6.18it/s]18it [00:05,  6.54it/s]20it [00:06,  7.78it/s]22it [00:06,  8.44it/s]24it [00:06,  9.36it/s]26it [00:06, 10.13it/s]28it [00:06, 10.26it/s]30it [00:07, 10.26it/s]32it [00:07, 10.04it/s]34it [00:07, 10.28it/s]36it [00:07, 10.13it/s]38it [00:07, 10.22it/s]40it [00:07, 10.45it/s]42it [00:08, 10.63it/s]44it [00:08, 11.33it/s]46it [00:08, 11.80it/s]48it [00:08, 11.78it/s]50it [00:08, 12.17it/s]52it [00:08, 12.07it/s]54it [00:09, 11.58it/s]56it [00:09, 11.35it/s]58it [00:09, 11.70it/s]60it [00:09, 11.85it/s]62it [00:09, 12.24it/s]64it [00:09, 12.24it/s]66it [00:10, 11.57it/s]68it [00:10, 11.42it/s]70it [00:10, 11.63it/s]72it [00:10, 11.12it/s]74it [00:10, 11.37it/s]76it [00:11, 10.57it/s]78it [00:11, 10.13it/s]80it [00:11, 10.03it/s]82it [00:11, 10.36it/s]84it [00:11, 10.42it/s]86it [00:12,  7.65it/s]87it [00:12,  7.91it/s]89it [00:12,  7.65it/s]90it [00:12,  7.90it/s]92it [00:13,  8.24it/s]93it [00:13,  8.22it/s]95it [00:13,  8.81it/s]96it [00:13,  9.01it/s]97it [00:13,  8.34it/s]99it [00:13, 10.02it/s]101it [00:13,  9.99it/s]103it [00:14, 10.32it/s]105it [00:14,  9.83it/s]106it [00:14,  4.99it/s]107it [00:15,  4.95it/s]108it [00:15,  4.82it/s]110it [00:15,  6.18it/s]112it [00:15,  7.36it/s]114it [00:15,  8.39it/s]115it [00:16,  8.66it/s]116it [00:16,  8.71it/s]118it [00:16,  9.77it/s]120it [00:16,  9.92it/s]122it [00:16, 10.21it/s]124it [00:16, 10.02it/s]126it [00:17,  9.87it/s]127it [00:17,  9.54it/s]129it [00:17, 10.39it/s]131it [00:17, 10.03it/s]133it [00:17,  9.64it/s]134it [00:17,  9.61it/s]136it [00:18, 10.16it/s]138it [00:18,  9.57it/s]140it [00:18,  9.84it/s]141it [00:18,  9.83it/s]143it [00:18, 10.06it/s]145it [00:19, 10.29it/s]147it [00:19, 10.62it/s]149it [00:19, 11.53it/s]151it [00:19, 12.23it/s]153it [00:19, 12.67it/s]155it [00:19, 12.95it/s]157it [00:19, 12.55it/s]159it [00:20, 11.45it/s]161it [00:20, 11.06it/s]163it [00:20, 10.26it/s]165it [00:20, 10.85it/s]167it [00:20, 11.64it/s]169it [00:21, 11.76it/s]171it [00:21, 11.56it/s]173it [00:21, 11.41it/s]175it [00:21,  9.88it/s]177it [00:21,  9.23it/s]179it [00:22,  9.69it/s]181it [00:22, 10.52it/s]183it [00:22, 11.51it/s]185it [00:22, 11.84it/s]187it [00:22, 12.24it/s]189it [00:22, 11.96it/s]191it [00:23, 11.99it/s]193it [00:23, 11.73it/s]195it [00:23, 12.48it/s]197it [00:23, 11.58it/s]199it [00:23,  9.81it/s]201it [00:24,  9.63it/s]203it [00:24,  9.52it/s]204it [00:24,  9.58it/s]206it [00:24,  9.78it/s]208it [00:24,  9.72it/s]210it [00:24,  9.51it/s]211it [00:25,  9.40it/s]213it [00:25,  9.62it/s]214it [00:25,  9.23it/s]216it [00:25,  9.50it/s]218it [00:25, 10.21it/s]220it [00:25, 10.43it/s]222it [00:26, 10.40it/s]224it [00:26, 10.62it/s]226it [00:26,  9.98it/s]228it [00:26,  9.47it/s]229it [00:27,  5.56it/s]230it [00:27,  5.95it/s]231it [00:27,  6.27it/s]232it [00:27,  6.82it/s]233it [00:27,  6.52it/s]234it [00:28,  4.78it/s]235it [00:28,  3.92it/s]236it [00:28,  3.46it/s]237it [00:29,  3.39it/s]238it [00:29,  2.93it/s]239it [00:30,  2.77it/s]240it [00:30,  2.99it/s]241it [00:30,  3.28it/s]242it [00:30,  3.38it/s]243it [00:31,  3.54it/s]244it [00:31,  3.43it/s]245it [00:31,  3.14it/s]246it [00:32,  3.15it/s]247it [00:32,  2.97it/s]248it [00:32,  3.16it/s]249it [00:33,  3.18it/s]250it [00:33,  2.59it/s]251it [00:34,  2.58it/s]252it [00:34,  2.41it/s]253it [00:34,  2.40it/s]254it [00:35,  2.33it/s]255it [00:35,  2.48it/s]256it [00:36,  2.18it/s]257it [00:36,  2.29it/s]258it [00:36,  2.72it/s]259it [00:37,  3.09it/s]260it [00:37,  3.34it/s]261it [00:37,  3.39it/s]262it [00:37,  3.97it/s]263it [00:38,  3.89it/s]264it [00:38,  3.96it/s]265it [00:38,  4.02it/s]266it [00:38,  4.40it/s]267it [00:39,  4.01it/s]268it [00:39,  3.80it/s]269it [00:39,  3.69it/s]270it [00:39,  4.38it/s]271it [00:40,  3.84it/s]272it [00:40,  4.05it/s]273it [00:40,  4.06it/s]274it [00:40,  4.28it/s]275it [00:41,  4.57it/s]276it [00:41,  4.56it/s]277it [00:41,  4.79it/s]278it [00:41,  3.92it/s]279it [00:42,  3.95it/s]280it [00:42,  3.66it/s]281it [00:42,  3.48it/s]282it [00:42,  3.67it/s]283it [00:43,  3.50it/s]284it [00:43,  3.31it/s]285it [00:43,  3.56it/s]286it [00:43,  3.96it/s]287it [00:44,  3.98it/s]288it [00:45,  2.42it/s]289it [00:45,  2.23it/s]290it [00:45,  2.27it/s]291it [00:46,  2.07it/s]292it [00:46,  2.15it/s]293it [00:47,  2.28it/s]294it [00:47,  2.43it/s]295it [00:48,  2.53it/s]296it [00:48,  2.92it/s]297it [00:48,  3.31it/s]298it [00:48,  3.46it/s]299it [00:49,  2.88it/s]300it [00:49,  2.72it/s]301it [00:49,  2.85it/s]302it [00:50,  2.48it/s]303it [00:50,  2.42it/s]304it [00:51,  2.56it/s]305it [00:51,  2.55it/s]306it [00:52,  2.61it/s]306it [00:52,  5.88it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:42,  4.28s/it]  8%|▊         | 2/25 [00:05<00:50,  2.19s/it] 12%|█▏        | 3/25 [00:05<00:28,  1.28s/it] 16%|█▌        | 4/25 [00:05<00:17,  1.17it/s] 20%|██        | 5/25 [00:05<00:12,  1.61it/s] 24%|██▍       | 6/25 [00:05<00:09,  2.09it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.57it/s] 32%|███▏      | 8/25 [00:06<00:05,  3.02it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.43it/s] 40%|████      | 10/25 [00:06<00:03,  3.78it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.07it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.29it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.46it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.58it/s] 60%|██████    | 15/25 [00:07<00:02,  4.67it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.73it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.78it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.82it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.84it/s] 80%|████████  | 20/25 [00:08<00:01,  4.86it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.88it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.89it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.88it/s]100%|██████████| 25/25 [00:09<00:00,  2.57it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288027763367
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:05<02:05,  5.24s/it]  8%|▊         | 2/25 [00:05<00:52,  2.28s/it] 12%|█▏        | 3/25 [00:05<00:29,  1.33s/it] 16%|█▌        | 4/25 [00:05<00:18,  1.13it/s] 20%|██        | 5/25 [00:06<00:12,  1.56it/s] 24%|██▍       | 6/25 [00:06<00:09,  2.03it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.51it/s] 32%|███▏      | 8/25 [00:06<00:05,  2.98it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.39it/s] 40%|████      | 10/25 [00:07<00:03,  3.75it/s] 44%|████▍     | 11/25 [00:07<00:03,  4.05it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.28it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.45it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.58it/s] 60%|██████    | 15/25 [00:08<00:02,  4.68it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.75it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.79it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.83it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.84it/s] 80%|████████  | 20/25 [00:09<00:01,  4.87it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.89it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.89it/s]100%|██████████| 25/25 [00:10<00:00,  2.46it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5103113055229187


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.81288146972656
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 61.619775573263944
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.6583828239377
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 58.83699168834403


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 51.031131744384766
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.10s/it]2it [00:02,  1.09s/it]3it [00:03,  1.07s/it]4it [00:04,  1.09s/it]5it [00:05,  1.08s/it]6it [00:06,  1.07s/it]7it [00:07,  1.04s/it]8it [00:08,  1.00it/s]9it [00:09,  1.01s/it]10it [00:10,  1.02s/it]11it [00:11,  1.03s/it]12it [00:12,  1.03it/s]13it [00:13,  1.04it/s]14it [00:14,  1.03it/s]15it [00:15,  1.00s/it]16it [00:16,  1.08it/s]17it [00:17,  1.01it/s]18it [00:18,  1.03it/s]19it [00:19,  1.01it/s]20it [00:20,  1.01it/s]21it [00:21,  1.02s/it]22it [00:22,  1.07s/it]23it [00:23,  1.02s/it]24it [00:24,  1.01s/it]25it [00:25,  1.00s/it]26it [00:26,  1.02s/it]27it [00:27,  1.07s/it]28it [00:28,  1.07s/it]29it [00:29,  1.06s/it]30it [00:30,  1.04s/it]31it [00:31,  1.08s/it]32it [00:32,  1.06s/it]33it [00:33,  1.04s/it]34it [00:34,  1.02s/it]35it [00:35,  1.02it/s]36it [00:36,  1.14it/s]37it [00:37,  1.13it/s]38it [00:38,  1.06it/s]39it [00:39,  1.05it/s]40it [00:39,  1.17it/s]41it [00:40,  1.21it/s]42it [00:41,  1.14it/s]43it [00:42,  1.08it/s]44it [00:43,  1.05it/s]45it [00:44,  1.07it/s]46it [00:45,  1.00it/s]47it [00:46,  1.01s/it]48it [00:47,  1.05s/it]49it [00:49,  1.07s/it]50it [00:49,  1.22it/s]51it [00:49,  1.49it/s]52it [00:50,  1.59it/s]53it [00:50,  1.71it/s]54it [00:50,  1.96it/s]55it [00:51,  2.50it/s]56it [00:51,  2.33it/s]57it [00:52,  2.14it/s]58it [00:52,  2.13it/s]59it [00:53,  1.76it/s]60it [00:54,  1.61it/s]61it [00:54,  1.67it/s]62it [00:55,  1.81it/s]63it [00:55,  1.93it/s]64it [00:56,  1.91it/s]65it [00:56,  2.26it/s]66it [00:56,  2.23it/s]67it [00:57,  2.29it/s]68it [00:57,  2.03it/s]69it [00:58,  1.81it/s]70it [00:59,  1.60it/s]71it [00:59,  1.85it/s]72it [01:00,  1.90it/s]73it [01:00,  2.05it/s]74it [01:00,  2.34it/s]75it [01:01,  2.46it/s]76it [01:01,  2.89it/s]77it [01:01,  2.63it/s]78it [01:02,  2.28it/s]79it [01:02,  2.29it/s]80it [01:03,  2.47it/s]81it [01:03,  2.81it/s]82it [01:03,  3.04it/s]83it [01:04,  2.77it/s]84it [01:04,  2.85it/s]85it [01:04,  3.28it/s]86it [01:04,  3.92it/s]88it [01:05,  5.68it/s]90it [01:05,  7.12it/s]92it [01:05,  8.65it/s]93it [01:05,  8.85it/s]95it [01:05,  9.42it/s]97it [01:05,  9.76it/s]99it [01:06, 10.71it/s]101it [01:06, 11.23it/s]103it [01:06, 11.69it/s]105it [01:06, 11.79it/s]107it [01:06, 10.88it/s]109it [01:06, 11.11it/s]111it [01:07, 11.60it/s]113it [01:07, 11.89it/s]115it [01:07, 11.47it/s]117it [01:07, 12.25it/s]119it [01:07, 12.46it/s]121it [01:07, 12.34it/s]123it [01:07, 12.45it/s]125it [01:08, 11.91it/s]127it [01:08, 11.74it/s]129it [01:08, 12.18it/s]131it [01:08, 12.62it/s]133it [01:08, 12.00it/s]135it [01:08, 12.53it/s]137it [01:09, 12.80it/s]139it [01:09, 12.58it/s]141it [01:09, 12.73it/s]143it [01:09, 12.25it/s]145it [01:09, 12.12it/s]147it [01:09, 12.76it/s]149it [01:10, 13.63it/s]151it [01:10, 12.99it/s]153it [01:10, 12.01it/s]155it [01:10, 11.61it/s]157it [01:10, 11.09it/s]159it [01:11, 10.52it/s]161it [01:11, 10.32it/s]163it [01:11, 10.21it/s]165it [01:11, 10.57it/s]167it [01:11, 10.41it/s]169it [01:12,  8.82it/s]171it [01:12,  9.80it/s]173it [01:12, 10.34it/s]175it [01:13,  5.07it/s]176it [01:13,  5.52it/s]177it [01:13,  5.91it/s]178it [01:13,  6.15it/s]179it [01:13,  6.61it/s]180it [01:13,  7.20it/s]181it [01:13,  7.60it/s]182it [01:14,  8.09it/s]183it [01:14,  8.03it/s]185it [01:14,  8.95it/s]186it [01:14,  8.66it/s]187it [01:14,  8.93it/s]189it [01:14,  8.85it/s]190it [01:14,  8.95it/s]191it [01:15,  9.02it/s]192it [01:15,  9.17it/s]193it [01:15,  9.33it/s]194it [01:15,  9.32it/s]195it [01:15,  8.97it/s]197it [01:15,  9.50it/s]198it [01:15,  9.32it/s]199it [01:15,  9.41it/s]201it [01:16,  9.85it/s]203it [01:16, 10.53it/s]205it [01:16, 11.00it/s]207it [01:16, 11.75it/s]209it [01:16, 11.49it/s]211it [01:16, 11.19it/s]213it [01:17, 11.13it/s]215it [01:17, 11.33it/s]217it [01:17, 12.04it/s]219it [01:17, 12.62it/s]221it [01:17, 12.31it/s]223it [01:17, 12.80it/s]225it [01:18, 13.14it/s]227it [01:18, 12.78it/s]229it [01:18, 13.56it/s]231it [01:18, 13.48it/s]233it [01:18, 13.79it/s]235it [01:18, 13.85it/s]237it [01:18, 12.98it/s]239it [01:19, 13.72it/s]241it [01:19, 13.61it/s]243it [01:19, 13.44it/s]245it [01:19, 12.89it/s]247it [01:19, 11.74it/s]249it [01:19, 11.37it/s]251it [01:20, 11.89it/s]253it [01:20, 12.93it/s]255it [01:20, 12.99it/s]257it [01:20, 12.27it/s]259it [01:20, 11.09it/s]261it [01:20, 11.21it/s]263it [01:21, 10.71it/s]265it [01:21, 10.68it/s]267it [01:21, 10.82it/s]269it [01:21, 11.00it/s]271it [01:21, 11.35it/s]273it [01:22, 11.29it/s]275it [01:22, 11.24it/s]277it [01:22, 11.40it/s]279it [01:22, 11.19it/s]281it [01:22,  8.30it/s]283it [01:23,  7.81it/s]284it [01:23,  7.86it/s]285it [01:23,  8.10it/s]287it [01:23,  9.20it/s]289it [01:23,  9.64it/s]290it [01:23,  9.51it/s]291it [01:24,  9.32it/s]293it [01:24,  9.43it/s]294it [01:24,  9.45it/s]296it [01:24,  9.99it/s]297it [01:24,  8.05it/s]298it [01:25,  4.65it/s]299it [01:25,  5.27it/s]301it [01:25,  6.85it/s]302it [01:25,  7.27it/s]303it [01:25,  6.83it/s]304it [01:26,  5.89it/s]305it [01:26,  5.46it/s]306it [01:26,  4.16it/s]306it [01:26,  3.53it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:59,  4.97s/it]  8%|▊         | 2/25 [00:05<00:49,  2.17s/it] 12%|█▏        | 3/25 [00:05<00:27,  1.27s/it] 16%|█▌        | 4/25 [00:05<00:17,  1.18it/s] 20%|██        | 5/25 [00:05<00:12,  1.62it/s] 24%|██▍       | 6/25 [00:05<00:09,  2.09it/s] 28%|██▊       | 7/25 [00:06<00:06,  2.58it/s] 32%|███▏      | 8/25 [00:06<00:05,  3.03it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.44it/s] 40%|████      | 10/25 [00:06<00:03,  3.79it/s] 44%|████▍     | 11/25 [00:07<00:03,  4.08it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.30it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.47it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.59it/s] 60%|██████    | 15/25 [00:07<00:02,  4.68it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.75it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.81it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.84it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.86it/s] 80%|████████  | 20/25 [00:08<00:01,  4.88it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.90it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.90it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.91it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.91it/s]100%|██████████| 25/25 [00:09<00:00,  2.53it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:06<02:40,  6.70s/it]  8%|▊         | 2/25 [00:06<01:06,  2.88s/it] 12%|█▏        | 3/25 [00:07<00:36,  1.66s/it] 16%|█▌        | 4/25 [00:07<00:22,  1.08s/it] 20%|██        | 5/25 [00:07<00:15,  1.30it/s] 24%|██▍       | 6/25 [00:07<00:11,  1.63it/s] 28%|██▊       | 7/25 [00:08<00:08,  2.09it/s] 32%|███▏      | 8/25 [00:08<00:06,  2.56it/s] 36%|███▌      | 9/25 [00:08<00:05,  3.01it/s] 40%|████      | 10/25 [00:08<00:04,  3.41it/s] 44%|████▍     | 11/25 [00:08<00:03,  3.76it/s] 48%|████▊     | 12/25 [00:09<00:03,  4.05it/s] 52%|█████▏    | 13/25 [00:09<00:02,  4.28it/s] 56%|█████▌    | 14/25 [00:09<00:02,  4.45it/s] 60%|██████    | 15/25 [00:09<00:02,  4.58it/s] 64%|██████▍   | 16/25 [00:09<00:01,  4.67it/s] 68%|██████▊   | 17/25 [00:10<00:01,  4.73it/s] 72%|███████▏  | 18/25 [00:10<00:01,  4.77it/s] 76%|███████▌  | 19/25 [00:10<00:01,  4.81it/s] 80%|████████  | 20/25 [00:10<00:01,  4.83it/s] 84%|████████▍ | 21/25 [00:10<00:00,  4.85it/s] 88%|████████▊ | 22/25 [00:11<00:00,  4.86it/s] 92%|█████████▏| 23/25 [00:11<00:00,  4.88it/s] 96%|█████████▌| 24/25 [00:11<00:00,  4.89it/s]100%|██████████| 25/25 [00:11<00:00,  2.13it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5098763108253479


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 61.13189136444951
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.78926279471953
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 59.24737873740703


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 50.987632751464844
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.80s/it]2it [00:03,  1.78s/it]3it [00:05,  1.81s/it]4it [00:07,  1.85s/it]5it [00:09,  1.86s/it]6it [00:11,  1.84s/it]7it [00:12,  1.87s/it]8it [00:14,  1.87s/it]9it [00:16,  1.82s/it]10it [00:18,  1.86s/it]11it [00:20,  1.83s/it]12it [00:21,  1.68s/it]13it [00:22,  1.44s/it]14it [00:23,  1.27s/it]15it [00:24,  1.21s/it]16it [00:25,  1.08s/it]17it [00:26,  1.09s/it]18it [00:27,  1.09s/it]19it [00:28,  1.16s/it]20it [00:29,  1.09s/it]21it [00:30,  1.03s/it]22it [00:31,  1.02it/s]23it [00:32,  1.03it/s]24it [00:33,  1.01it/s]25it [00:34,  1.00it/s]26it [00:35,  1.05s/it]27it [00:36,  1.04it/s]28it [00:37,  1.06it/s]29it [00:38,  1.08it/s]30it [00:38,  1.11it/s]31it [00:39,  1.13it/s]32it [00:40,  1.15it/s]33it [00:41,  1.15it/s]34it [00:42,  1.12it/s]35it [00:43,  1.12it/s]36it [00:44,  1.13it/s]37it [00:45,  1.11it/s]38it [00:45,  1.12it/s]39it [00:46,  1.15it/s]40it [00:47,  1.09it/s]41it [00:49,  1.20s/it]42it [00:51,  1.38s/it]43it [00:53,  1.47s/it]44it [00:54,  1.57s/it]45it [00:56,  1.63s/it]46it [00:58,  1.67s/it]47it [01:00,  1.76s/it]48it [01:02,  1.78s/it]49it [01:04,  1.77s/it]50it [01:05,  1.79s/it]51it [01:07,  1.82s/it]52it [01:09,  1.84s/it]53it [01:11,  1.84s/it]54it [01:13,  1.84s/it]55it [01:15,  1.87s/it]56it [01:17,  1.86s/it]57it [01:19,  1.87s/it]58it [01:20,  1.84s/it]59it [01:22,  1.80s/it]60it [01:24,  1.80s/it]61it [01:26,  1.80s/it]62it [01:27,  1.81s/it]63it [01:29,  1.77s/it]64it [01:31,  1.77s/it]65it [01:33,  1.75s/it]66it [01:34,  1.71s/it]67it [01:35,  1.51s/it]68it [01:36,  1.32s/it]69it [01:37,  1.16s/it]70it [01:38,  1.05s/it]71it [01:39,  1.02s/it]72it [01:39,  1.09it/s]73it [01:40,  1.19it/s]74it [01:41,  1.00it/s]75it [01:42,  1.09it/s]76it [01:43,  1.08it/s]77it [01:44,  1.12it/s]78it [01:45,  1.10it/s]79it [01:46,  1.09it/s]80it [01:47,  1.08it/s]81it [01:48,  1.05it/s]82it [01:49,  1.06s/it]83it [01:50,  1.07s/it]84it [01:51,  1.05s/it]85it [01:52,  1.08s/it]86it [01:53,  1.05s/it]87it [01:54,  1.02s/it]88it [01:55,  1.01s/it]89it [01:56,  1.03it/s]90it [01:57,  1.04it/s]91it [01:58,  1.02it/s]92it [01:59,  1.01it/s]93it [02:00,  1.04it/s]94it [02:01,  1.03s/it]95it [02:02,  1.07s/it]96it [02:04,  1.16s/it]97it [02:05,  1.19s/it]98it [02:06,  1.25s/it]99it [02:08,  1.41s/it]100it [02:10,  1.51s/it]101it [02:11,  1.56s/it]102it [02:13,  1.58s/it]103it [02:15,  1.61s/it]104it [02:17,  1.66s/it]105it [02:18,  1.56s/it]106it [02:19,  1.43s/it]107it [02:20,  1.37s/it]108it [02:21,  1.29s/it]109it [02:23,  1.30s/it]110it [02:24,  1.30s/it]111it [02:25,  1.23s/it]112it [02:26,  1.21s/it]113it [02:28,  1.26s/it]114it [02:29,  1.38s/it]115it [02:30,  1.32s/it]116it [02:32,  1.25s/it]117it [02:33,  1.17s/it]118it [02:34,  1.12s/it]119it [02:34,  1.07s/it]120it [02:35,  1.03s/it]121it [02:36,  1.15it/s]122it [02:36,  1.45it/s]123it [02:36,  1.76it/s]124it [02:37,  2.23it/s]125it [02:37,  2.83it/s]126it [02:37,  2.39it/s]127it [02:38,  2.37it/s]128it [02:38,  2.88it/s]129it [02:38,  3.27it/s]130it [02:38,  3.21it/s]131it [02:39,  2.59it/s]132it [02:40,  2.34it/s]133it [02:40,  1.91it/s]134it [02:41,  1.79it/s]135it [02:42,  1.62it/s]136it [02:42,  1.62it/s]137it [02:43,  1.73it/s]138it [02:43,  1.93it/s]139it [02:44,  1.84it/s]140it [02:45,  1.57it/s]141it [02:45,  1.93it/s]142it [02:45,  2.15it/s]143it [02:46,  2.18it/s]144it [02:46,  2.79it/s]145it [02:46,  3.20it/s]146it [02:46,  3.91it/s]148it [02:46,  5.17it/s]150it [02:47,  6.28it/s]151it [02:47,  6.06it/s]152it [02:47,  4.15it/s]153it [02:48,  3.38it/s]154it [02:48,  3.92it/s]155it [02:48,  4.29it/s]156it [02:49,  2.71it/s]157it [02:49,  3.27it/s]158it [02:49,  3.76it/s]159it [02:49,  3.74it/s]160it [02:50,  3.93it/s]161it [02:50,  3.18it/s]162it [02:50,  3.01it/s]163it [02:51,  3.25it/s]164it [02:51,  3.25it/s]165it [02:51,  3.52it/s]166it [02:51,  3.36it/s]167it [02:52,  3.63it/s]168it [02:52,  3.69it/s]169it [02:52,  2.93it/s]170it [02:53,  2.43it/s]171it [02:53,  2.66it/s]172it [02:54,  3.09it/s]173it [02:54,  2.51it/s]174it [02:55,  2.17it/s]175it [02:55,  2.44it/s]176it [02:55,  2.46it/s]177it [02:56,  2.26it/s]178it [02:57,  2.02it/s]179it [02:57,  1.93it/s]180it [02:58,  2.11it/s]181it [02:58,  2.23it/s]182it [02:58,  2.33it/s]183it [02:59,  2.57it/s]184it [02:59,  3.02it/s]185it [02:59,  3.14it/s]186it [03:00,  1.90it/s]187it [03:01,  1.45it/s]188it [03:02,  1.27it/s]189it [03:02,  1.72it/s]191it [03:03,  2.69it/s]192it [03:03,  3.07it/s]193it [03:03,  3.70it/s]194it [03:03,  3.80it/s]195it [03:03,  3.52it/s]196it [03:04,  3.66it/s]197it [03:04,  4.00it/s]198it [03:04,  4.22it/s]199it [03:04,  4.03it/s]200it [03:05,  3.77it/s]201it [03:05,  3.57it/s]202it [03:05,  3.29it/s]203it [03:05,  3.64it/s]204it [03:06,  4.13it/s]205it [03:06,  4.30it/s]206it [03:06,  4.55it/s]207it [03:06,  4.41it/s]209it [03:06,  6.46it/s]211it [03:07,  8.15it/s]213it [03:07,  9.35it/s]215it [03:07, 10.27it/s]217it [03:07, 11.11it/s]219it [03:07, 11.96it/s]221it [03:07, 12.63it/s]223it [03:07, 12.92it/s]225it [03:08, 13.22it/s]227it [03:08, 13.66it/s]229it [03:08, 13.69it/s]231it [03:08, 13.19it/s]233it [03:08, 13.64it/s]235it [03:08, 13.49it/s]237it [03:09, 13.05it/s]239it [03:09, 13.67it/s]241it [03:09, 13.48it/s]243it [03:09, 13.22it/s]245it [03:09, 13.78it/s]247it [03:09, 13.47it/s]249it [03:09, 13.28it/s]251it [03:10, 12.95it/s]253it [03:10, 13.23it/s]255it [03:10, 14.03it/s]257it [03:10, 13.83it/s]259it [03:10, 13.02it/s]261it [03:10, 11.75it/s]263it [03:11, 11.91it/s]265it [03:11, 12.17it/s]267it [03:11, 11.14it/s]269it [03:11, 11.98it/s]271it [03:11, 12.72it/s]273it [03:11, 13.24it/s]275it [03:12, 10.59it/s]277it [03:12, 10.75it/s]279it [03:12, 10.81it/s]281it [03:12, 11.20it/s]283it [03:12, 12.11it/s]285it [03:12, 12.81it/s]287it [03:13, 13.39it/s]289it [03:13, 13.25it/s]291it [03:13, 13.18it/s]293it [03:13, 13.12it/s]295it [03:13, 13.02it/s]297it [03:13, 13.23it/s]299it [03:13, 12.80it/s]301it [03:14, 12.38it/s]303it [03:14, 11.81it/s]305it [03:14, 11.54it/s]306it [03:14,  1.57it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:42,  4.27s/it]  8%|▊         | 2/25 [00:04<00:50,  2.18s/it] 12%|█▏        | 3/25 [00:05<00:28,  1.28s/it] 16%|█▌        | 4/25 [00:05<00:17,  1.17it/s] 20%|██        | 5/25 [00:05<00:12,  1.61it/s] 24%|██▍       | 6/25 [00:05<00:09,  2.09it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.57it/s] 32%|███▏      | 8/25 [00:06<00:05,  3.03it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.44it/s] 40%|████      | 10/25 [00:06<00:03,  3.78it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.06it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.28it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.45it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.57it/s] 60%|██████    | 15/25 [00:07<00:02,  4.66it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.73it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.78it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.82it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.84it/s] 80%|████████  | 20/25 [00:08<00:01,  4.86it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.89it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.90it/s]100%|██████████| 25/25 [00:09<00:00,  2.58it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:40,  4.18s/it]  8%|▊         | 2/25 [00:05<00:52,  2.28s/it] 12%|█▏        | 3/25 [00:05<00:29,  1.33s/it] 16%|█▌        | 4/25 [00:05<00:18,  1.13it/s] 20%|██        | 5/25 [00:05<00:12,  1.56it/s] 24%|██▍       | 6/25 [00:05<00:09,  2.03it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.51it/s] 32%|███▏      | 8/25 [00:06<00:05,  2.97it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.39it/s] 40%|████      | 10/25 [00:06<00:04,  3.75it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.04it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.27it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.44it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.57it/s] 60%|██████    | 15/25 [00:07<00:02,  4.67it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.74it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.79it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.83it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.85it/s] 80%|████████  | 20/25 [00:08<00:01,  4.87it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.90it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.90it/s]100%|██████████| 25/25 [00:09<00:00,  2.55it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5098724961280823


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 61.94503171247357
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 80.01080168212215
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 60.71133665069931


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 50.98725128173828
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  2.31it/s]2it [00:00,  2.01it/s]3it [00:01,  2.09it/s]4it [00:01,  2.19it/s]5it [00:02,  2.53it/s]6it [00:02,  2.31it/s]7it [00:03,  2.13it/s]8it [00:03,  1.92it/s]9it [00:04,  1.63it/s]10it [00:04,  2.07it/s]11it [00:05,  2.27it/s]12it [00:05,  2.25it/s]13it [00:06,  2.01it/s]14it [00:06,  2.43it/s]15it [00:06,  2.29it/s]16it [00:07,  2.25it/s]17it [00:08,  2.04it/s]18it [00:08,  1.94it/s]19it [00:09,  1.84it/s]20it [00:09,  1.88it/s]21it [00:10,  1.83it/s]22it [00:10,  1.81it/s]23it [00:11,  2.05it/s]24it [00:11,  1.92it/s]25it [00:12,  1.83it/s]26it [00:12,  1.93it/s]27it [00:13,  1.80it/s]28it [00:14,  1.74it/s]29it [00:14,  1.49it/s]30it [00:16,  1.23it/s]31it [00:17,  1.20it/s]32it [00:17,  1.40it/s]33it [00:17,  1.78it/s]34it [00:18,  1.44it/s]35it [00:19,  1.21it/s]36it [00:20,  1.10it/s]37it [00:21,  1.07it/s]38it [00:23,  1.01it/s]39it [00:24,  1.02s/it]40it [00:25,  1.04s/it]41it [00:26,  1.03s/it]42it [00:27,  1.06s/it]43it [00:28,  1.09s/it]44it [00:29,  1.07s/it]45it [00:30,  1.07s/it]46it [00:31,  1.11s/it]47it [00:33,  1.15s/it]48it [00:34,  1.11s/it]49it [00:35,  1.07s/it]50it [00:36,  1.08s/it]51it [00:37,  1.11s/it]52it [00:38,  1.11s/it]53it [00:39,  1.11s/it]54it [00:40,  1.04s/it]55it [00:41,  1.04it/s]56it [00:42,  1.04it/s]57it [00:43,  1.07it/s]58it [00:43,  1.24it/s]59it [00:43,  1.48it/s]60it [00:44,  1.64it/s]61it [00:44,  1.86it/s]62it [00:45,  2.13it/s]63it [00:45,  2.03it/s]64it [00:46,  1.99it/s]65it [00:46,  2.04it/s]66it [00:46,  2.34it/s]67it [00:47,  2.46it/s]68it [00:47,  2.18it/s]69it [00:48,  2.46it/s]70it [00:48,  2.15it/s]71it [00:49,  1.70it/s]72it [00:49,  1.95it/s]73it [00:50,  1.92it/s]74it [00:51,  1.85it/s]75it [00:51,  1.76it/s]76it [00:52,  1.89it/s]77it [00:52,  1.81it/s]78it [00:53,  1.75it/s]79it [00:53,  1.72it/s]80it [00:54,  1.68it/s]81it [00:55,  1.56it/s]82it [00:55,  1.53it/s]83it [00:56,  1.86it/s]84it [00:56,  2.08it/s]85it [00:57,  1.98it/s]86it [00:57,  2.22it/s]87it [00:58,  2.01it/s]88it [00:58,  1.86it/s]89it [00:59,  1.80it/s]90it [00:59,  2.19it/s]91it [00:59,  2.78it/s]92it [00:59,  2.90it/s]93it [01:00,  3.05it/s]94it [01:00,  2.65it/s]95it [01:01,  2.20it/s]96it [01:01,  2.05it/s]97it [01:02,  1.94it/s]98it [01:03,  1.88it/s]99it [01:03,  1.95it/s]100it [01:04,  1.82it/s]101it [01:04,  1.81it/s]102it [01:05,  1.86it/s]103it [01:05,  1.84it/s]104it [01:06,  1.47it/s]105it [01:07,  1.25it/s]106it [01:08,  1.17it/s]107it [01:09,  1.35it/s]108it [01:10,  1.25it/s]109it [01:11,  1.13it/s]110it [01:12,  1.05it/s]111it [01:13,  1.04it/s]112it [01:14,  1.04it/s]113it [01:15,  1.03it/s]114it [01:16,  1.01s/it]115it [01:17,  1.00it/s]116it [01:18,  1.00s/it]117it [01:19,  1.00it/s]118it [01:20,  1.01it/s]119it [01:21,  1.00s/it]120it [01:22,  1.01s/it]121it [01:23,  1.05s/it]122it [01:24,  1.09s/it]123it [01:26,  1.11s/it]124it [01:27,  1.12s/it]125it [01:28,  1.11s/it]126it [01:29,  1.08s/it]127it [01:30,  1.09s/it]128it [01:31,  1.06s/it]129it [01:32,  1.07s/it]130it [01:33,  1.07s/it]131it [01:34,  1.06s/it]132it [01:35,  1.04s/it]133it [01:36,  1.05s/it]134it [01:37,  1.16it/s]135it [01:37,  1.42it/s]136it [01:37,  1.49it/s]137it [01:38,  1.69it/s]138it [01:38,  1.72it/s]139it [01:39,  1.70it/s]140it [01:40,  1.74it/s]141it [01:40,  1.88it/s]142it [01:41,  1.76it/s]143it [01:41,  1.68it/s]144it [01:42,  1.76it/s]145it [01:43,  1.54it/s]146it [01:43,  1.76it/s]147it [01:43,  1.95it/s]148it [01:44,  2.04it/s]149it [01:44,  2.24it/s]150it [01:45,  2.13it/s]151it [01:45,  1.98it/s]152it [01:46,  1.86it/s]153it [01:47,  1.77it/s]154it [01:47,  1.69it/s]155it [01:48,  2.00it/s]156it [01:48,  2.55it/s]157it [01:48,  2.90it/s]158it [01:49,  2.11it/s]159it [01:49,  2.47it/s]160it [01:49,  2.54it/s]161it [01:49,  3.23it/s]162it [01:50,  3.14it/s]163it [01:50,  3.28it/s]164it [01:50,  3.80it/s]165it [01:51,  2.90it/s]166it [01:51,  2.48it/s]167it [01:52,  2.36it/s]168it [01:52,  2.06it/s]169it [01:53,  1.97it/s]170it [01:53,  1.91it/s]171it [01:54,  1.80it/s]172it [01:55,  1.75it/s]173it [01:55,  1.73it/s]174it [01:56,  1.68it/s]175it [01:56,  1.77it/s]176it [01:57,  1.69it/s]177it [01:58,  1.81it/s]178it [01:58,  1.81it/s]179it [01:59,  1.56it/s]180it [02:00,  1.36it/s]181it [02:01,  1.17it/s]182it [02:02,  1.32it/s]183it [02:03,  1.23it/s]184it [02:04,  1.04it/s]185it [02:05,  1.03it/s]186it [02:06,  1.05it/s]187it [02:07,  1.04it/s]188it [02:08,  1.01s/it]189it [02:09,  1.02s/it]190it [02:10,  1.04s/it]191it [02:11,  1.07s/it]192it [02:12,  1.10s/it]193it [02:13,  1.07s/it]194it [02:14,  1.06s/it]195it [02:15,  1.02s/it]196it [02:16,  1.22it/s]197it [02:16,  1.52it/s]198it [02:16,  1.82it/s]199it [02:16,  2.19it/s]200it [02:17,  2.41it/s]201it [02:17,  2.71it/s]202it [02:17,  3.40it/s]204it [02:17,  5.21it/s]206it [02:17,  6.94it/s]208it [02:18,  8.43it/s]210it [02:18,  9.78it/s]212it [02:18, 10.55it/s]214it [02:18, 11.40it/s]216it [02:18, 11.35it/s]218it [02:18, 12.25it/s]220it [02:18, 12.35it/s]222it [02:19, 12.67it/s]224it [02:19, 13.15it/s]226it [02:19, 12.75it/s]228it [02:19, 13.34it/s]230it [02:19, 13.56it/s]232it [02:19, 12.97it/s]234it [02:20, 13.61it/s]236it [02:20, 14.11it/s]238it [02:20, 13.99it/s]240it [02:20, 13.98it/s]242it [02:20, 13.17it/s]244it [02:20, 13.43it/s]246it [02:20, 13.41it/s]248it [02:21, 12.74it/s]250it [02:21, 12.96it/s]252it [02:21, 13.36it/s]254it [02:21, 13.60it/s]256it [02:21,  7.84it/s]258it [02:22,  8.41it/s]260it [02:22,  8.89it/s]262it [02:22,  9.70it/s]264it [02:22, 10.00it/s]266it [02:22, 10.09it/s]268it [02:23, 10.43it/s]270it [02:23, 10.95it/s]272it [02:23, 11.03it/s]274it [02:23, 11.03it/s]276it [02:23, 11.12it/s]278it [02:24, 10.84it/s]280it [02:24, 10.80it/s]282it [02:24, 11.13it/s]284it [02:24, 11.15it/s]286it [02:24, 11.50it/s]288it [02:24, 11.52it/s]290it [02:25, 11.39it/s]292it [02:25, 11.07it/s]294it [02:25, 10.67it/s]296it [02:25,  8.93it/s]298it [02:25,  9.72it/s]300it [02:26,  9.72it/s]302it [02:26,  9.98it/s]304it [02:26, 10.26it/s]306it [02:26,  9.69it/s]306it [02:26,  2.09it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:41,  4.21s/it]  8%|▊         | 2/25 [00:04<00:42,  1.85s/it] 12%|█▏        | 3/25 [00:05<00:29,  1.34s/it] 16%|█▌        | 4/25 [00:05<00:18,  1.12it/s] 20%|██        | 5/25 [00:05<00:12,  1.55it/s] 24%|██▍       | 6/25 [00:05<00:09,  2.02it/s] 28%|██▊       | 7/25 [00:05<00:07,  2.50it/s] 32%|███▏      | 8/25 [00:06<00:05,  2.96it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.38it/s] 40%|████      | 10/25 [00:06<00:04,  3.74it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.03it/s] 48%|████▊     | 12/25 [00:06<00:03,  4.26it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.44it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.57it/s] 60%|██████    | 15/25 [00:07<00:02,  4.67it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.74it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.79it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.83it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.85it/s] 80%|████████  | 20/25 [00:08<00:01,  4.87it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.89it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.90it/s]100%|██████████| 25/25 [00:09<00:00,  2.60it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:48,  4.53s/it]  8%|▊         | 2/25 [00:04<00:45,  1.98s/it] 12%|█▏        | 3/25 [00:04<00:25,  1.17s/it] 16%|█▌        | 4/25 [00:05<00:16,  1.27it/s] 20%|██        | 5/25 [00:05<00:11,  1.73it/s] 24%|██▍       | 6/25 [00:05<00:08,  2.22it/s] 28%|██▊       | 7/25 [00:05<00:06,  2.70it/s] 32%|███▏      | 8/25 [00:05<00:05,  3.15it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.54it/s] 40%|████      | 10/25 [00:06<00:03,  3.88it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.14it/s] 48%|████▊     | 12/25 [00:06<00:02,  4.35it/s] 52%|█████▏    | 13/25 [00:06<00:02,  4.50it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.61it/s] 60%|██████    | 15/25 [00:07<00:02,  4.70it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.76it/s] 68%|██████▊   | 17/25 [00:07<00:01,  4.81it/s] 72%|███████▏  | 18/25 [00:07<00:01,  4.84it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.86it/s] 80%|████████  | 20/25 [00:08<00:01,  4.88it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.90it/s] 88%|████████▊ | 22/25 [00:08<00:00,  4.90it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.91it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.91it/s]100%|██████████| 25/25 [00:09<00:00,  2.66it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.514397382736206


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 62.595543990892835
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 80.16456857484634
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 61.157683602105784


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 51.43973922729492
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  4.09it/s]2it [00:00,  4.94it/s]3it [00:00,  5.54it/s]4it [00:00,  4.27it/s]5it [00:01,  4.10it/s]6it [00:01,  3.71it/s]7it [00:01,  3.93it/s]8it [00:01,  4.48it/s]9it [00:02,  4.72it/s]10it [00:02,  4.57it/s]11it [00:02,  4.05it/s]12it [00:02,  4.72it/s]13it [00:02,  5.49it/s]14it [00:02,  6.13it/s]15it [00:03,  5.22it/s]16it [00:03,  4.45it/s]17it [00:03,  4.89it/s]18it [00:03,  4.32it/s]19it [00:04,  4.63it/s]20it [00:04,  4.97it/s]21it [00:04,  4.72it/s]22it [00:04,  4.03it/s]23it [00:05,  3.90it/s]24it [00:05,  4.17it/s]25it [00:05,  4.40it/s]26it [00:05,  4.70it/s]28it [00:05,  5.75it/s]29it [00:06,  5.76it/s]30it [00:06,  5.66it/s]31it [00:06,  4.95it/s]32it [00:06,  5.12it/s]33it [00:07,  4.82it/s]34it [00:07,  4.61it/s]35it [00:07,  3.98it/s]36it [00:07,  4.12it/s]37it [00:07,  4.54it/s]38it [00:08,  4.33it/s]39it [00:08,  4.49it/s]40it [00:08,  3.93it/s]41it [00:09,  3.98it/s]42it [00:09,  4.36it/s]43it [00:09,  4.32it/s]44it [00:09,  4.63it/s]45it [00:09,  4.12it/s]46it [00:10,  4.26it/s]47it [00:10,  4.11it/s]48it [00:10,  4.11it/s]49it [00:10,  3.96it/s]50it [00:11,  4.74it/s]51it [00:11,  4.93it/s]52it [00:11,  5.21it/s]53it [00:11,  5.44it/s]54it [00:11,  5.96it/s]55it [00:11,  6.07it/s]56it [00:12,  5.20it/s]57it [00:12,  5.54it/s]58it [00:12,  5.41it/s]59it [00:12,  5.02it/s]60it [00:13,  4.10it/s]61it [00:13,  4.65it/s]62it [00:13,  4.34it/s]63it [00:13,  3.82it/s]64it [00:13,  4.35it/s]65it [00:14,  4.00it/s]66it [00:14,  4.51it/s]67it [00:14,  4.96it/s]68it [00:14,  5.29it/s]69it [00:14,  5.77it/s]70it [00:15,  4.60it/s]71it [00:15,  4.62it/s]72it [00:15,  4.40it/s]73it [00:15,  5.08it/s]74it [00:15,  5.07it/s]75it [00:16,  4.86it/s]76it [00:16,  4.69it/s]77it [00:16,  4.67it/s]78it [00:16,  4.32it/s]79it [00:17,  3.65it/s]80it [00:17,  3.98it/s]81it [00:17,  3.91it/s]82it [00:17,  4.13it/s]83it [00:18,  4.50it/s]84it [00:18,  4.82it/s]85it [00:18,  5.58it/s]86it [00:18,  5.35it/s]88it [00:18,  7.36it/s]89it [00:18,  7.80it/s]90it [00:18,  7.69it/s]91it [00:19,  7.77it/s]92it [00:19,  7.91it/s]93it [00:19,  6.46it/s]94it [00:19,  4.61it/s]95it [00:20,  4.91it/s]96it [00:20,  4.75it/s]97it [00:20,  5.07it/s]98it [00:20,  4.76it/s]99it [00:20,  4.86it/s]100it [00:21,  4.34it/s]101it [00:21,  4.62it/s]102it [00:21,  4.65it/s]103it [00:21,  4.39it/s]104it [00:22,  4.05it/s]105it [00:22,  4.10it/s]106it [00:22,  4.01it/s]107it [00:22,  4.64it/s]108it [00:22,  4.70it/s]109it [00:23,  4.71it/s]110it [00:23,  4.62it/s]111it [00:23,  5.09it/s]112it [00:23,  4.99it/s]113it [00:23,  5.34it/s]114it [00:23,  5.98it/s]115it [00:24,  6.04it/s]116it [00:24,  3.40it/s]117it [00:25,  3.38it/s]118it [00:25,  4.07it/s]119it [00:25,  4.55it/s]120it [00:25,  4.31it/s]121it [00:26,  3.34it/s]122it [00:26,  3.13it/s]123it [00:26,  3.01it/s]124it [00:27,  2.93it/s]125it [00:27,  2.85it/s]126it [00:27,  3.19it/s]127it [00:28,  3.25it/s]128it [00:28,  3.37it/s]129it [00:28,  3.66it/s]130it [00:28,  3.17it/s]131it [00:29,  3.46it/s]132it [00:29,  2.88it/s]133it [00:30,  2.48it/s]134it [00:30,  2.92it/s]135it [00:30,  2.82it/s]136it [00:31,  2.36it/s]137it [00:31,  2.12it/s]138it [00:32,  2.13it/s]139it [00:32,  1.96it/s]140it [00:33,  1.89it/s]141it [00:34,  1.88it/s]142it [00:34,  2.01it/s]143it [00:34,  2.06it/s]144it [00:35,  1.98it/s]145it [00:36,  1.86it/s]146it [00:36,  1.96it/s]147it [00:37,  2.08it/s]148it [00:37,  2.00it/s]149it [00:37,  2.36it/s]150it [00:38,  2.37it/s]151it [00:38,  2.14it/s]152it [00:39,  2.16it/s]153it [00:39,  2.27it/s]154it [00:39,  2.53it/s]155it [00:40,  3.14it/s]156it [00:40,  3.76it/s]157it [00:40,  4.19it/s]158it [00:40,  3.28it/s]159it [00:41,  2.48it/s]160it [00:41,  2.81it/s]161it [00:42,  2.66it/s]162it [00:42,  3.03it/s]163it [00:42,  3.63it/s]164it [00:43,  2.86it/s]165it [00:43,  2.53it/s]166it [00:43,  2.62it/s]167it [00:44,  2.52it/s]168it [00:44,  2.50it/s]169it [00:45,  2.33it/s]170it [00:45,  2.24it/s]171it [00:46,  2.29it/s]172it [00:46,  2.50it/s]173it [00:46,  2.46it/s]174it [00:47,  2.12it/s]175it [00:48,  1.98it/s]176it [00:48,  2.00it/s]177it [00:48,  2.08it/s]178it [00:49,  2.05it/s]179it [00:49,  2.16it/s]180it [00:50,  2.11it/s]181it [00:50,  1.98it/s]182it [00:51,  1.88it/s]183it [00:52,  1.93it/s]184it [00:52,  1.79it/s]185it [00:53,  1.92it/s]186it [00:53,  1.87it/s]187it [00:54,  1.97it/s]189it [00:54,  3.22it/s]191it [00:54,  4.66it/s]193it [00:54,  6.00it/s]195it [00:54,  7.13it/s]197it [00:54,  7.96it/s]199it [00:55,  8.40it/s]201it [00:55,  9.09it/s]203it [00:55, 10.06it/s]205it [00:55, 10.49it/s]207it [00:55, 10.75it/s]209it [00:56, 11.11it/s]211it [00:56, 11.04it/s]213it [00:56, 10.83it/s]215it [00:56, 10.63it/s]217it [00:56, 10.81it/s]219it [00:56, 11.21it/s]221it [00:57, 11.20it/s]223it [00:57, 11.41it/s]225it [00:57, 11.49it/s]227it [00:57, 11.23it/s]229it [00:57, 11.48it/s]231it [00:58, 11.07it/s]233it [00:58, 11.26it/s]235it [00:58, 11.09it/s]237it [00:58, 10.72it/s]239it [00:58, 10.87it/s]241it [00:58, 10.81it/s]243it [00:59, 10.49it/s]245it [00:59, 10.79it/s]247it [00:59, 10.76it/s]249it [00:59, 10.69it/s]251it [00:59, 10.91it/s]253it [01:00, 11.15it/s]255it [01:00, 11.78it/s]257it [01:00, 11.40it/s]259it [01:00, 11.32it/s]261it [01:00, 11.41it/s]263it [01:00, 11.28it/s]265it [01:01, 11.28it/s]267it [01:01, 11.37it/s]269it [01:01, 11.28it/s]271it [01:01, 11.28it/s]273it [01:01, 11.28it/s]275it [01:01, 11.24it/s]277it [01:02, 11.00it/s]279it [01:02, 11.11it/s]281it [01:02, 11.30it/s]283it [01:02, 11.55it/s]285it [01:02, 11.96it/s]287it [01:02, 12.56it/s]289it [01:03, 13.11it/s]291it [01:03, 13.13it/s]293it [01:03, 12.92it/s]295it [01:03, 13.32it/s]297it [01:03, 13.79it/s]299it [01:03, 13.50it/s]301it [01:04, 13.12it/s]303it [01:04, 12.95it/s]305it [01:04, 13.44it/s]306it [01:04,  4.75it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:48,  4.51s/it]  8%|▊         | 2/25 [00:04<00:45,  1.98s/it] 12%|█▏        | 3/25 [00:04<00:25,  1.17s/it] 16%|█▌        | 4/25 [00:05<00:16,  1.27it/s] 20%|██        | 5/25 [00:05<00:11,  1.73it/s] 24%|██▍       | 6/25 [00:05<00:08,  2.21it/s] 28%|██▊       | 7/25 [00:05<00:06,  2.69it/s] 32%|███▏      | 8/25 [00:05<00:05,  3.14it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.54it/s] 40%|████      | 10/25 [00:06<00:03,  3.88it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.14it/s] 48%|████▊     | 12/25 [00:06<00:02,  4.35it/s] 52%|█████▏    | 13/25 [00:06<00:02,  4.51it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.62it/s] 60%|██████    | 15/25 [00:07<00:02,  4.71it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.77it/s] 68%|██████▊   | 17/25 [00:07<00:01,  4.81it/s] 72%|███████▏  | 18/25 [00:07<00:01,  4.85it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.87it/s] 80%|████████  | 20/25 [00:08<00:01,  4.88it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.89it/s] 88%|████████▊ | 22/25 [00:08<00:00,  4.90it/s] 92%|█████████▏| 23/25 [00:08<00:00,  4.90it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.91it/s]100%|██████████| 25/25 [00:09<00:00,  2.66it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:39,  4.14s/it]  8%|▊         | 2/25 [00:04<00:42,  1.83s/it] 12%|█▏        | 3/25 [00:04<00:23,  1.09s/it] 16%|█▌        | 4/25 [00:04<00:15,  1.36it/s] 20%|██        | 5/25 [00:04<00:10,  1.83it/s] 24%|██▍       | 6/25 [00:05<00:08,  2.33it/s] 28%|██▊       | 7/25 [00:05<00:06,  2.81it/s] 32%|███▏      | 8/25 [00:05<00:05,  3.25it/s] 36%|███▌      | 9/25 [00:05<00:04,  3.63it/s] 40%|████      | 10/25 [00:05<00:03,  3.95it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.20it/s] 48%|████▊     | 12/25 [00:06<00:02,  4.39it/s] 52%|█████▏    | 13/25 [00:06<00:02,  4.53it/s] 56%|█████▌    | 14/25 [00:06<00:02,  4.63it/s] 60%|██████    | 15/25 [00:07<00:02,  4.71it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.75it/s] 68%|██████▊   | 17/25 [00:07<00:01,  4.79it/s] 72%|███████▏  | 18/25 [00:07<00:01,  4.82it/s] 76%|███████▌  | 19/25 [00:07<00:01,  4.85it/s] 80%|████████  | 20/25 [00:08<00:01,  4.86it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.87it/s] 88%|████████▊ | 22/25 [00:08<00:00,  4.87it/s] 92%|█████████▏| 23/25 [00:08<00:00,  4.88it/s] 96%|█████████▌| 24/25 [00:08<00:00,  4.89it/s]100%|██████████| 25/25 [00:09<00:00,  2.76it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.5108917355537415


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 62.28655065864368
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.84762780511826
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 60.268990212278


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 51.08917236328125
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  4.69it/s]2it [00:00,  2.79it/s]3it [00:00,  3.59it/s]4it [00:01,  3.87it/s]5it [00:01,  4.48it/s]6it [00:01,  3.48it/s]7it [00:02,  2.61it/s]8it [00:02,  2.25it/s]9it [00:03,  2.08it/s]10it [00:03,  2.32it/s]11it [00:04,  2.01it/s]12it [00:04,  1.89it/s]13it [00:05,  1.79it/s]14it [00:05,  2.01it/s]15it [00:06,  2.48it/s]16it [00:06,  2.56it/s]17it [00:07,  2.21it/s]18it [00:07,  2.07it/s]19it [00:07,  2.61it/s]20it [00:07,  3.05it/s]21it [00:08,  3.54it/s]22it [00:08,  3.94it/s]23it [00:08,  3.47it/s]24it [00:09,  2.66it/s]25it [00:09,  2.27it/s]26it [00:10,  2.35it/s]27it [00:10,  2.38it/s]28it [00:11,  2.22it/s]29it [00:11,  2.06it/s]30it [00:12,  1.90it/s]31it [00:12,  1.89it/s]32it [00:13,  1.98it/s]33it [00:13,  1.88it/s]34it [00:14,  1.81it/s]35it [00:15,  1.82it/s]36it [00:15,  1.79it/s]37it [00:16,  1.87it/s]38it [00:16,  1.80it/s]39it [00:17,  1.95it/s]40it [00:17,  1.95it/s]41it [00:18,  2.00it/s]42it [00:18,  1.85it/s]43it [00:19,  1.79it/s]44it [00:20,  1.73it/s]45it [00:20,  1.66it/s]46it [00:21,  1.71it/s]47it [00:21,  1.71it/s]48it [00:22,  1.69it/s]49it [00:22,  1.72it/s]50it [00:23,  1.90it/s]51it [00:23,  1.85it/s]52it [00:24,  1.88it/s]53it [00:24,  2.13it/s]54it [00:25,  2.40it/s]55it [00:25,  2.16it/s]56it [00:25,  2.34it/s]57it [00:26,  2.45it/s]58it [00:26,  2.72it/s]59it [00:27,  2.37it/s]60it [00:27,  2.02it/s]61it [00:28,  2.11it/s]62it [00:28,  1.91it/s]63it [00:29,  1.93it/s]64it [00:29,  1.87it/s]65it [00:30,  1.82it/s]66it [00:31,  1.75it/s]67it [00:31,  1.89it/s]68it [00:32,  1.81it/s]69it [00:32,  1.91it/s]70it [00:33,  1.86it/s]71it [00:33,  2.30it/s]72it [00:33,  2.23it/s]73it [00:34,  2.01it/s]74it [00:35,  1.96it/s]75it [00:35,  1.89it/s]76it [00:36,  1.81it/s]77it [00:36,  1.75it/s]78it [00:37,  1.74it/s]79it [00:38,  1.71it/s]80it [00:38,  1.71it/s]81it [00:39,  1.77it/s]82it [00:39,  1.76it/s]83it [00:40,  1.72it/s]84it [00:40,  1.70it/s]85it [00:41,  1.69it/s]86it [00:42,  1.69it/s]87it [00:42,  1.70it/s]88it [00:43,  1.89it/s]89it [00:43,  1.80it/s]90it [00:44,  1.72it/s]91it [00:44,  1.71it/s]92it [00:45,  1.68it/s]93it [00:45,  1.93it/s]94it [00:46,  1.93it/s]95it [00:46,  1.92it/s]96it [00:47,  1.82it/s]97it [00:48,  1.77it/s]98it [00:48,  1.73it/s]99it [00:49,  1.83it/s]100it [00:49,  1.75it/s]101it [00:50,  1.93it/s]102it [00:50,  2.22it/s]103it [00:51,  2.01it/s]104it [00:51,  1.87it/s]105it [00:52,  2.26it/s]106it [00:52,  2.05it/s]107it [00:53,  2.09it/s]108it [00:53,  2.41it/s]109it [00:53,  2.25it/s]110it [00:54,  2.06it/s]111it [00:55,  1.95it/s]112it [00:55,  1.87it/s]113it [00:56,  1.83it/s]114it [00:56,  1.92it/s]115it [00:57,  1.93it/s]116it [00:57,  1.81it/s]117it [00:58,  1.85it/s]118it [00:58,  1.83it/s]119it [00:59,  1.95it/s]120it [00:59,  1.85it/s]121it [01:00,  1.77it/s]122it [01:01,  1.76it/s]123it [01:01,  1.88it/s]124it [01:01,  2.08it/s]125it [01:02,  1.90it/s]126it [01:03,  1.81it/s]127it [01:03,  1.88it/s]128it [01:03,  2.33it/s]129it [01:03,  2.90it/s]130it [01:04,  2.48it/s]131it [01:05,  2.20it/s]132it [01:05,  2.71it/s]133it [01:05,  3.14it/s]134it [01:05,  3.53it/s]135it [01:06,  2.66it/s]136it [01:06,  2.37it/s]137it [01:07,  2.16it/s]138it [01:07,  1.96it/s]139it [01:08,  1.82it/s]140it [01:09,  1.76it/s]141it [01:09,  1.97it/s]142it [01:10,  1.84it/s]143it [01:10,  1.78it/s]144it [01:11,  1.75it/s]145it [01:12,  1.73it/s]146it [01:12,  1.69it/s]147it [01:13,  1.67it/s]148it [01:13,  1.69it/s]149it [01:14,  1.69it/s]150it [01:14,  1.80it/s]151it [01:15,  1.81it/s]152it [01:15,  1.86it/s]153it [01:16,  2.11it/s]154it [01:16,  2.31it/s]155it [01:17,  2.03it/s]156it [01:17,  1.95it/s]157it [01:18,  1.85it/s]158it [01:18,  1.90it/s]159it [01:19,  2.01it/s]160it [01:19,  2.05it/s]161it [01:20,  2.11it/s]162it [01:20,  1.91it/s]163it [01:21,  2.00it/s]164it [01:21,  2.16it/s]165it [01:22,  2.17it/s]166it [01:22,  2.11it/s]167it [01:23,  1.91it/s]168it [01:23,  1.87it/s]169it [01:24,  1.78it/s]170it [01:25,  1.79it/s]171it [01:25,  1.75it/s]172it [01:25,  2.01it/s]173it [01:26,  2.01it/s]174it [01:27,  1.95it/s]175it [01:27,  2.41it/s]176it [01:27,  2.11it/s]177it [01:28,  1.92it/s]178it [01:29,  1.82it/s]179it [01:29,  1.80it/s]180it [01:30,  1.75it/s]181it [01:30,  1.77it/s]182it [01:31,  1.89it/s]183it [01:31,  1.83it/s]184it [01:32,  1.88it/s]185it [01:32,  2.16it/s]186it [01:33,  1.97it/s]187it [01:33,  2.28it/s]188it [01:33,  2.64it/s]189it [01:34,  2.30it/s]190it [01:34,  2.51it/s]191it [01:35,  2.43it/s]192it [01:35,  2.12it/s]193it [01:36,  2.10it/s]194it [01:36,  2.04it/s]195it [01:37,  1.91it/s]196it [01:37,  2.00it/s]197it [01:38,  1.91it/s]198it [01:38,  1.86it/s]199it [01:39,  2.08it/s]200it [01:39,  2.02it/s]201it [01:40,  2.23it/s]202it [01:40,  2.41it/s]203it [01:40,  2.43it/s]204it [01:41,  2.13it/s]205it [01:41,  2.61it/s]206it [01:42,  2.43it/s]207it [01:42,  3.02it/s]208it [01:42,  2.60it/s]209it [01:43,  2.37it/s]210it [01:43,  2.92it/s]211it [01:43,  3.52it/s]212it [01:43,  3.99it/s]213it [01:43,  4.10it/s]214it [01:44,  3.48it/s]215it [01:44,  3.23it/s]216it [01:45,  2.66it/s]217it [01:45,  2.98it/s]218it [01:45,  3.02it/s]219it [01:46,  3.13it/s]220it [01:46,  3.24it/s]221it [01:46,  3.69it/s]222it [01:46,  3.69it/s]223it [01:47,  4.15it/s]224it [01:47,  4.28it/s]225it [01:47,  4.08it/s]226it [01:47,  3.77it/s]227it [01:48,  3.87it/s]228it [01:48,  4.15it/s]229it [01:48,  4.33it/s]230it [01:48,  4.70it/s]231it [01:48,  4.16it/s]232it [01:49,  4.60it/s]233it [01:49,  5.23it/s]234it [01:49,  5.30it/s]235it [01:49,  4.76it/s]236it [01:49,  4.43it/s]237it [01:50,  3.82it/s]238it [01:50,  3.38it/s]239it [01:50,  3.51it/s]240it [01:51,  3.96it/s]241it [01:51,  3.57it/s]242it [01:51,  3.50it/s]243it [01:51,  3.74it/s]245it [01:52,  5.43it/s]247it [01:52,  6.67it/s]248it [01:52,  7.17it/s]250it [01:52,  8.41it/s]252it [01:52,  9.48it/s]254it [01:52, 10.32it/s]256it [01:53, 10.70it/s]258it [01:53, 10.53it/s]260it [01:53, 10.88it/s]262it [01:53, 12.13it/s]264it [01:53, 12.79it/s]266it [01:53, 13.09it/s]268it [01:54, 13.14it/s]270it [01:54, 13.94it/s]272it [01:54, 13.98it/s]274it [01:54, 13.32it/s]276it [01:54, 13.33it/s]278it [01:54, 13.02it/s]280it [01:54, 13.10it/s]282it [01:55, 13.57it/s]284it [01:55, 13.78it/s]286it [01:55, 13.81it/s]288it [01:55, 13.60it/s]290it [01:55, 13.64it/s]292it [01:55, 13.73it/s]294it [01:55, 12.13it/s]296it [01:56, 11.74it/s]298it [01:56, 11.39it/s]300it [01:56, 11.11it/s]302it [01:56, 11.13it/s]304it [01:56, 10.95it/s]306it [01:57, 11.13it/s]306it [01:57,  2.61it/s]
Number of selected candidates = 167
---> Each Classifier' shapes
	 GT_classifier = 102
	 ViLang_guessed = 167
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:04<01:48,  4.53s/it]  8%|▊         | 2/25 [00:04<00:47,  2.07s/it] 12%|█▏        | 3/25 [00:05<00:27,  1.24s/it] 16%|█▌        | 4/25 [00:05<00:17,  1.20it/s] 20%|██        | 5/25 [00:05<00:12,  1.65it/s] 24%|██▍       | 6/25 [00:05<00:08,  2.14it/s] 28%|██▊       | 7/25 [00:05<00:06,  2.62it/s] 32%|███▏      | 8/25 [00:06<00:05,  3.07it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.48it/s] 40%|████      | 10/25 [00:06<00:03,  3.80it/s] 44%|████▍     | 11/25 [00:06<00:03,  4.08it/s] 48%|████▊     | 12/25 [00:06<00:03,  4.30it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.47it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.59it/s] 60%|██████    | 15/25 [00:07<00:02,  4.68it/s] 64%|██████▍   | 16/25 [00:07<00:01,  4.74it/s] 68%|██████▊   | 17/25 [00:07<00:01,  4.79it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.82it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.85it/s] 80%|████████  | 20/25 [00:08<00:01,  4.87it/s] 84%|████████▍ | 21/25 [00:08<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.89it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.89it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.90it/s]100%|██████████| 25/25 [00:09<00:00,  2.60it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.7781288623809814
---> Evaluating
  0%|          | 0/25 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  4%|▍         | 1/25 [00:05<02:00,  5.04s/it]  8%|▊         | 2/25 [00:05<00:50,  2.20s/it] 12%|█▏        | 3/25 [00:05<00:28,  1.29s/it] 16%|█▌        | 4/25 [00:05<00:18,  1.16it/s] 20%|██        | 5/25 [00:05<00:12,  1.61it/s] 24%|██▍       | 6/25 [00:06<00:09,  2.08it/s] 28%|██▊       | 7/25 [00:06<00:07,  2.57it/s] 32%|███▏      | 8/25 [00:06<00:05,  3.03it/s] 36%|███▌      | 9/25 [00:06<00:04,  3.44it/s] 40%|████      | 10/25 [00:06<00:03,  3.79it/s] 44%|████▍     | 11/25 [00:07<00:03,  4.08it/s] 48%|████▊     | 12/25 [00:07<00:03,  4.30it/s] 52%|█████▏    | 13/25 [00:07<00:02,  4.47it/s] 56%|█████▌    | 14/25 [00:07<00:02,  4.59it/s] 60%|██████    | 15/25 [00:07<00:02,  4.69it/s] 64%|██████▍   | 16/25 [00:08<00:01,  4.76it/s] 68%|██████▊   | 17/25 [00:08<00:01,  4.80it/s] 72%|███████▏  | 18/25 [00:08<00:01,  4.84it/s] 76%|███████▌  | 19/25 [00:08<00:01,  4.86it/s] 80%|████████  | 20/25 [00:08<00:01,  4.87it/s] 84%|████████▍ | 21/25 [00:09<00:00,  4.88it/s] 88%|████████▊ | 22/25 [00:09<00:00,  4.88it/s] 92%|█████████▏| 23/25 [00:09<00:00,  4.89it/s] 96%|█████████▌| 24/25 [00:09<00:00,  4.89it/s]100%|██████████| 25/25 [00:09<00:00,  2.51it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([6149, 768])
gt_feats.shape torch.Size([6149, 768])
Semantic similarity score = 0.509644091129303


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 69.93006993006993
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 81.59529380891625
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 62.20632601351731


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 77.8128890991211
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 61.261993820133355
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 79.84895106196404
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 58.927090372174526


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 50.96440887451172
=========================          END          =========================


========================= ViLang Final Results of 10 runs, w/ 3 imgs per class=========================


[Clustering]
Clustering ACC: 62.02309318588387
Semantic ACC:   51.05419158935547
=========================          END          =========================
