Namespace(config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/dog120_all.yml', alpha=0.7, N_tta=10, num_per_category='3', num_runs=10)
Number of GPUs: 1
Device ID: 0 Device Name: NVIDIA RTX A6000
['Wire-Haired Terrier', 'Whippet', 'Affenpinscher', 'King Charles Spaniel', 'Irish Setter', 'Basset Hound', 'Doberman Pinscher', 'Rottweiler', 'German Pinscher', 'Mixed Breed', 'Australian Shepherd', 'Saluki', 'Toy Terrier', 'Teddy Bear Terrier', 'Norfolk Terrier', 'Bernese Mountain Dog mix', 'Terrier Mix', 'Brown Labrador Retriever', 'Cairn Terrier', 'Boston Terrier', 'French Bulldog', 'Shepherd', 'Pembroke Welsh Corgi', 'English Bulldog', 'Yorkshire Terrier', 'Shih Tzu', 'Maltese', 'Chow Chow', 'Akita', 'Samoyed', 'Setter', 'Labrador Retriever', 'Bernese Mountain Dog puppy', 'Appenzeller Sennenhund', 'Rat Terrier', 'Bernese Mountain Dog', 'St. Bernard', 'Dachshund', 'Old English Sheepdog', 'Saint Bernard', 'Crossbreed', 'boston terrier', 'Terrier mix', 'Hound mix', 'Fox Terrier', 'Pit Bull', 'Chihuahua', 'Dachshund', 'Pomeranian', 'Weimaraner', 'Terrier', 'Standard Schnauzer', 'Scottie', 'Belgian Shepherd', 'Beagle mix', 'Boxer', 'Coonhound', 'Labrador Retriever', 'Boxer', 'Rottweiler', 'Cocker Spaniel', 'Poodle', 'Snub-Nosed Terrier', 'Hound', 'Border Terrier', 'boxer', 'Russian Taylor Dog', 'Siberian Husky', 'Bichon Frise', 'Portuguese Water Dog', 'Newfoundland', 'Dachshund', 'Shih Tzu', 'Pomeranian', 'Spitz Dog', 'Samoyed', 'Collie', 'West Highland White Terrier', 'French Bulldog', 'Hound Dog', 'Blue Tick Coonhound', 'Toy Poodle', 'Italian Greyhound', 'Boxer', 'Hound', 'Bullmastiff', 'St. Bernard Mix', 'Bloodhound', 'Boxer Puppy', 'Dutch Shepherd', 'American Cocker Spaniel', 'Doberman Pinscher', 'Miniature Poodle', 'Possible breeds', 'Corgi', 'Chihuahua', 'Smooth Fox Terrier', 'Shih Tzu', 'Chihuahua', 'Boston Terrier', 'Dalmatian', 'Beagle', 'Brown and White Spaniel', 'Shih Tzu', 'Chihuahua', 'Maltese', 'Basenji', 'Greater Swiss Mountain Dog', 'American Eskimo', 'Pointer', 'Belgian Shepherd', 'Pekingese', 'Wire Fox Terrier', 'Great Dane', 'Shar Pei', 'Afghan', 'Poodle', 'Corgi mix', 'St. Bernard', 'Chihuahua mix', 'Boxer', 'Shih Tzu', 'Bichon Frise', 'Lhasa Apso', 'bulldog', 'Husky', 'Hound mix', 'Shih Tzu', 'Pomeranian', 'Chow Chow', 'Alsatian', 'Staffordshire Bull Terrier', 'Dingo', 'Black and Tan Retriever', 'Briard', 'Springer Spaniel', 'Bernese Mountain Dog Mix', 'Afghan Hounds', 'Poodle mix', 'Husky', 'Alaskan Malamute', 'Samoyed', 'Rottweiler Mix', 'Coton de Tulear', 'Afghan Hound', 'Leonberger', 'Mixed Breed (possibly including St. Bernard)', 'Bulldog', 'Dachshund', 'Alaskan Klee Kai', 'Swiss Mountain Dog', 'Finnish Spitz', 'Rottweiler mix', 'Toy Fox Terrier', 'Silky Terrier', 'English Cocker Spaniel', 'Yorkie', 'Deutscher Schäferhund', 'Plott Hound', 'Akita', 'Havanese', 'Spitz', 'Irish Wolfhound', 'Terrier Dog', 'German Shepherd', 'Poodle', 'Cockapoo', 'Labrador Retriever', 'Fox Terrier', 'Rat Terrier', 'Terrier Mix', 'Black Terrier', 'Collie', 'Shetland Sheepdog', 'Rough Collie', 'Old English Sheepdog', 'Tibetan Terrier', 'Borzoi', 'Swiss Mountain Dog Mix', 'French Bulldog', 'Dachshund', 'Boston Terrier', 'African wild dog', 'Schnauzer', 'Fox Terrier', 'Welsh Terrier', 'Cardigan Welsh Corgi', 'Giant Schnauzer', 'Scottish Terrier', 'Mastiff', 'Shih Tzu', 'Chihuahua', 'Dachshund', 'Boxer Bulldog Mix', 'Dachshund', 'Basset Hound', 'Shar Pei', 'Boston Terrier', 'Border Collie', 'German Rottweiler', 'Highland Terrier', 'Chocolate Labrador Retriever', 'Golden Retriever', 'American Staffordshire Terrier', 'Lurcher', 'St. Bernard puppy', 'Foxhound', 'Dalmatian', 'English Setter', 'Toy Spaniel', 'Swiss St. Bernard', 'Spoodle', 'Alaskan Malamute', 'Chow Chow', 'Maltese', 'Pug', 'Terrier mix', 'Miniature Schnauzer', 'Yorkshire Terrier', 'Vizsla', 'Newfoundland', 'Old English Sheepdog', 'Bernese Mountain Dog', 'West Highland White Terrier', 'Dachshund', 'Bichon Frise', 'Bloodhound', 'Basset Hound', 'Bulldog', 'Basset Hound', 'Dachshund', 'Beagle', 'American Eskimo Dog', 'Bloodhound', 'Basset Hound', 'Rhodesian Ridgeback', 'Wire-haired Fox Terrier', 'Pit Bull Terrier', 'Teddy Bear Dog', 'American Bulldog', 'Chi', 'Bullmastiff', 'Rottweiler', 'Keeshond', 'Labrador Retriever', 'Golden Retriever', 'Bernese Mountain Dog', 'Brussels Griffon', 'Bloodhound', 'Boxer', 'Doberman Pinscher', 'Jack Russell Terrier', 'Rottweiler puppy', 'Japanese Chin', 'Cocker Spaniel', 'Irish Terrier', 'Dalmatian', 'Basset Hound', 'Boxer', 'Retriever mix', 'Chinese Crested', 'Pinscher', 'Japanese Spitz', 'Basset Hound', 'Bloodhound', 'Great Dane', 'King Charles Spaniel', 'Poodle', 'Cocker Spaniel', 'Flat-Coated Retriever', 'American Pit Bull Terrier', 'Hound dog', 'Belgian Malinois', 'Beagle', 'Basset Hound', 'Bloodhound', 'Siberian Husky', 'Alaskan Malamute', 'Samoyed', 'Miniature Pinscher', 'Shiba Inu', 'Aberdeen Terrier', 'Alaskan Husky', 'Greyhound', 'Pembroke Welsh Corgi', 'Cardigan Welsh Corgi', 'Corgi Mix', 'Papillon', 'Chihuahua', 'Shih Tzu', 'Spitz Mix', 'Red Irish Wolfhound', 'Tibetan Mastiff', 'Tibetan Spaniel', 'Airedale Terrier', 'Standard Poodle', 'Brittany Spaniel', 'Rhodesian Ridgeback', 'Parson Russell Terrier', 'Bull Terrier', 'Pharaoh Hound', 'Cairn Terrier', 'Beagle mix', 'African Wild Dog', 'Biewer Terrier', 'Great Pyrenees', 'Pomeranian', 'Beagle crossbreed', 'Manchester Terrier', 'Long-haired Chihuahua', 'Chihuahua Terrier mix', 'Dachshund-Terrier Mix', 'Old English Sheepdog', 'Briard', 'Komondor', 'Boxer Mix', 'Chinese Crested Dog']
0it [00:00, ?it/s]1it [00:00,  4.54it/s]3it [00:00,  9.46it/s]5it [00:00, 11.68it/s]7it [00:00, 12.65it/s]9it [00:00, 12.53it/s]11it [00:00, 13.40it/s]13it [00:01, 13.77it/s]15it [00:01, 13.98it/s]17it [00:01, 13.81it/s]19it [00:01, 13.17it/s]21it [00:01, 13.30it/s]23it [00:01, 13.79it/s]25it [00:01, 13.59it/s]27it [00:02, 14.37it/s]29it [00:02, 14.87it/s]31it [00:02, 15.07it/s]33it [00:02, 15.33it/s]35it [00:02, 14.92it/s]37it [00:02, 16.02it/s]39it [00:02, 14.56it/s]41it [00:02, 14.60it/s]43it [00:03, 14.09it/s]45it [00:03, 14.06it/s]47it [00:03, 14.52it/s]49it [00:03, 15.14it/s]51it [00:03, 15.83it/s]53it [00:03, 15.52it/s]55it [00:03, 16.16it/s]57it [00:04, 15.92it/s]59it [00:04, 14.01it/s]61it [00:04, 14.64it/s]63it [00:04,  9.74it/s]65it [00:04, 11.08it/s]67it [00:04, 12.67it/s]69it [00:05, 13.70it/s]71it [00:05, 13.60it/s]73it [00:05, 14.14it/s]75it [00:05, 10.26it/s]77it [00:05, 11.74it/s]79it [00:05, 12.07it/s]81it [00:06, 13.33it/s]83it [00:06, 13.45it/s]85it [00:06, 14.02it/s]87it [00:06, 14.44it/s]89it [00:06, 14.98it/s]91it [00:06, 15.07it/s]93it [00:06, 15.59it/s]95it [00:06, 14.99it/s]97it [00:07, 15.13it/s]99it [00:07, 15.56it/s]101it [00:07, 16.59it/s]103it [00:07, 15.60it/s]105it [00:07, 13.74it/s]107it [00:07, 14.46it/s]109it [00:07, 14.93it/s]111it [00:07, 15.60it/s]113it [00:08, 14.58it/s]115it [00:08, 12.47it/s]117it [00:08, 12.40it/s]119it [00:08, 12.59it/s]121it [00:08, 13.18it/s]123it [00:08, 14.42it/s]125it [00:09, 14.65it/s]127it [00:09, 15.35it/s]129it [00:09, 15.75it/s]131it [00:09, 14.18it/s]133it [00:09, 12.11it/s]135it [00:09, 12.24it/s]137it [00:10,  9.80it/s]139it [00:10, 10.41it/s]141it [00:10,  7.33it/s]142it [00:10,  6.62it/s]143it [00:11,  5.61it/s]144it [00:11,  5.42it/s]145it [00:12,  3.36it/s]146it [00:12,  2.35it/s]147it [00:13,  1.93it/s]148it [00:14,  2.13it/s]149it [00:14,  2.03it/s]150it [00:14,  2.12it/s]151it [00:15,  2.27it/s]152it [00:15,  2.14it/s]153it [00:16,  2.05it/s]154it [00:17,  1.82it/s]155it [00:17,  1.86it/s]156it [00:18,  1.80it/s]157it [00:18,  2.19it/s]158it [00:18,  2.78it/s]159it [00:18,  3.37it/s]160it [00:18,  3.70it/s]161it [00:19,  4.15it/s]162it [00:19,  4.46it/s]163it [00:19,  4.32it/s]164it [00:19,  5.07it/s]165it [00:19,  5.27it/s]167it [00:19,  7.44it/s]169it [00:20,  9.74it/s]171it [00:20, 11.48it/s]173it [00:20,  9.98it/s]175it [00:20, 10.78it/s]177it [00:20, 11.70it/s]179it [00:20, 13.04it/s]181it [00:20, 13.91it/s]183it [00:21, 14.80it/s]185it [00:21, 15.37it/s]187it [00:21, 15.75it/s]189it [00:21, 15.30it/s]191it [00:21, 14.64it/s]193it [00:21, 15.28it/s]195it [00:21, 15.94it/s]197it [00:21, 16.05it/s]199it [00:22, 16.43it/s]201it [00:22, 16.47it/s]203it [00:22, 16.49it/s]205it [00:22, 13.82it/s]207it [00:22, 14.24it/s]209it [00:23,  6.07it/s]211it [00:23,  7.51it/s]213it [00:23,  8.73it/s]215it [00:23, 10.22it/s]217it [00:23, 11.68it/s]219it [00:24, 10.22it/s]221it [00:24,  8.42it/s]223it [00:24,  6.73it/s]224it [00:25,  6.65it/s]225it [00:25,  6.64it/s]226it [00:25,  5.69it/s]227it [00:25,  4.53it/s]228it [00:26,  4.29it/s]229it [00:26,  4.83it/s]231it [00:26,  6.17it/s]232it [00:26,  6.54it/s]234it [00:27,  4.61it/s]235it [00:27,  4.81it/s]236it [00:27,  5.28it/s]237it [00:27,  5.37it/s]238it [00:28,  4.81it/s]239it [00:28,  5.14it/s]240it [00:28,  4.93it/s]241it [00:28,  5.66it/s]242it [00:28,  4.86it/s]243it [00:28,  5.44it/s]244it [00:29,  5.46it/s]245it [00:29,  5.50it/s]246it [00:29,  4.44it/s]247it [00:29,  5.19it/s]248it [00:29,  5.67it/s]249it [00:30,  5.45it/s]250it [00:30,  5.60it/s]251it [00:30,  5.33it/s]252it [00:30,  5.70it/s]253it [00:30,  6.21it/s]254it [00:30,  6.92it/s]255it [00:30,  7.61it/s]256it [00:31,  7.77it/s]257it [00:31,  6.94it/s]258it [00:31,  7.03it/s]259it [00:31,  5.90it/s]260it [00:31,  6.23it/s]262it [00:31,  7.33it/s]263it [00:32,  7.66it/s]264it [00:32,  6.69it/s]265it [00:32,  6.47it/s]266it [00:32,  6.96it/s]267it [00:32,  7.01it/s]268it [00:32,  6.47it/s]269it [00:33,  6.53it/s]270it [00:33,  6.74it/s]271it [00:33,  7.11it/s]272it [00:33,  7.53it/s]274it [00:33,  7.82it/s]275it [00:33,  6.13it/s]276it [00:34,  6.62it/s]277it [00:34,  4.21it/s]278it [00:34,  4.95it/s]279it [00:34,  5.59it/s]280it [00:34,  4.88it/s]281it [00:35,  5.41it/s]282it [00:35,  5.32it/s]283it [00:35,  4.71it/s]284it [00:35,  5.02it/s]285it [00:35,  4.90it/s]286it [00:36,  4.98it/s]287it [00:36,  5.57it/s]288it [00:36,  6.38it/s]289it [00:36,  5.92it/s]290it [00:36,  4.99it/s]291it [00:37,  2.94it/s]292it [00:37,  3.01it/s]293it [00:38,  2.21it/s]294it [00:39,  1.70it/s]295it [00:40,  1.46it/s]296it [00:41,  1.30it/s]297it [00:42,  1.19it/s]298it [00:43,  1.11it/s]299it [00:44,  1.05it/s]300it [00:45,  1.03it/s]301it [00:46,  1.00s/it]302it [00:47,  1.01s/it]303it [00:48,  1.02s/it]304it [00:49,  1.03s/it]305it [00:50,  1.05s/it]306it [00:52,  1.23s/it]307it [00:53,  1.12s/it]308it [00:54,  1.03s/it]309it [00:55,  1.02s/it]310it [00:56,  1.09s/it]311it [00:56,  1.18it/s]312it [00:57,  1.37it/s]313it [00:57,  1.76it/s]314it [00:57,  1.76it/s]315it [00:58,  1.71it/s]316it [00:58,  1.96it/s]317it [00:59,  2.26it/s]318it [00:59,  2.25it/s]319it [00:59,  2.34it/s]320it [01:00,  2.82it/s]321it [01:00,  3.04it/s]322it [01:00,  3.26it/s]323it [01:01,  2.39it/s]324it [01:01,  2.37it/s]325it [01:02,  2.71it/s]326it [01:02,  3.04it/s]327it [01:02,  2.66it/s]328it [01:03,  2.21it/s]329it [01:03,  2.12it/s]330it [01:04,  2.57it/s]331it [01:04,  2.66it/s]332it [01:05,  2.23it/s]333it [01:05,  2.29it/s]334it [01:06,  2.05it/s]335it [01:06,  2.29it/s]336it [01:06,  2.09it/s]337it [01:07,  1.98it/s]338it [01:07,  2.35it/s]339it [01:07,  3.01it/s]340it [01:08,  3.42it/s]341it [01:08,  2.76it/s]342it [01:09,  2.57it/s]343it [01:09,  2.45it/s]344it [01:10,  2.28it/s]345it [01:10,  2.10it/s]346it [01:11,  1.91it/s]347it [01:11,  1.84it/s]348it [01:12,  1.78it/s]349it [01:12,  1.77it/s]350it [01:13,  1.76it/s]351it [01:14,  1.75it/s]352it [01:14,  1.70it/s]353it [01:15,  1.68it/s]354it [01:16,  1.61it/s]355it [01:16,  1.51it/s]356it [01:17,  1.48it/s]357it [01:18,  1.43it/s]358it [01:18,  1.46it/s]359it [01:19,  1.36it/s]360it [01:20,  1.35it/s]360it [01:20,  4.47it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]  3%|▎         | 1/34 [00:03<02:04,  3.78s/it]  6%|▌         | 2/34 [00:05<01:14,  2.33s/it]  9%|▉         | 3/34 [00:05<00:42,  1.36s/it] 12%|█▏        | 4/34 [00:05<00:28,  1.06it/s] 15%|█▍        | 5/34 [00:05<00:19,  1.48it/s] 18%|█▊        | 6/34 [00:06<00:15,  1.82it/s] 21%|██        | 7/34 [00:06<00:11,  2.30it/s] 24%|██▎       | 8/34 [00:06<00:10,  2.54it/s] 26%|██▋       | 9/34 [00:06<00:08,  3.00it/s] 29%|██▉       | 10/34 [00:07<00:07,  3.09it/s] 32%|███▏      | 11/34 [00:07<00:06,  3.48it/s] 35%|███▌      | 12/34 [00:07<00:06,  3.41it/s] 38%|███▊      | 13/34 [00:07<00:05,  3.75it/s] 41%|████      | 14/34 [00:08<00:05,  3.61it/s] 44%|████▍     | 15/34 [00:08<00:04,  3.92it/s] 47%|████▋     | 16/34 [00:08<00:04,  4.17it/s] 50%|█████     | 17/34 [00:08<00:03,  4.37it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.52it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.64it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.72it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.78it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.82it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.85it/s] 71%|███████   | 24/34 [00:10<00:02,  4.87it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.88it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.89it/s] 79%|███████▉  | 27/34 [00:10<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.91it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.92it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.92it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.92it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.91it/s]100%|██████████| 34/34 [00:12<00:00,  5.17it/s]100%|██████████| 34/34 [00:12<00:00,  2.76it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:14,  4.09s/it]  6%|▌         | 2/34 [00:04<00:57,  1.80s/it]  9%|▉         | 3/34 [00:04<00:34,  1.12s/it] 12%|█▏        | 4/34 [00:04<00:22,  1.32it/s] 15%|█▍        | 5/34 [00:05<00:17,  1.67it/s] 18%|█▊        | 6/34 [00:05<00:13,  2.15it/s] 21%|██        | 7/34 [00:05<00:11,  2.41it/s] 24%|██▎       | 8/34 [00:05<00:09,  2.87it/s] 26%|██▋       | 9/34 [00:06<00:08,  2.98it/s] 29%|██▉       | 10/34 [00:06<00:07,  3.39it/s] 32%|███▏      | 11/34 [00:06<00:06,  3.74it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.04it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.27it/s] 41%|████      | 14/34 [00:07<00:04,  4.45it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.59it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.69it/s] 50%|█████     | 17/34 [00:07<00:03,  4.76it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.81it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.85it/s] 59%|█████▉    | 20/34 [00:08<00:02,  4.87it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.89it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.90it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.91it/s] 71%|███████   | 24/34 [00:09<00:02,  4.92it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.92it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.92it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.93it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.93it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.93it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.93it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.93it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.93it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.93it/s]100%|██████████| 34/34 [00:11<00:00,  5.75it/s]100%|██████████| 34/34 [00:11<00:00,  3.02it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6498726010322571


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.862470862470865
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.3702470026808
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.595877632714995


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 64.98725891113281
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 10.99it/s]4it [00:00,  8.00it/s]6it [00:00,  6.38it/s]7it [00:01,  6.18it/s]9it [00:01,  7.43it/s]10it [00:01,  7.86it/s]12it [00:01,  9.41it/s]14it [00:01, 10.33it/s]16it [00:01, 10.98it/s]18it [00:02, 10.36it/s]20it [00:02, 10.92it/s]22it [00:02, 10.06it/s]24it [00:02, 10.76it/s]26it [00:02,  9.34it/s]28it [00:03,  9.88it/s]30it [00:03, 10.21it/s]32it [00:03, 11.15it/s]34it [00:03, 11.38it/s]36it [00:03, 12.06it/s]38it [00:03, 12.40it/s]40it [00:03, 12.20it/s]42it [00:04, 12.33it/s]44it [00:04, 12.85it/s]46it [00:04, 13.18it/s]48it [00:04, 12.64it/s]50it [00:04, 12.86it/s]52it [00:04, 12.74it/s]54it [00:05, 13.26it/s]56it [00:05, 13.78it/s]58it [00:05, 14.89it/s]60it [00:05, 13.81it/s]62it [00:05, 14.73it/s]64it [00:05,  9.90it/s]66it [00:06, 11.12it/s]68it [00:06, 12.18it/s]70it [00:06, 13.22it/s]72it [00:06, 14.08it/s]74it [00:06, 14.74it/s]76it [00:06, 11.37it/s]78it [00:06, 11.31it/s]80it [00:07, 11.39it/s]82it [00:07, 11.83it/s]84it [00:07, 12.03it/s]86it [00:07,  9.48it/s]88it [00:07, 10.34it/s]90it [00:08, 10.88it/s]92it [00:08, 11.36it/s]94it [00:08, 12.23it/s]96it [00:08, 12.54it/s]98it [00:08, 12.86it/s]100it [00:08, 13.89it/s]102it [00:08, 13.07it/s]104it [00:09, 13.58it/s]106it [00:09, 14.20it/s]108it [00:09, 14.08it/s]110it [00:09, 13.27it/s]112it [00:09, 13.39it/s]114it [00:09, 13.28it/s]116it [00:10, 11.86it/s]118it [00:10, 11.88it/s]120it [00:10, 12.10it/s]122it [00:10, 12.80it/s]124it [00:10, 13.82it/s]126it [00:10, 14.87it/s]128it [00:10, 14.38it/s]130it [00:11, 14.98it/s]132it [00:11, 13.11it/s]134it [00:11, 13.02it/s]136it [00:11, 13.51it/s]138it [00:11, 14.18it/s]140it [00:11, 11.14it/s]142it [00:12,  9.28it/s]144it [00:12, 10.54it/s]146it [00:12, 10.74it/s]148it [00:13,  5.07it/s]149it [00:13,  5.17it/s]150it [00:14,  3.92it/s]151it [00:14,  3.49it/s]152it [00:14,  3.55it/s]153it [00:15,  3.13it/s]154it [00:15,  2.44it/s]155it [00:16,  2.20it/s]156it [00:17,  1.96it/s]157it [00:17,  2.17it/s]158it [00:17,  2.07it/s]159it [00:18,  2.12it/s]160it [00:18,  2.51it/s]161it [00:18,  2.78it/s]162it [00:19,  3.08it/s]163it [00:19,  2.74it/s]164it [00:19,  2.91it/s]165it [00:20,  2.81it/s]166it [00:20,  2.58it/s]167it [00:21,  2.61it/s]168it [00:21,  2.28it/s]169it [00:22,  2.33it/s]170it [00:22,  2.45it/s]171it [00:22,  2.19it/s]172it [00:23,  2.62it/s]173it [00:23,  2.26it/s]174it [00:24,  2.07it/s]175it [00:24,  2.07it/s]176it [00:25,  2.47it/s]177it [00:25,  2.43it/s]178it [00:26,  2.06it/s]179it [00:26,  2.04it/s]180it [00:27,  2.14it/s]181it [00:27,  2.74it/s]182it [00:27,  2.71it/s]183it [00:28,  2.40it/s]184it [00:28,  2.22it/s]185it [00:28,  2.44it/s]186it [00:29,  2.39it/s]187it [00:29,  2.75it/s]188it [00:29,  2.73it/s]189it [00:30,  2.59it/s]190it [00:30,  2.58it/s]191it [00:31,  2.67it/s]192it [00:31,  2.33it/s]193it [00:32,  2.36it/s]194it [00:32,  2.37it/s]195it [00:32,  2.37it/s]196it [00:33,  2.75it/s]197it [00:33,  2.63it/s]198it [00:33,  2.65it/s]199it [00:34,  3.07it/s]200it [00:34,  3.39it/s]201it [00:34,  3.24it/s]202it [00:35,  2.48it/s]203it [00:35,  2.43it/s]204it [00:36,  2.38it/s]205it [00:36,  2.18it/s]206it [00:37,  2.25it/s]207it [00:37,  2.25it/s]208it [00:38,  1.72it/s]209it [00:38,  2.03it/s]210it [00:39,  2.43it/s]211it [00:39,  2.67it/s]212it [00:39,  2.39it/s]213it [00:40,  2.19it/s]214it [00:40,  2.22it/s]215it [00:41,  2.46it/s]217it [00:41,  3.71it/s]218it [00:41,  3.62it/s]219it [00:42,  3.00it/s]220it [00:42,  3.13it/s]221it [00:42,  2.86it/s]222it [00:43,  3.09it/s]223it [00:43,  3.07it/s]224it [00:43,  2.80it/s]225it [00:44,  2.89it/s]226it [00:44,  2.86it/s]227it [00:44,  2.67it/s]228it [00:45,  3.19it/s]229it [00:45,  3.31it/s]230it [00:45,  3.88it/s]231it [00:46,  2.87it/s]232it [00:46,  2.29it/s]233it [00:47,  2.16it/s]234it [00:47,  2.54it/s]235it [00:47,  2.47it/s]236it [00:48,  2.68it/s]237it [00:48,  2.54it/s]238it [00:48,  2.97it/s]239it [00:49,  2.92it/s]240it [00:49,  2.70it/s]241it [00:50,  2.79it/s]242it [00:50,  3.08it/s]243it [00:50,  3.09it/s]244it [00:50,  3.57it/s]245it [00:50,  4.25it/s]246it [00:51,  3.24it/s]247it [00:51,  2.76it/s]248it [00:52,  2.56it/s]249it [00:52,  2.64it/s]250it [00:52,  2.93it/s]252it [00:53,  3.67it/s]253it [00:53,  3.33it/s]254it [00:53,  3.54it/s]255it [00:54,  3.74it/s]256it [00:54,  4.15it/s]257it [00:54,  3.14it/s]258it [00:55,  3.17it/s]259it [00:55,  2.92it/s]260it [00:56,  2.69it/s]261it [00:56,  2.64it/s]262it [00:56,  3.14it/s]263it [00:57,  2.86it/s]264it [00:57,  2.88it/s]265it [00:57,  2.53it/s]266it [00:58,  2.90it/s]267it [00:58,  2.43it/s]268it [00:59,  2.49it/s]269it [00:59,  2.61it/s]270it [00:59,  2.78it/s]271it [01:00,  2.64it/s]272it [01:00,  2.53it/s]273it [01:00,  2.84it/s]274it [01:00,  3.48it/s]275it [01:01,  3.27it/s]276it [01:01,  2.95it/s]277it [01:02,  2.48it/s]278it [01:02,  2.44it/s]279it [01:03,  2.59it/s]280it [01:03,  2.95it/s]281it [01:03,  2.78it/s]282it [01:04,  2.75it/s]283it [01:04,  2.44it/s]284it [01:04,  2.86it/s]285it [01:04,  3.54it/s]286it [01:05,  3.18it/s]287it [01:05,  3.26it/s]288it [01:05,  3.04it/s]289it [01:06,  3.08it/s]290it [01:06,  2.25it/s]291it [01:07,  2.46it/s]292it [01:07,  2.67it/s]293it [01:08,  2.49it/s]294it [01:08,  2.65it/s]296it [01:08,  3.32it/s]297it [01:09,  3.31it/s]298it [01:09,  3.60it/s]299it [01:09,  3.84it/s]300it [01:10,  3.02it/s]301it [01:10,  2.98it/s]302it [01:10,  3.43it/s]303it [01:11,  2.84it/s]304it [01:11,  2.47it/s]305it [01:11,  2.48it/s]306it [01:12,  1.81it/s]307it [01:13,  2.14it/s]308it [01:13,  2.38it/s]309it [01:13,  2.72it/s]310it [01:14,  2.20it/s]311it [01:14,  2.14it/s]313it [01:15,  2.63it/s]314it [01:15,  2.73it/s]315it [01:15,  3.07it/s]316it [01:16,  2.86it/s]317it [01:16,  3.05it/s]318it [01:16,  3.22it/s]319it [01:17,  3.23it/s]320it [01:17,  2.83it/s]321it [01:17,  2.97it/s]322it [01:18,  3.03it/s]323it [01:18,  3.42it/s]324it [01:18,  3.33it/s]325it [01:19,  2.60it/s]326it [01:19,  2.52it/s]327it [01:20,  2.44it/s]328it [01:20,  2.89it/s]329it [01:20,  3.11it/s]330it [01:20,  3.47it/s]331it [01:21,  3.27it/s]332it [01:21,  3.41it/s]333it [01:22,  2.70it/s]334it [01:22,  2.28it/s]335it [01:23,  2.17it/s]336it [01:23,  2.02it/s]337it [01:24,  2.07it/s]338it [01:24,  2.14it/s]339it [01:25,  2.04it/s]340it [01:25,  1.92it/s]341it [01:26,  1.73it/s]342it [01:27,  1.76it/s]343it [01:27,  2.22it/s]344it [01:27,  2.41it/s]345it [01:28,  2.24it/s]346it [01:28,  2.26it/s]347it [01:28,  2.49it/s]348it [01:28,  3.14it/s]349it [01:29,  2.84it/s]350it [01:29,  3.54it/s]351it [01:30,  2.69it/s]352it [01:30,  2.49it/s]353it [01:31,  2.22it/s]354it [01:31,  1.91it/s]355it [01:32,  1.73it/s]356it [01:33,  1.59it/s]357it [01:33,  1.78it/s]358it [01:34,  1.86it/s]359it [01:34,  2.00it/s]360it [01:34,  2.16it/s]360it [01:34,  3.79it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:21,  4.28s/it]  6%|▌         | 2/34 [00:04<01:00,  1.89s/it]  9%|▉         | 3/34 [00:04<00:34,  1.12s/it] 12%|█▏        | 4/34 [00:04<00:22,  1.32it/s] 15%|█▍        | 5/34 [00:05<00:16,  1.79it/s] 18%|█▊        | 6/34 [00:05<00:12,  2.27it/s] 21%|██        | 7/34 [00:05<00:10,  2.49it/s] 24%|██▎       | 8/34 [00:05<00:08,  2.90it/s] 26%|██▋       | 9/34 [00:06<00:07,  3.27it/s] 29%|██▉       | 10/34 [00:06<00:07,  3.29it/s] 32%|███▏      | 11/34 [00:06<00:06,  3.58it/s] 35%|███▌      | 12/34 [00:06<00:05,  3.87it/s] 38%|███▊      | 13/34 [00:07<00:05,  4.07it/s] 41%|████      | 14/34 [00:07<00:04,  4.29it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.39it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.53it/s] 50%|█████     | 17/34 [00:07<00:03,  4.61it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.64it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.67it/s] 59%|█████▉    | 20/34 [00:08<00:02,  4.69it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.71it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.72it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.72it/s] 71%|███████   | 24/34 [00:09<00:02,  4.73it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.78it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.77it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.77it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.73it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.74it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.75it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.71it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.65it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.59it/s]100%|██████████| 34/34 [00:11<00:00,  5.37it/s]100%|██████████| 34/34 [00:11<00:00,  2.94it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:16,  4.15s/it]  6%|▌         | 2/34 [00:04<00:58,  1.84s/it]  9%|▉         | 3/34 [00:04<00:34,  1.10s/it] 12%|█▏        | 4/34 [00:04<00:23,  1.29it/s] 15%|█▍        | 5/34 [00:05<00:18,  1.55it/s] 18%|█▊        | 6/34 [00:05<00:15,  1.77it/s] 21%|██        | 7/34 [00:06<00:14,  1.86it/s] 24%|██▎       | 8/34 [00:06<00:13,  1.98it/s] 26%|██▋       | 9/34 [00:07<00:12,  2.07it/s] 29%|██▉       | 10/34 [00:07<00:10,  2.37it/s] 32%|███▏      | 11/34 [00:07<00:08,  2.82it/s] 35%|███▌      | 12/34 [00:07<00:06,  3.24it/s] 38%|███▊      | 13/34 [00:07<00:05,  3.61it/s] 41%|████      | 14/34 [00:08<00:05,  3.92it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.17it/s] 47%|████▋     | 16/34 [00:08<00:04,  4.27it/s] 50%|█████     | 17/34 [00:08<00:04,  3.91it/s] 53%|█████▎    | 18/34 [00:09<00:04,  3.42it/s] 56%|█████▌    | 19/34 [00:09<00:04,  3.12it/s] 59%|█████▉    | 20/34 [00:09<00:04,  3.00it/s] 62%|██████▏   | 21/34 [00:10<00:04,  2.92it/s] 65%|██████▍   | 22/34 [00:10<00:04,  2.85it/s] 68%|██████▊   | 23/34 [00:11<00:03,  2.79it/s] 71%|███████   | 24/34 [00:11<00:03,  2.73it/s] 74%|███████▎  | 25/34 [00:11<00:03,  2.64it/s] 76%|███████▋  | 26/34 [00:12<00:03,  2.57it/s] 79%|███████▉  | 27/34 [00:12<00:02,  2.52it/s] 82%|████████▏ | 28/34 [00:13<00:02,  2.50it/s] 85%|████████▌ | 29/34 [00:13<00:02,  2.48it/s] 88%|████████▊ | 30/34 [00:13<00:01,  2.45it/s] 91%|█████████ | 31/34 [00:14<00:01,  2.44it/s] 94%|█████████▍| 32/34 [00:14<00:00,  2.41it/s] 97%|█████████▋| 33/34 [00:15<00:00,  2.40it/s]100%|██████████| 34/34 [00:15<00:00,  2.79it/s]100%|██████████| 34/34 [00:15<00:00,  2.17it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6528578400611877


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.675990675990676
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.21506533368819
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.885314061000734


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.28578186035156
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  8.58it/s]3it [00:00, 12.04it/s]5it [00:00, 12.80it/s]7it [00:00, 13.34it/s]9it [00:00, 12.58it/s]11it [00:00, 12.99it/s]13it [00:01, 13.03it/s]15it [00:01, 12.79it/s]17it [00:01,  8.24it/s]19it [00:01,  9.29it/s]21it [00:01, 10.45it/s]23it [00:02,  7.85it/s]24it [00:03,  4.10it/s]25it [00:03,  3.51it/s]26it [00:03,  3.35it/s]27it [00:04,  2.93it/s]28it [00:04,  2.69it/s]29it [00:05,  2.20it/s]30it [00:06,  2.03it/s]31it [00:06,  1.92it/s]32it [00:07,  1.60it/s]33it [00:08,  1.50it/s]34it [00:09,  1.42it/s]35it [00:09,  1.61it/s]36it [00:09,  1.84it/s]37it [00:10,  1.76it/s]38it [00:11,  1.52it/s]39it [00:12,  1.46it/s]40it [00:12,  1.42it/s]41it [00:13,  1.32it/s]42it [00:14,  1.20it/s]43it [00:16,  1.00s/it]44it [00:17,  1.01it/s]45it [00:18,  1.01s/it]46it [00:19,  1.08s/it]47it [00:20,  1.02s/it]48it [00:21,  1.02s/it]49it [00:22,  1.05s/it]50it [00:23,  1.06s/it]51it [00:24,  1.05s/it]52it [00:25,  1.03s/it]53it [00:26,  1.00s/it]54it [00:27,  1.01s/it]55it [00:28,  1.04s/it]56it [00:29,  1.02s/it]57it [00:30,  1.01s/it]58it [00:31,  1.05s/it]59it [00:33,  1.15s/it]60it [00:34,  1.11s/it]61it [00:35,  1.24s/it]62it [00:37,  1.31s/it]63it [00:39,  1.53s/it]64it [00:40,  1.42s/it]65it [00:41,  1.29s/it]66it [00:42,  1.19s/it]67it [00:43,  1.18s/it]68it [00:44,  1.16s/it]69it [00:45,  1.10s/it]70it [00:46,  1.11s/it]71it [00:47,  1.17s/it]72it [00:49,  1.15s/it]73it [00:49,  1.07s/it]74it [00:50,  1.06s/it]75it [00:52,  1.18s/it]76it [00:53,  1.16s/it]77it [00:54,  1.12s/it]78it [00:55,  1.11s/it]79it [00:56,  1.17s/it]80it [00:58,  1.15s/it]81it [00:59,  1.11s/it]82it [01:00,  1.13s/it]83it [01:01,  1.11s/it]84it [01:02,  1.09s/it]85it [01:03,  1.11s/it]86it [01:04,  1.08s/it]87it [01:05,  1.05s/it]88it [01:06,  1.03s/it]89it [01:07,  1.07s/it]90it [01:08,  1.07s/it]91it [01:09,  1.01s/it]92it [01:10,  1.11it/s]93it [01:10,  1.21it/s]94it [01:11,  1.27it/s]95it [01:12,  1.27it/s]96it [01:13,  1.29it/s]97it [01:13,  1.37it/s]98it [01:14,  1.31it/s]99it [01:15,  1.15it/s]100it [01:16,  1.20it/s]101it [01:17,  1.11it/s]102it [01:19,  1.12s/it]103it [01:19,  1.02s/it]104it [01:20,  1.06it/s]105it [01:21,  1.22it/s]106it [01:22,  1.17it/s]107it [01:23,  1.06it/s]108it [01:24,  1.11it/s]109it [01:24,  1.19it/s]110it [01:25,  1.26it/s]111it [01:26,  1.29it/s]112it [01:26,  1.35it/s]113it [01:27,  1.39it/s]114it [01:28,  1.37it/s]115it [01:29,  1.24it/s]116it [01:30,  1.01it/s]117it [01:32,  1.17s/it]118it [01:33,  1.28s/it]119it [01:35,  1.36s/it]120it [01:37,  1.42s/it]121it [01:38,  1.51s/it]122it [01:40,  1.52s/it]123it [01:41,  1.56s/it]124it [01:43,  1.58s/it]125it [01:45,  1.69s/it]126it [01:47,  1.71s/it]127it [01:48,  1.70s/it]128it [01:50,  1.68s/it]129it [01:51,  1.58s/it]130it [01:53,  1.57s/it]131it [01:55,  1.61s/it]132it [01:56,  1.60s/it]133it [01:58,  1.57s/it]134it [01:59,  1.57s/it]135it [02:01,  1.61s/it]136it [02:03,  1.57s/it]137it [02:04,  1.56s/it]138it [02:06,  1.57s/it]139it [02:07,  1.62s/it]140it [02:09,  1.61s/it]141it [02:11,  1.64s/it]142it [02:12,  1.48s/it]143it [02:13,  1.30s/it]144it [02:14,  1.21s/it]145it [02:15,  1.17s/it]146it [02:16,  1.08s/it]147it [02:17,  1.05s/it]148it [02:18,  1.02s/it]149it [02:19,  1.14s/it]150it [02:20,  1.04s/it]151it [02:21,  1.02s/it]152it [02:22,  1.01s/it]153it [02:23,  1.04s/it]154it [02:24,  1.12s/it]155it [02:26,  1.20s/it]156it [02:27,  1.20s/it]157it [02:28,  1.14s/it]158it [02:29,  1.07s/it]159it [02:30,  1.08s/it]160it [02:31,  1.08s/it]161it [02:32,  1.06s/it]162it [02:33,  1.07s/it]163it [02:34,  1.06s/it]164it [02:35,  1.05s/it]165it [02:36,  1.03it/s]166it [02:37,  1.01s/it]167it [02:38,  1.10s/it]168it [02:39,  1.07s/it]169it [02:41,  1.20s/it]170it [02:42,  1.34s/it]171it [02:44,  1.40s/it]172it [02:45,  1.37s/it]173it [02:47,  1.44s/it]174it [02:48,  1.32s/it]175it [02:49,  1.29s/it]176it [02:50,  1.24s/it]177it [02:51,  1.19s/it]178it [02:52,  1.18s/it]179it [02:54,  1.21s/it]180it [02:55,  1.27s/it]181it [02:56,  1.28s/it]182it [02:58,  1.25s/it]183it [02:59,  1.21s/it]184it [03:00,  1.15s/it]185it [03:01,  1.17s/it]186it [03:02,  1.22s/it]187it [03:04,  1.29s/it]188it [03:05,  1.31s/it]189it [03:06,  1.26s/it]190it [03:07,  1.19s/it]191it [03:08,  1.16s/it]192it [03:10,  1.16s/it]193it [03:11,  1.17s/it]194it [03:12,  1.16s/it]195it [03:13,  1.14s/it]196it [03:14,  1.13s/it]197it [03:15,  1.15s/it]198it [03:16,  1.17s/it]199it [03:18,  1.17s/it]200it [03:19,  1.16s/it]201it [03:20,  1.21s/it]202it [03:21,  1.26s/it]203it [03:23,  1.31s/it]204it [03:24,  1.31s/it]205it [03:26,  1.43s/it]206it [03:27,  1.35s/it]207it [03:28,  1.24s/it]208it [03:30,  1.49s/it]209it [03:31,  1.38s/it]210it [03:32,  1.24s/it]211it [03:33,  1.10s/it]212it [03:34,  1.00s/it]213it [03:35,  1.04it/s]214it [03:35,  1.14it/s]215it [03:36,  1.16it/s]216it [03:37,  1.02s/it]217it [03:39,  1.03s/it]218it [03:39,  1.01it/s]219it [03:40,  1.13it/s]220it [03:41,  1.21it/s]221it [03:41,  1.27it/s]222it [03:42,  1.27it/s]223it [03:43,  1.30it/s]224it [03:44,  1.29it/s]225it [03:45,  1.11it/s]226it [03:46,  1.26it/s]227it [03:46,  1.43it/s]228it [03:47,  1.41it/s]229it [03:48,  1.36it/s]230it [03:48,  1.25it/s]231it [03:49,  1.23it/s]232it [03:50,  1.19it/s]233it [03:51,  1.14it/s]234it [03:52,  1.13it/s]235it [03:53,  1.22it/s]236it [03:54,  1.17it/s]237it [03:55,  1.13it/s]238it [03:56,  1.02it/s]239it [03:57,  1.05s/it]240it [03:58,  1.06s/it]241it [03:59,  1.10s/it]242it [04:00,  1.09s/it]243it [04:01,  1.01it/s]244it [04:02,  1.02it/s]245it [04:03,  1.01s/it]246it [04:05,  1.22s/it]247it [04:06,  1.17s/it]248it [04:07,  1.09s/it]249it [04:08,  1.13s/it]250it [04:09,  1.09s/it]251it [04:10,  1.00it/s]252it [04:11,  1.06it/s]253it [04:11,  1.17it/s]254it [04:12,  1.20it/s]255it [04:13,  1.21it/s]256it [04:14,  1.11it/s]257it [04:15,  1.03it/s]258it [04:17,  1.09s/it]259it [04:18,  1.12s/it]260it [04:19,  1.11s/it]261it [04:20,  1.10s/it]262it [04:21,  1.06s/it]263it [04:22,  1.13s/it]264it [04:23,  1.11s/it]265it [04:24,  1.14s/it]266it [04:25,  1.11s/it]267it [04:27,  1.10s/it]268it [04:28,  1.12s/it]269it [04:29,  1.10s/it]270it [04:30,  1.11s/it]271it [04:31,  1.07s/it]272it [04:32,  1.08s/it]273it [04:33,  1.03s/it]274it [04:34,  1.01s/it]275it [04:35,  1.03s/it]276it [04:36,  1.06s/it]277it [04:38,  1.20s/it]278it [04:39,  1.19s/it]279it [04:40,  1.19s/it]280it [04:41,  1.05s/it]281it [04:42,  1.06s/it]282it [04:43,  1.15s/it]283it [04:45,  1.28s/it]284it [04:46,  1.26s/it]285it [04:47,  1.22s/it]286it [04:48,  1.11s/it]287it [04:49,  1.07s/it]288it [04:50,  1.05s/it]289it [04:51,  1.02s/it]290it [04:52,  1.01it/s]291it [04:53,  1.04s/it]292it [04:54,  1.06s/it]293it [04:55,  1.05s/it]294it [04:56,  1.09s/it]295it [04:57,  1.02s/it]296it [04:58,  1.05s/it]297it [04:59,  1.02s/it]298it [05:00,  1.08s/it]299it [05:01,  1.11s/it]300it [05:03,  1.10s/it]301it [05:04,  1.06s/it]302it [05:05,  1.04s/it]303it [05:06,  1.04s/it]304it [05:07,  1.03s/it]305it [05:08,  1.06s/it]306it [05:10,  1.37s/it]307it [05:11,  1.32s/it]308it [05:12,  1.37s/it]309it [05:14,  1.37s/it]310it [05:16,  1.74s/it]311it [05:18,  1.59s/it]312it [05:19,  1.53s/it]313it [05:20,  1.47s/it]314it [05:22,  1.43s/it]315it [05:23,  1.39s/it]316it [05:24,  1.32s/it]317it [05:25,  1.28s/it]318it [05:27,  1.29s/it]319it [05:28,  1.28s/it]320it [05:29,  1.30s/it]321it [05:31,  1.28s/it]322it [05:32,  1.30s/it]323it [05:33,  1.34s/it]324it [05:35,  1.34s/it]325it [05:36,  1.36s/it]326it [05:37,  1.32s/it]327it [05:38,  1.25s/it]328it [05:40,  1.24s/it]329it [05:41,  1.16s/it]330it [05:42,  1.15s/it]331it [05:43,  1.15s/it]332it [05:44,  1.19s/it]333it [05:46,  1.28s/it]334it [05:47,  1.23s/it]335it [05:48,  1.23s/it]336it [05:49,  1.28s/it]337it [05:51,  1.24s/it]338it [05:52,  1.20s/it]339it [05:53,  1.19s/it]340it [05:54,  1.15s/it]341it [05:55,  1.13s/it]342it [05:56,  1.15s/it]343it [05:57,  1.14s/it]344it [05:58,  1.15s/it]345it [06:00,  1.19s/it]346it [06:01,  1.16s/it]347it [06:02,  1.13s/it]348it [06:03,  1.06s/it]349it [06:04,  1.08s/it]350it [06:05,  1.08s/it]351it [06:06,  1.10s/it]352it [06:07,  1.18s/it]353it [06:09,  1.17s/it]354it [06:10,  1.14s/it]355it [06:11,  1.18s/it]356it [06:12,  1.13s/it]357it [06:13,  1.03s/it]358it [06:13,  1.11it/s]359it [06:14,  1.24it/s]360it [06:15,  1.26it/s]360it [06:15,  1.04s/it]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:07<03:53,  7.09s/it]  6%|▌         | 2/34 [00:07<01:37,  3.04s/it]  9%|▉         | 3/34 [00:07<00:54,  1.75s/it] 12%|█▏        | 4/34 [00:07<00:34,  1.14s/it] 15%|█▍        | 5/34 [00:07<00:23,  1.24it/s] 18%|█▊        | 6/34 [00:08<00:16,  1.66it/s] 21%|██        | 7/34 [00:08<00:12,  2.12it/s] 24%|██▎       | 8/34 [00:08<00:10,  2.57it/s] 26%|██▋       | 9/34 [00:08<00:08,  2.97it/s] 29%|██▉       | 10/34 [00:08<00:07,  3.38it/s] 32%|███▏      | 11/34 [00:09<00:06,  3.73it/s] 35%|███▌      | 12/34 [00:09<00:05,  4.02it/s] 38%|███▊      | 13/34 [00:09<00:04,  4.21it/s] 41%|████      | 14/34 [00:09<00:04,  4.34it/s] 44%|████▍     | 15/34 [00:10<00:04,  4.49it/s] 47%|████▋     | 16/34 [00:10<00:03,  4.60it/s] 50%|█████     | 17/34 [00:10<00:03,  4.68it/s] 53%|█████▎    | 18/34 [00:10<00:03,  4.70it/s] 56%|█████▌    | 19/34 [00:10<00:03,  4.75it/s] 59%|█████▉    | 20/34 [00:11<00:02,  4.79it/s] 62%|██████▏   | 21/34 [00:11<00:02,  4.81it/s] 65%|██████▍   | 22/34 [00:11<00:02,  4.80it/s] 68%|██████▊   | 23/34 [00:11<00:02,  4.73it/s] 71%|███████   | 24/34 [00:11<00:02,  4.75it/s] 74%|███████▎  | 25/34 [00:12<00:01,  4.78it/s] 76%|███████▋  | 26/34 [00:12<00:01,  4.80it/s] 79%|███████▉  | 27/34 [00:12<00:01,  4.76it/s] 82%|████████▏ | 28/34 [00:12<00:01,  4.79it/s] 85%|████████▌ | 29/34 [00:12<00:01,  4.77it/s] 88%|████████▊ | 30/34 [00:13<00:00,  4.81it/s] 91%|█████████ | 31/34 [00:13<00:00,  4.79it/s] 94%|█████████▍| 32/34 [00:13<00:00,  4.81it/s] 97%|█████████▋| 33/34 [00:13<00:00,  4.80it/s]100%|██████████| 34/34 [00:13<00:00,  5.47it/s]100%|██████████| 34/34 [00:14<00:00,  2.39it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:12,  5.85s/it]  6%|▌         | 2/34 [00:06<01:21,  2.53s/it]  9%|▉         | 3/34 [00:06<00:45,  1.47s/it] 12%|█▏        | 4/34 [00:06<00:29,  1.03it/s] 15%|█▍        | 5/34 [00:06<00:20,  1.44it/s] 18%|█▊        | 6/34 [00:06<00:14,  1.89it/s] 21%|██        | 7/34 [00:07<00:11,  2.37it/s] 24%|██▎       | 8/34 [00:07<00:09,  2.83it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.26it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.63it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.91it/s] 35%|███▌      | 12/34 [00:08<00:05,  4.16it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.35it/s] 41%|████      | 14/34 [00:08<00:04,  4.50it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.61it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.69it/s] 50%|█████     | 17/34 [00:09<00:03,  4.75it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.79it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.77it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.81it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.83it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.84it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.85it/s] 71%|███████   | 24/34 [00:10<00:02,  4.86it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.86it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.87it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.87it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.83it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.84it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.86it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.87it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.88it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.88it/s]100%|██████████| 34/34 [00:12<00:00,  5.70it/s]100%|██████████| 34/34 [00:12<00:00,  2.66it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6504933834075928


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.722610722610725
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.22871848538146
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.60400837650476


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.0493392944336
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 11.73it/s]4it [00:00, 12.27it/s]6it [00:00, 13.00it/s]8it [00:00, 13.03it/s]10it [00:00, 12.79it/s]12it [00:00, 13.49it/s]14it [00:01, 13.13it/s]16it [00:01, 13.38it/s]18it [00:01, 13.03it/s]20it [00:01, 13.81it/s]22it [00:01, 14.41it/s]24it [00:01, 14.87it/s]26it [00:01, 13.68it/s]28it [00:02, 14.23it/s]30it [00:02, 14.66it/s]32it [00:02, 15.00it/s]34it [00:02, 15.16it/s]36it [00:02, 15.82it/s]38it [00:02, 15.71it/s]40it [00:02, 15.78it/s]42it [00:02, 15.48it/s]44it [00:03, 15.46it/s]46it [00:03, 15.31it/s]48it [00:03,  9.13it/s]50it [00:03,  8.21it/s]52it [00:04,  4.21it/s]53it [00:05,  2.71it/s]54it [00:07,  1.88it/s]55it [00:07,  1.67it/s]56it [00:08,  1.55it/s]57it [00:09,  1.52it/s]58it [00:10,  1.42it/s]59it [00:10,  1.44it/s]60it [00:11,  1.43it/s]61it [00:12,  1.37it/s]62it [00:13,  1.34it/s]63it [00:14,  1.07it/s]64it [00:15,  1.09it/s]65it [00:16,  1.16it/s]66it [00:17,  1.15it/s]67it [00:17,  1.21it/s]68it [00:18,  1.26it/s]69it [00:19,  1.27it/s]70it [00:20,  1.30it/s]71it [00:20,  1.38it/s]72it [00:21,  1.37it/s]73it [00:22,  1.32it/s]74it [00:23,  1.27it/s]75it [00:24,  1.00it/s]76it [00:25,  1.08s/it]77it [00:26,  1.01s/it]78it [00:27,  1.02it/s]79it [00:28,  1.07it/s]80it [00:29,  1.12it/s]81it [00:29,  1.20it/s]82it [00:30,  1.17it/s]83it [00:31,  1.13it/s]84it [00:32,  1.09it/s]85it [00:33,  1.04it/s]86it [00:34,  1.04it/s]87it [00:35,  1.01it/s]88it [00:36,  1.03s/it]89it [00:37,  1.02it/s]90it [00:38,  1.05it/s]91it [00:39,  1.06it/s]92it [00:40,  1.09it/s]93it [00:41,  1.14it/s]94it [00:42,  1.20it/s]95it [00:42,  1.24it/s]96it [00:43,  1.26it/s]97it [00:44,  1.31it/s]98it [00:44,  1.38it/s]99it [00:45,  1.32it/s]100it [00:46,  1.35it/s]101it [00:47,  1.31it/s]102it [00:47,  1.31it/s]103it [00:48,  1.52it/s]104it [00:48,  1.88it/s]105it [00:49,  1.99it/s]106it [00:49,  2.44it/s]107it [00:49,  2.44it/s]108it [00:50,  2.18it/s]109it [00:50,  2.14it/s]110it [00:51,  2.00it/s]111it [00:51,  1.93it/s]112it [00:52,  1.74it/s]113it [00:53,  1.64it/s]114it [00:54,  1.50it/s]115it [00:54,  1.62it/s]116it [00:55,  1.70it/s]117it [00:55,  1.66it/s]118it [00:56,  1.53it/s]119it [00:57,  1.46it/s]120it [00:58,  1.38it/s]121it [00:58,  1.35it/s]122it [00:59,  1.47it/s]123it [01:00,  1.30it/s]124it [01:01,  1.29it/s]125it [01:01,  1.29it/s]126it [01:02,  1.39it/s]127it [01:03,  1.43it/s]128it [01:03,  1.38it/s]129it [01:04,  1.36it/s]130it [01:05,  1.25it/s]131it [01:06,  1.24it/s]132it [01:07,  1.18it/s]133it [01:08,  1.14it/s]134it [01:09,  1.18it/s]135it [01:09,  1.23it/s]136it [01:10,  1.15it/s]137it [01:11,  1.17it/s]138it [01:12,  1.18it/s]139it [01:13,  1.17it/s]140it [01:14,  1.10it/s]141it [01:15,  1.02it/s]142it [01:16,  1.05it/s]143it [01:17,  1.09it/s]144it [01:18,  1.02it/s]145it [01:19,  1.00it/s]146it [01:20,  1.09s/it]147it [01:21,  1.06s/it]148it [01:22,  1.01s/it]149it [01:23,  1.06it/s]150it [01:24,  1.04it/s]151it [01:25,  1.14it/s]152it [01:26,  1.04it/s]153it [01:27,  1.05it/s]154it [01:28,  1.09s/it]155it [01:29,  1.14s/it]156it [01:30,  1.13s/it]157it [01:32,  1.12s/it]158it [01:33,  1.07s/it]159it [01:34,  1.04s/it]160it [01:35,  1.06s/it]161it [01:36,  1.08s/it]162it [01:37,  1.01s/it]163it [01:38,  1.03s/it]164it [01:39,  1.02it/s]165it [01:40,  1.00s/it]166it [01:40,  1.14it/s]167it [01:41,  1.12it/s]168it [01:42,  1.12it/s]169it [01:43,  1.11it/s]170it [01:44,  1.16it/s]171it [01:44,  1.19it/s]172it [01:45,  1.24it/s]173it [01:46,  1.23it/s]174it [01:47,  1.21it/s]175it [01:48,  1.07it/s]176it [01:49,  1.03s/it]177it [01:50,  1.07s/it]178it [01:52,  1.10s/it]179it [01:53,  1.11s/it]180it [01:54,  1.05s/it]181it [01:55,  1.00s/it]182it [01:56,  1.03s/it]183it [01:57,  1.04s/it]184it [01:58,  1.05s/it]185it [01:59,  1.03s/it]186it [02:00,  1.01s/it]187it [02:01,  1.02s/it]188it [02:02,  1.01s/it]189it [02:03,  1.04s/it]190it [02:04,  1.01it/s]191it [02:05,  1.01it/s]192it [02:06,  1.02s/it]193it [02:07,  1.00it/s]194it [02:08,  1.13s/it]195it [02:09,  1.13s/it]196it [02:11,  1.14s/it]197it [02:12,  1.22s/it]198it [02:13,  1.27s/it]199it [02:14,  1.22s/it]200it [02:16,  1.20s/it]201it [02:17,  1.22s/it]202it [02:18,  1.26s/it]203it [02:20,  1.29s/it]204it [02:21,  1.30s/it]205it [02:22,  1.31s/it]206it [02:24,  1.31s/it]207it [02:25,  1.25s/it]208it [02:27,  1.52s/it]209it [02:28,  1.34s/it]210it [02:28,  1.15s/it]211it [02:29,  1.02s/it]212it [02:30,  1.02it/s]213it [02:31,  1.15it/s]214it [02:31,  1.16it/s]215it [02:32,  1.14it/s]216it [02:33,  1.24it/s]217it [02:34,  1.21it/s]218it [02:35,  1.18it/s]219it [02:36,  1.17it/s]220it [02:36,  1.22it/s]221it [02:37,  1.21it/s]222it [02:38,  1.21it/s]223it [02:39,  1.17it/s]224it [02:40,  1.19it/s]225it [02:41,  1.21it/s]226it [02:41,  1.21it/s]227it [02:42,  1.17it/s]228it [02:43,  1.24it/s]229it [02:44,  1.31it/s]230it [02:45,  1.25it/s]231it [02:45,  1.26it/s]232it [02:46,  1.27it/s]233it [02:47,  1.33it/s]234it [02:48,  1.33it/s]235it [02:48,  1.31it/s]236it [02:49,  1.35it/s]237it [02:50,  1.38it/s]238it [02:51,  1.27it/s]239it [02:51,  1.25it/s]240it [02:52,  1.28it/s]241it [02:53,  1.20it/s]242it [02:54,  1.13it/s]243it [02:55,  1.06it/s]244it [02:56,  1.05it/s]245it [02:57,  1.01s/it]246it [02:59,  1.10s/it]247it [03:00,  1.06s/it]248it [03:01,  1.06s/it]249it [03:02,  1.06s/it]250it [03:03,  1.02s/it]251it [03:04,  1.01s/it]252it [03:05,  1.04s/it]253it [03:06,  1.02s/it]254it [03:07,  1.06s/it]255it [03:08,  1.09s/it]256it [03:09,  1.06s/it]257it [03:10,  1.03s/it]258it [03:11,  1.04it/s]259it [03:12,  1.11it/s]260it [03:12,  1.17it/s]261it [03:13,  1.14it/s]262it [03:14,  1.05it/s]263it [03:15,  1.07it/s]264it [03:16,  1.13it/s]265it [03:17,  1.15it/s]266it [03:18,  1.03it/s]267it [03:19,  1.00s/it]268it [03:20,  1.08s/it]269it [03:21,  1.06s/it]270it [03:23,  1.10s/it]271it [03:24,  1.02s/it]272it [03:24,  1.00s/it]273it [03:25,  1.03it/s]274it [03:26,  1.06it/s]275it [03:27,  1.02it/s]276it [03:28,  1.01it/s]277it [03:30,  1.11s/it]278it [03:31,  1.03s/it]279it [03:31,  1.07it/s]280it [03:32,  1.12it/s]281it [03:33,  1.29it/s]282it [03:33,  1.33it/s]283it [03:34,  1.32it/s]284it [03:35,  1.27it/s]285it [03:36,  1.25it/s]286it [03:37,  1.12it/s]287it [03:38,  1.00it/s]288it [03:39,  1.04s/it]289it [03:40,  1.01it/s]290it [03:41,  1.01s/it]291it [03:42,  1.06s/it]292it [03:44,  1.14s/it]293it [03:45,  1.15s/it]294it [03:46,  1.07s/it]295it [03:47,  1.03s/it]296it [03:48,  1.01it/s]297it [03:49,  1.01s/it]298it [03:50,  1.00s/it]299it [03:51,  1.01it/s]300it [03:51,  1.06it/s]301it [03:52,  1.05it/s]302it [03:53,  1.06it/s]303it [03:54,  1.08it/s]304it [03:55,  1.09it/s]305it [03:56,  1.06it/s]306it [03:58,  1.26s/it]307it [03:59,  1.16s/it]308it [04:00,  1.10s/it]309it [04:01,  1.07s/it]310it [04:03,  1.25s/it]311it [04:03,  1.06it/s]312it [04:03,  1.37it/s]313it [04:03,  1.64it/s]314it [04:04,  1.88it/s]315it [04:04,  2.30it/s]316it [04:04,  2.71it/s]317it [04:05,  2.71it/s]318it [04:05,  2.89it/s]319it [04:05,  3.20it/s]320it [04:05,  3.27it/s]321it [04:06,  3.03it/s]322it [04:06,  2.93it/s]323it [04:06,  2.84it/s]324it [04:07,  2.20it/s]325it [04:08,  1.69it/s]326it [04:09,  1.61it/s]327it [04:09,  2.05it/s]328it [04:09,  2.66it/s]329it [04:09,  2.85it/s]330it [04:10,  3.06it/s]331it [04:10,  2.85it/s]332it [04:10,  2.82it/s]333it [04:11,  2.55it/s]334it [04:11,  2.60it/s]335it [04:12,  2.62it/s]336it [04:12,  3.07it/s]337it [04:12,  2.93it/s]338it [04:13,  2.54it/s]339it [04:13,  2.27it/s]340it [04:14,  1.88it/s]341it [04:15,  1.57it/s]342it [04:15,  1.72it/s]343it [04:16,  2.19it/s]344it [04:16,  2.78it/s]345it [04:16,  3.27it/s]346it [04:16,  3.32it/s]347it [04:17,  2.62it/s]348it [04:17,  2.52it/s]349it [04:17,  2.96it/s]350it [04:18,  2.39it/s]351it [04:19,  1.95it/s]352it [04:19,  1.80it/s]353it [04:20,  1.71it/s]354it [04:21,  1.64it/s]355it [04:21,  1.66it/s]356it [04:22,  1.82it/s]357it [04:22,  1.90it/s]358it [04:23,  1.75it/s]359it [04:23,  1.67it/s]360it [04:24,  1.70it/s]360it [04:24,  1.36it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:06<03:27,  6.29s/it]  6%|▌         | 2/34 [00:06<01:26,  2.72s/it]  9%|▉         | 3/34 [00:06<00:48,  1.57s/it] 12%|█▏        | 4/34 [00:06<00:30,  1.03s/it] 15%|█▍        | 5/34 [00:07<00:21,  1.36it/s] 18%|█▊        | 6/34 [00:07<00:15,  1.80it/s] 21%|██        | 7/34 [00:07<00:11,  2.27it/s] 24%|██▎       | 8/34 [00:07<00:09,  2.73it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.15it/s] 29%|██▉       | 10/34 [00:08<00:06,  3.53it/s] 32%|███▏      | 11/34 [00:08<00:05,  3.86it/s] 35%|███▌      | 12/34 [00:08<00:05,  4.12it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.29it/s] 41%|████      | 14/34 [00:08<00:04,  4.45it/s] 44%|████▍     | 15/34 [00:09<00:04,  4.57it/s] 47%|████▋     | 16/34 [00:09<00:03,  4.66it/s] 50%|█████     | 17/34 [00:09<00:03,  4.68it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.74it/s] 56%|█████▌    | 19/34 [00:10<00:03,  4.77it/s] 59%|█████▉    | 20/34 [00:10<00:02,  4.80it/s] 62%|██████▏   | 21/34 [00:10<00:02,  4.78it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.81it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.83it/s] 71%|███████   | 24/34 [00:11<00:02,  4.83it/s] 74%|███████▎  | 25/34 [00:11<00:01,  4.84it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.86it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.87it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.85it/s] 85%|████████▌ | 29/34 [00:12<00:01,  4.81it/s] 88%|████████▊ | 30/34 [00:12<00:00,  4.83it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.84it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.85it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.84it/s]100%|██████████| 34/34 [00:13<00:00,  5.65it/s]100%|██████████| 34/34 [00:13<00:00,  2.57it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536966800689697
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<02:53,  5.26s/it]  6%|▌         | 2/34 [00:05<01:13,  2.29s/it]  9%|▉         | 3/34 [00:05<00:41,  1.34s/it] 12%|█▏        | 4/34 [00:05<00:26,  1.12it/s] 15%|█▍        | 5/34 [00:06<00:18,  1.55it/s] 18%|█▊        | 6/34 [00:06<00:13,  2.01it/s] 21%|██        | 7/34 [00:06<00:10,  2.49it/s] 24%|██▎       | 8/34 [00:06<00:08,  2.95it/s] 26%|██▋       | 9/34 [00:06<00:07,  3.35it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.70it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.95it/s] 35%|███▌      | 12/34 [00:07<00:05,  4.20it/s] 38%|███▊      | 13/34 [00:07<00:04,  4.39it/s] 41%|████      | 14/34 [00:07<00:04,  4.53it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.63it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.70it/s] 50%|█████     | 17/34 [00:08<00:03,  4.75it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.79it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.82it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.80it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.83it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.85it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.86it/s] 71%|███████   | 24/34 [00:10<00:02,  4.87it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.87it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.88it/s] 79%|███████▉  | 27/34 [00:10<00:01,  4.88it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.87it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.86it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.85it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.86it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.87it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.88it/s]100%|██████████| 34/34 [00:11<00:00,  5.69it/s]100%|██████████| 34/34 [00:12<00:00,  2.79it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6507176160812378


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36966705322266
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.23310023310024
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.05209457886738
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.26982056907829


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.07176208496094
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  1.38it/s]2it [00:01,  1.53it/s]3it [00:01,  1.73it/s]4it [00:02,  1.64it/s]5it [00:03,  1.55it/s]6it [00:03,  1.55it/s]7it [00:04,  1.57it/s]8it [00:05,  1.49it/s]9it [00:06,  1.38it/s]10it [00:06,  1.31it/s]11it [00:07,  1.25it/s]12it [00:08,  1.17it/s]13it [00:09,  1.07it/s]14it [00:10,  1.03it/s]15it [00:11,  1.08it/s]16it [00:12,  1.07it/s]17it [00:13,  1.13it/s]18it [00:14,  1.11it/s]19it [00:15,  1.17it/s]20it [00:15,  1.23it/s]21it [00:16,  1.30it/s]22it [00:17,  1.28it/s]23it [00:18,  1.29it/s]24it [00:18,  1.29it/s]25it [00:19,  1.27it/s]26it [00:20,  1.29it/s]27it [00:21,  1.36it/s]28it [00:21,  1.41it/s]29it [00:22,  1.44it/s]30it [00:23,  1.43it/s]31it [00:23,  1.35it/s]32it [00:24,  1.21it/s]33it [00:25,  1.13it/s]34it [00:26,  1.10it/s]35it [00:27,  1.15it/s]36it [00:28,  1.21it/s]37it [00:29,  1.23it/s]38it [00:29,  1.28it/s]39it [00:30,  1.25it/s]40it [00:31,  1.20it/s]41it [00:32,  1.21it/s]42it [00:33,  1.25it/s]43it [00:34,  1.28it/s]44it [00:34,  1.26it/s]45it [00:35,  1.25it/s]46it [00:36,  1.23it/s]47it [00:37,  1.25it/s]48it [00:38,  1.23it/s]49it [00:38,  1.22it/s]50it [00:39,  1.24it/s]51it [00:40,  1.22it/s]52it [00:41,  1.27it/s]53it [00:42,  1.23it/s]54it [00:43,  1.15it/s]55it [00:44,  1.07it/s]56it [00:45,  1.09it/s]57it [00:45,  1.14it/s]58it [00:46,  1.15it/s]59it [00:48,  1.17s/it]60it [00:49,  1.08s/it]61it [00:50,  1.02it/s]62it [00:50,  1.16it/s]63it [00:52,  1.01s/it]64it [00:53,  1.04it/s]65it [00:53,  1.10it/s]66it [00:54,  1.19it/s]67it [00:55,  1.25it/s]68it [00:55,  1.25it/s]69it [00:56,  1.29it/s]70it [00:57,  1.47it/s]71it [00:57,  1.65it/s]72it [00:58,  1.70it/s]73it [00:58,  1.61it/s]74it [00:59,  1.99it/s]75it [00:59,  1.89it/s]76it [00:59,  2.29it/s]77it [01:00,  2.72it/s]78it [01:00,  2.93it/s]79it [01:00,  3.05it/s]80it [01:00,  3.20it/s]81it [01:01,  3.83it/s]82it [01:01,  2.99it/s]83it [01:01,  3.03it/s]84it [01:02,  3.46it/s]85it [01:02,  3.34it/s]86it [01:02,  3.46it/s]87it [01:03,  2.65it/s]88it [01:03,  2.37it/s]89it [01:04,  2.56it/s]90it [01:04,  2.44it/s]91it [01:05,  2.41it/s]92it [01:05,  2.62it/s]93it [01:05,  2.78it/s]94it [01:05,  3.16it/s]95it [01:06,  3.46it/s]96it [01:06,  3.66it/s]97it [01:06,  3.58it/s]98it [01:07,  3.10it/s]99it [01:07,  2.64it/s]100it [01:07,  3.03it/s]101it [01:08,  2.58it/s]102it [01:08,  2.29it/s]103it [01:09,  2.65it/s]104it [01:09,  2.89it/s]105it [01:09,  2.36it/s]106it [01:10,  2.11it/s]107it [01:10,  2.29it/s]108it [01:11,  2.28it/s]109it [01:11,  2.67it/s]110it [01:12,  2.39it/s]111it [01:12,  2.15it/s]112it [01:13,  1.95it/s]113it [01:13,  2.19it/s]114it [01:13,  2.40it/s]115it [01:14,  2.41it/s]117it [01:14,  3.72it/s]119it [01:14,  5.14it/s]121it [01:14,  6.50it/s]123it [01:15,  6.64it/s]125it [01:15,  8.03it/s]127it [01:15,  9.29it/s]129it [01:15, 10.84it/s]131it [01:15, 11.01it/s]133it [01:15,  9.32it/s]135it [01:16, 10.44it/s]137it [01:16, 11.39it/s]139it [01:16, 12.22it/s]141it [01:16, 12.87it/s]143it [01:16, 13.05it/s]145it [01:16, 12.39it/s]147it [01:17, 12.15it/s]149it [01:17, 12.00it/s]151it [01:17, 10.69it/s]153it [01:17, 10.54it/s]155it [01:18,  5.59it/s]156it [01:18,  5.98it/s]158it [01:18,  7.41it/s]160it [01:18,  8.75it/s]162it [01:19,  8.92it/s]164it [01:19,  9.25it/s]166it [01:19,  9.97it/s]168it [01:19, 10.19it/s]170it [01:19, 10.54it/s]172it [01:19, 10.50it/s]174it [01:20,  6.39it/s]176it [01:20,  7.56it/s]178it [01:20,  8.80it/s]180it [01:20,  9.67it/s]182it [01:21, 10.56it/s]184it [01:21, 11.49it/s]186it [01:21, 10.24it/s]188it [01:21,  8.37it/s]189it [01:21,  8.10it/s]191it [01:22,  8.20it/s]192it [01:22,  6.74it/s]193it [01:22,  6.34it/s]194it [01:22,  6.73it/s]195it [01:23,  5.81it/s]196it [01:23,  6.07it/s]197it [01:23,  6.47it/s]199it [01:23,  8.26it/s]201it [01:23,  9.58it/s]203it [01:23, 10.94it/s]205it [01:23, 10.25it/s]207it [01:24,  8.22it/s]208it [01:25,  4.06it/s]209it [01:25,  3.08it/s]210it [01:26,  2.53it/s]211it [01:26,  2.64it/s]213it [01:26,  3.52it/s]214it [01:27,  3.56it/s]215it [01:27,  2.71it/s]216it [01:28,  2.32it/s]217it [01:29,  2.17it/s]218it [01:29,  2.07it/s]219it [01:30,  1.82it/s]220it [01:30,  2.01it/s]221it [01:31,  2.14it/s]222it [01:31,  2.62it/s]223it [01:31,  2.46it/s]224it [01:32,  2.29it/s]225it [01:32,  2.22it/s]226it [01:33,  2.26it/s]227it [01:33,  2.64it/s]228it [01:33,  2.29it/s]229it [01:34,  2.41it/s]230it [01:34,  2.28it/s]231it [01:35,  2.47it/s]232it [01:35,  2.87it/s]233it [01:35,  2.95it/s]234it [01:36,  2.53it/s]235it [01:36,  3.21it/s]236it [01:36,  3.17it/s]237it [01:36,  3.11it/s]238it [01:37,  2.98it/s]239it [01:37,  3.23it/s]240it [01:38,  2.84it/s]241it [01:38,  2.90it/s]242it [01:38,  2.46it/s]243it [01:39,  2.40it/s]244it [01:39,  2.22it/s]245it [01:40,  2.64it/s]246it [01:40,  2.33it/s]247it [01:41,  2.13it/s]248it [01:41,  2.12it/s]249it [01:42,  2.09it/s]250it [01:42,  1.95it/s]251it [01:43,  1.77it/s]252it [01:44,  1.64it/s]253it [01:44,  1.55it/s]254it [01:45,  1.48it/s]255it [01:46,  1.44it/s]256it [01:47,  1.44it/s]257it [01:47,  1.40it/s]258it [01:47,  1.81it/s]259it [01:48,  1.87it/s]260it [01:48,  2.08it/s]261it [01:49,  1.95it/s]262it [01:49,  2.07it/s]263it [01:50,  2.43it/s]264it [01:50,  2.36it/s]265it [01:50,  2.37it/s]266it [01:51,  2.45it/s]267it [01:51,  2.68it/s]268it [01:52,  2.04it/s]269it [01:53,  1.82it/s]270it [01:53,  1.81it/s]271it [01:54,  1.77it/s]272it [01:54,  1.72it/s]273it [01:55,  1.78it/s]274it [01:55,  1.90it/s]275it [01:55,  2.34it/s]276it [01:56,  2.62it/s]277it [01:56,  2.71it/s]278it [01:56,  2.89it/s]279it [01:57,  2.97it/s]280it [01:57,  3.09it/s]281it [01:57,  3.55it/s]282it [01:58,  3.15it/s]283it [01:58,  2.73it/s]284it [01:59,  2.39it/s]285it [01:59,  2.46it/s]286it [01:59,  2.35it/s]287it [02:00,  2.72it/s]288it [02:00,  3.02it/s]289it [02:00,  3.23it/s]290it [02:01,  3.13it/s]291it [02:01,  3.30it/s]292it [02:01,  3.06it/s]293it [02:01,  3.23it/s]294it [02:02,  2.88it/s]295it [02:02,  2.41it/s]296it [02:03,  2.10it/s]297it [02:04,  2.07it/s]298it [02:04,  2.03it/s]299it [02:04,  2.25it/s]300it [02:05,  2.29it/s]301it [02:05,  2.11it/s]302it [02:06,  2.17it/s]303it [02:06,  2.14it/s]304it [02:07,  2.62it/s]306it [02:07,  3.01it/s]308it [02:07,  4.37it/s]309it [02:07,  4.98it/s]310it [02:08,  4.05it/s]312it [02:08,  5.59it/s]314it [02:08,  7.23it/s]316it [02:08,  8.58it/s]318it [02:08,  9.78it/s]320it [02:08, 10.55it/s]322it [02:09, 10.84it/s]324it [02:09, 11.00it/s]326it [02:09, 11.41it/s]328it [02:09, 11.90it/s]330it [02:09, 12.45it/s]332it [02:09, 11.57it/s]334it [02:10, 11.60it/s]336it [02:10, 12.11it/s]338it [02:10, 11.72it/s]340it [02:10, 11.99it/s]342it [02:11,  5.92it/s]343it [02:11,  5.32it/s]344it [02:11,  5.86it/s]345it [02:11,  6.41it/s]347it [02:11,  7.84it/s]348it [02:12,  4.76it/s]349it [02:12,  5.12it/s]350it [02:13,  3.57it/s]351it [02:13,  3.49it/s]352it [02:13,  3.17it/s]353it [02:14,  2.63it/s]354it [02:14,  2.93it/s]355it [02:15,  2.66it/s]356it [02:15,  2.10it/s]357it [02:16,  2.37it/s]358it [02:16,  2.33it/s]359it [02:16,  2.71it/s]360it [02:17,  2.66it/s]360it [02:17,  2.62it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:01,  5.51s/it]  6%|▌         | 2/34 [00:05<01:17,  2.41s/it]  9%|▉         | 3/34 [00:06<00:44,  1.44s/it] 12%|█▏        | 4/34 [00:06<00:29,  1.02it/s] 15%|█▍        | 5/34 [00:06<00:22,  1.28it/s] 18%|█▊        | 6/34 [00:07<00:17,  1.62it/s] 21%|██        | 7/34 [00:07<00:13,  1.96it/s] 24%|██▎       | 8/34 [00:07<00:11,  2.25it/s] 26%|██▋       | 9/34 [00:07<00:09,  2.51it/s] 29%|██▉       | 10/34 [00:08<00:08,  2.74it/s] 32%|███▏      | 11/34 [00:08<00:07,  2.92it/s] 35%|███▌      | 12/34 [00:08<00:07,  3.06it/s] 38%|███▊      | 13/34 [00:09<00:06,  3.18it/s] 41%|████      | 14/34 [00:09<00:05,  3.52it/s] 44%|████▍     | 15/34 [00:09<00:04,  3.85it/s] 47%|████▋     | 16/34 [00:09<00:04,  4.11it/s] 50%|█████     | 17/34 [00:09<00:03,  4.32it/s] 53%|█████▎    | 18/34 [00:10<00:03,  4.48it/s] 56%|█████▌    | 19/34 [00:10<00:03,  4.60it/s] 59%|█████▉    | 20/34 [00:10<00:02,  4.69it/s] 62%|██████▏   | 21/34 [00:10<00:02,  4.75it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.80it/s] 68%|██████▊   | 23/34 [00:11<00:02,  4.83it/s] 71%|███████   | 24/34 [00:11<00:02,  4.85it/s] 74%|███████▎  | 25/34 [00:11<00:01,  4.86it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.88it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.89it/s] 82%|████████▏ | 28/34 [00:12<00:01,  4.89it/s] 85%|████████▌ | 29/34 [00:12<00:01,  4.89it/s] 88%|████████▊ | 30/34 [00:12<00:00,  4.89it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.89it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:13<00:00,  4.90it/s]100%|██████████| 34/34 [00:13<00:00,  5.65it/s]100%|██████████| 34/34 [00:13<00:00,  2.51it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:17,  5.97s/it]  6%|▌         | 2/34 [00:06<01:22,  2.58s/it]  9%|▉         | 3/34 [00:06<00:46,  1.50s/it] 12%|█▏        | 4/34 [00:06<00:29,  1.01it/s] 15%|█▍        | 5/34 [00:06<00:20,  1.41it/s] 18%|█▊        | 6/34 [00:07<00:15,  1.85it/s] 21%|██        | 7/34 [00:07<00:11,  2.31it/s] 24%|██▎       | 8/34 [00:07<00:09,  2.77it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.18it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.55it/s] 32%|███▏      | 11/34 [00:08<00:05,  3.85it/s] 35%|███▌      | 12/34 [00:08<00:05,  4.08it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.23it/s] 41%|████      | 14/34 [00:08<00:04,  4.38it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.48it/s] 47%|████▋     | 16/34 [00:09<00:03,  4.55it/s] 50%|█████     | 17/34 [00:09<00:03,  4.60it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.68it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.69it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.70it/s] 62%|██████▏   | 21/34 [00:10<00:02,  4.70it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.72it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.73it/s] 71%|███████   | 24/34 [00:10<00:02,  4.70it/s] 74%|███████▎  | 25/34 [00:11<00:01,  4.71it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.73it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.73it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.73it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.74it/s] 88%|████████▊ | 30/34 [00:12<00:00,  4.75it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.75it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.76it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.76it/s]100%|██████████| 34/34 [00:12<00:00,  5.52it/s]100%|██████████| 34/34 [00:13<00:00,  2.60it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6506965756416321


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.53613053613054
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.12390997171516
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.64393651110598


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.06965637207031
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 13.39it/s]4it [00:00, 13.51it/s]6it [00:00, 13.73it/s]8it [00:00, 12.53it/s]10it [00:00, 12.12it/s]12it [00:00, 12.19it/s]14it [00:01, 12.98it/s]16it [00:01, 14.05it/s]18it [00:01, 14.29it/s]20it [00:01, 14.72it/s]22it [00:01, 14.89it/s]24it [00:01, 15.23it/s]26it [00:01, 14.38it/s]28it [00:01, 15.28it/s]30it [00:02, 15.73it/s]32it [00:02, 16.04it/s]34it [00:02, 16.07it/s]36it [00:02, 15.60it/s]38it [00:02, 15.76it/s]40it [00:02, 15.76it/s]42it [00:02, 13.67it/s]44it [00:03, 14.06it/s]46it [00:03, 13.22it/s]48it [00:03, 12.58it/s]50it [00:03, 11.88it/s]52it [00:03, 11.32it/s]54it [00:03, 11.10it/s]56it [00:04, 10.95it/s]58it [00:04, 11.21it/s]60it [00:04,  9.80it/s]62it [00:04, 10.50it/s]64it [00:05,  7.21it/s]66it [00:05,  8.39it/s]68it [00:05,  9.09it/s]70it [00:05,  9.43it/s]72it [00:05, 10.28it/s]74it [00:06, 11.04it/s]76it [00:06,  9.44it/s]78it [00:06,  9.94it/s]80it [00:06, 10.51it/s]82it [00:06, 11.62it/s]84it [00:07, 11.52it/s]86it [00:07, 10.32it/s]88it [00:07, 11.09it/s]90it [00:07, 11.73it/s]92it [00:07,  8.39it/s]94it [00:08,  8.94it/s]96it [00:08,  9.90it/s]98it [00:08,  8.91it/s]100it [00:08, 10.17it/s]102it [00:08, 10.13it/s]104it [00:09, 10.56it/s]106it [00:09, 10.82it/s]108it [00:09, 11.62it/s]110it [00:09, 12.28it/s]112it [00:09, 11.87it/s]114it [00:09, 12.52it/s]116it [00:10,  9.09it/s]118it [00:10,  9.60it/s]120it [00:10, 10.35it/s]122it [00:10, 10.81it/s]124it [00:10, 10.95it/s]126it [00:11,  7.32it/s]128it [00:11,  8.24it/s]130it [00:11,  9.48it/s]132it [00:11,  9.49it/s]134it [00:12,  9.45it/s]136it [00:12,  9.06it/s]138it [00:12,  9.93it/s]140it [00:12, 10.68it/s]142it [00:12, 11.24it/s]144it [00:12, 11.89it/s]146it [00:13, 11.44it/s]148it [00:13, 12.23it/s]150it [00:13, 12.71it/s]152it [00:13, 12.75it/s]154it [00:13, 11.36it/s]156it [00:13, 10.91it/s]158it [00:14, 11.65it/s]160it [00:14, 11.66it/s]162it [00:14, 12.82it/s]164it [00:14, 13.48it/s]166it [00:14, 13.45it/s]168it [00:14, 14.55it/s]170it [00:14, 14.88it/s]172it [00:15, 14.62it/s]174it [00:15, 13.60it/s]176it [00:15, 13.63it/s]178it [00:15, 13.13it/s]180it [00:15, 13.41it/s]182it [00:15, 13.92it/s]184it [00:15, 13.82it/s]186it [00:16, 14.10it/s]188it [00:16, 13.23it/s]190it [00:16, 13.49it/s]192it [00:16, 12.56it/s]194it [00:16, 11.83it/s]196it [00:16, 12.72it/s]198it [00:17,  5.56it/s]199it [00:18,  5.25it/s]200it [00:18,  5.51it/s]201it [00:18,  5.59it/s]202it [00:19,  3.38it/s]203it [00:19,  2.32it/s]204it [00:20,  2.29it/s]205it [00:20,  2.05it/s]206it [00:21,  1.85it/s]207it [00:21,  2.04it/s]208it [00:22,  1.58it/s]209it [00:23,  1.76it/s]210it [00:23,  1.70it/s]211it [00:24,  1.76it/s]212it [00:24,  1.84it/s]213it [00:25,  2.37it/s]214it [00:25,  2.63it/s]215it [00:25,  2.52it/s]216it [00:26,  2.77it/s]217it [00:26,  3.09it/s]218it [00:26,  3.88it/s]219it [00:26,  3.35it/s]220it [00:27,  3.14it/s]221it [00:27,  3.17it/s]222it [00:27,  2.78it/s]223it [00:28,  2.95it/s]224it [00:28,  2.92it/s]225it [00:29,  2.70it/s]226it [00:29,  2.32it/s]227it [00:30,  2.11it/s]228it [00:30,  2.21it/s]229it [00:30,  2.60it/s]230it [00:31,  2.38it/s]231it [00:31,  2.15it/s]232it [00:32,  2.37it/s]233it [00:32,  2.49it/s]234it [00:32,  2.53it/s]235it [00:33,  2.54it/s]236it [00:33,  2.22it/s]237it [00:34,  1.98it/s]238it [00:35,  1.90it/s]239it [00:35,  1.87it/s]240it [00:36,  2.10it/s]241it [00:36,  2.02it/s]242it [00:36,  2.39it/s]243it [00:37,  2.45it/s]244it [00:37,  2.50it/s]245it [00:37,  2.97it/s]246it [00:38,  2.31it/s]247it [00:38,  2.59it/s]248it [00:39,  2.10it/s]249it [00:40,  1.78it/s]250it [00:40,  1.66it/s]251it [00:41,  1.57it/s]252it [00:42,  1.42it/s]253it [00:42,  1.55it/s]254it [00:43,  1.86it/s]255it [00:43,  1.99it/s]256it [00:44,  1.79it/s]257it [00:45,  1.62it/s]258it [00:45,  1.56it/s]259it [00:46,  1.60it/s]260it [00:47,  1.58it/s]261it [00:47,  1.53it/s]262it [00:48,  1.46it/s]263it [00:49,  1.45it/s]264it [00:50,  1.33it/s]265it [00:50,  1.30it/s]266it [00:51,  1.39it/s]267it [00:52,  1.37it/s]268it [00:52,  1.40it/s]269it [00:53,  1.41it/s]270it [00:54,  1.39it/s]271it [00:55,  1.35it/s]272it [00:56,  1.28it/s]273it [00:56,  1.28it/s]274it [00:57,  1.35it/s]275it [00:58,  1.38it/s]276it [00:58,  1.42it/s]277it [00:59,  1.30it/s]278it [01:00,  1.32it/s]279it [01:01,  1.33it/s]280it [01:01,  1.50it/s]281it [01:02,  1.57it/s]282it [01:02,  1.61it/s]283it [01:03,  1.51it/s]284it [01:04,  1.48it/s]285it [01:04,  1.54it/s]286it [01:05,  1.55it/s]287it [01:06,  1.46it/s]288it [01:06,  1.44it/s]289it [01:07,  1.43it/s]290it [01:08,  1.37it/s]291it [01:09,  1.42it/s]292it [01:09,  1.41it/s]293it [01:10,  1.41it/s]294it [01:10,  1.63it/s]295it [01:11,  1.59it/s]296it [01:12,  1.54it/s]297it [01:13,  1.44it/s]298it [01:13,  1.39it/s]299it [01:14,  1.38it/s]300it [01:15,  1.41it/s]301it [01:16,  1.40it/s]302it [01:16,  1.45it/s]303it [01:17,  1.42it/s]304it [01:18,  1.47it/s]305it [01:18,  1.47it/s]306it [01:20,  1.03it/s]307it [01:21,  1.09it/s]308it [01:21,  1.16it/s]309it [01:22,  1.23it/s]310it [01:24,  1.04s/it]311it [01:25,  1.02it/s]312it [01:25,  1.10it/s]313it [01:26,  1.20it/s]314it [01:27,  1.28it/s]315it [01:27,  1.31it/s]316it [01:28,  1.32it/s]317it [01:29,  1.32it/s]318it [01:29,  1.35it/s]319it [01:30,  1.39it/s]320it [01:31,  1.41it/s]321it [01:32,  1.43it/s]322it [01:32,  1.41it/s]323it [01:33,  1.67it/s]324it [01:33,  1.90it/s]325it [01:33,  2.16it/s]326it [01:34,  2.26it/s]327it [01:34,  2.19it/s]328it [01:35,  2.10it/s]329it [01:35,  2.45it/s]330it [01:35,  2.23it/s]331it [01:36,  2.57it/s]332it [01:36,  2.82it/s]333it [01:37,  2.35it/s]334it [01:37,  2.26it/s]335it [01:38,  1.98it/s]336it [01:38,  2.01it/s]337it [01:39,  2.03it/s]338it [01:39,  2.14it/s]339it [01:39,  2.44it/s]340it [01:40,  2.44it/s]341it [01:40,  2.26it/s]342it [01:41,  2.35it/s]343it [01:41,  2.43it/s]344it [01:42,  1.94it/s]345it [01:42,  1.84it/s]346it [01:43,  2.05it/s]347it [01:43,  2.13it/s]348it [01:44,  2.39it/s]349it [01:44,  2.38it/s]350it [01:44,  2.38it/s]351it [01:45,  2.31it/s]352it [01:45,  2.27it/s]353it [01:46,  2.51it/s]354it [01:46,  2.64it/s]355it [01:46,  2.46it/s]356it [01:47,  2.71it/s]357it [01:47,  2.76it/s]359it [01:47,  3.62it/s]360it [01:48,  3.50it/s]360it [01:48,  3.33it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:35,  4.70s/it]  6%|▌         | 2/34 [00:04<01:07,  2.10s/it]  9%|▉         | 3/34 [00:05<00:39,  1.28s/it] 12%|█▏        | 4/34 [00:05<00:26,  1.13it/s] 15%|█▍        | 5/34 [00:05<00:19,  1.49it/s] 18%|█▊        | 6/34 [00:06<00:15,  1.84it/s] 21%|██        | 7/34 [00:06<00:12,  2.18it/s] 24%|██▎       | 8/34 [00:06<00:10,  2.52it/s] 26%|██▋       | 9/34 [00:06<00:08,  2.97it/s] 29%|██▉       | 10/34 [00:07<00:07,  3.38it/s] 32%|███▏      | 11/34 [00:07<00:06,  3.73it/s] 35%|███▌      | 12/34 [00:07<00:05,  4.03it/s] 38%|███▊      | 13/34 [00:07<00:04,  4.26it/s] 41%|████      | 14/34 [00:07<00:04,  4.43it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.57it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.66it/s] 50%|█████     | 17/34 [00:08<00:03,  4.73it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.78it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.82it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.84it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.86it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.87it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.88it/s] 71%|███████   | 24/34 [00:09<00:02,  4.88it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.89it/s] 79%|███████▉  | 27/34 [00:10<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.90it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.91it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.91it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.90it/s]100%|██████████| 34/34 [00:11<00:00,  5.72it/s]100%|██████████| 34/34 [00:12<00:00,  2.80it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:02,  3.73s/it]  6%|▌         | 2/34 [00:04<00:55,  1.73s/it]  9%|▉         | 3/34 [00:04<00:32,  1.04s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.39it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.84it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.34it/s] 21%|██        | 7/34 [00:05<00:09,  2.79it/s] 24%|██▎       | 8/34 [00:05<00:08,  3.19it/s] 26%|██▋       | 9/34 [00:05<00:07,  3.56it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.80it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.00it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.14it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.28it/s] 41%|████      | 14/34 [00:06<00:04,  4.41it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.44it/s] 47%|████▋     | 16/34 [00:07<00:04,  4.46it/s] 50%|█████     | 17/34 [00:07<00:03,  4.48it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.47it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.48it/s] 59%|█████▉    | 20/34 [00:08<00:03,  3.88it/s] 62%|██████▏   | 21/34 [00:08<00:04,  3.21it/s] 65%|██████▍   | 22/34 [00:09<00:04,  2.86it/s] 68%|██████▊   | 23/34 [00:09<00:04,  2.66it/s] 71%|███████   | 24/34 [00:09<00:03,  2.54it/s] 74%|███████▎  | 25/34 [00:10<00:03,  2.56it/s] 76%|███████▋  | 26/34 [00:10<00:02,  2.98it/s] 79%|███████▉  | 27/34 [00:10<00:02,  3.37it/s] 82%|████████▏ | 28/34 [00:10<00:01,  3.72it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.00it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.23it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.41it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.54it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.63it/s]100%|██████████| 34/34 [00:12<00:00,  5.45it/s]100%|██████████| 34/34 [00:12<00:00,  2.79it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6505043506622314


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.256410256410255
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.1256176144535
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.35272789644964


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.0504379272461
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  7.52it/s]2it [00:00,  8.77it/s]3it [00:00,  9.14it/s]5it [00:00, 11.02it/s]7it [00:00,  8.33it/s]8it [00:00,  8.38it/s]9it [00:01,  6.83it/s]11it [00:01,  8.65it/s]13it [00:01, 10.02it/s]15it [00:01, 10.84it/s]17it [00:01, 11.74it/s]19it [00:01, 11.43it/s]21it [00:02,  9.96it/s]23it [00:02,  9.43it/s]25it [00:02,  9.99it/s]27it [00:02, 11.30it/s]29it [00:02, 12.95it/s]31it [00:02, 14.22it/s]33it [00:03, 14.92it/s]35it [00:03, 15.82it/s]37it [00:03, 16.85it/s]39it [00:03, 16.84it/s]41it [00:03, 17.07it/s]43it [00:03, 16.10it/s]45it [00:03, 16.69it/s]47it [00:03, 16.99it/s]49it [00:03, 17.11it/s]51it [00:04, 17.12it/s]53it [00:04, 16.22it/s]55it [00:04, 16.06it/s]57it [00:04, 16.03it/s]59it [00:04, 14.13it/s]61it [00:04, 14.14it/s]63it [00:05,  9.70it/s]65it [00:05, 10.45it/s]67it [00:05, 10.76it/s]69it [00:05, 11.33it/s]71it [00:05, 11.82it/s]73it [00:05, 12.31it/s]75it [00:06, 10.92it/s]77it [00:06, 12.06it/s]79it [00:06, 12.43it/s]81it [00:06, 13.06it/s]83it [00:06, 12.87it/s]85it [00:06, 13.51it/s]87it [00:07, 11.99it/s]89it [00:07,  6.26it/s]91it [00:07,  7.62it/s]93it [00:07,  9.32it/s]95it [00:08, 10.55it/s]97it [00:09,  2.96it/s]99it [00:11,  2.22it/s]100it [00:11,  2.38it/s]101it [00:12,  1.73it/s]102it [00:14,  1.35it/s]103it [00:15,  1.18it/s]104it [00:16,  1.08it/s]105it [00:17,  1.06it/s]106it [00:18,  1.04it/s]107it [00:19,  1.01it/s]108it [00:20,  1.03s/it]109it [00:21,  1.08s/it]110it [00:22,  1.08s/it]111it [00:24,  1.11s/it]112it [00:25,  1.10s/it]113it [00:26,  1.12s/it]114it [00:27,  1.17s/it]115it [00:29,  1.27s/it]116it [00:30,  1.30s/it]117it [00:31,  1.34s/it]118it [00:33,  1.26s/it]119it [00:34,  1.27s/it]120it [00:35,  1.24s/it]121it [00:36,  1.26s/it]122it [00:37,  1.22s/it]123it [00:39,  1.24s/it]124it [00:39,  1.09s/it]125it [00:40,  1.00it/s]126it [00:41,  1.06it/s]127it [00:42,  1.15it/s]128it [00:43,  1.15it/s]129it [00:43,  1.16it/s]130it [00:44,  1.29it/s]131it [00:45,  1.33it/s]132it [00:46,  1.12it/s]133it [00:47,  1.14it/s]134it [00:48,  1.17it/s]135it [00:48,  1.21it/s]136it [00:49,  1.18it/s]137it [00:50,  1.18it/s]138it [00:51,  1.16it/s]139it [00:52,  1.20it/s]140it [00:53,  1.11it/s]141it [00:54,  1.06s/it]142it [00:55,  1.02s/it]143it [00:56,  1.05it/s]144it [00:57,  1.07it/s]145it [00:58,  1.13it/s]146it [00:58,  1.17it/s]147it [00:59,  1.17it/s]148it [01:00,  1.20it/s]149it [01:01,  1.24it/s]150it [01:02,  1.29it/s]151it [01:02,  1.28it/s]152it [01:03,  1.35it/s]153it [01:04,  1.33it/s]154it [01:05,  1.20it/s]155it [01:06,  1.22it/s]156it [01:07,  1.03it/s]157it [01:08,  1.08s/it]158it [01:09,  1.08s/it]159it [01:10,  1.05s/it]160it [01:11,  1.07it/s]161it [01:12,  1.10it/s]162it [01:13,  1.12it/s]163it [01:14,  1.07it/s]164it [01:15,  1.05it/s]165it [01:16,  1.05it/s]166it [01:17,  1.06it/s]167it [01:18,  1.01it/s]168it [01:19,  1.02it/s]169it [01:19,  1.06it/s]170it [01:20,  1.03it/s]171it [01:22,  1.01s/it]172it [01:23,  1.03s/it]173it [01:24,  1.09s/it]174it [01:25,  1.06s/it]175it [01:26,  1.05s/it]176it [01:27,  1.03s/it]177it [01:28,  1.01s/it]178it [01:29,  1.03it/s]179it [01:30,  1.08it/s]180it [01:30,  1.11it/s]181it [01:31,  1.12it/s]182it [01:32,  1.12it/s]183it [01:33,  1.09it/s]184it [01:34,  1.08it/s]185it [01:35,  1.01it/s]186it [01:36,  1.03it/s]187it [01:37,  1.05it/s]188it [01:38,  1.02s/it]189it [01:39,  1.08s/it]190it [01:41,  1.10s/it]191it [01:42,  1.13s/it]192it [01:43,  1.15s/it]193it [01:44,  1.12s/it]194it [01:45,  1.09s/it]195it [01:46,  1.03s/it]196it [01:47,  1.06s/it]197it [01:48,  1.07s/it]198it [01:49,  1.12s/it]199it [01:50,  1.07s/it]200it [01:52,  1.11s/it]201it [01:53,  1.14s/it]202it [01:53,  1.06it/s]203it [01:54,  1.15it/s]204it [01:55,  1.20it/s]205it [01:56,  1.08it/s]206it [01:57,  1.14it/s]207it [01:57,  1.30it/s]208it [01:59,  1.02it/s]209it [02:00,  1.02s/it]210it [02:00,  1.12it/s]211it [02:01,  1.21it/s]212it [02:02,  1.21it/s]213it [02:03,  1.18it/s]214it [02:04,  1.19it/s]215it [02:04,  1.21it/s]216it [02:05,  1.24it/s]217it [02:06,  1.26it/s]218it [02:07,  1.21it/s]219it [02:08,  1.19it/s]220it [02:08,  1.33it/s]221it [02:09,  1.38it/s]222it [02:10,  1.37it/s]223it [02:10,  1.38it/s]224it [02:11,  1.59it/s]225it [02:11,  1.55it/s]226it [02:12,  1.45it/s]227it [02:13,  1.38it/s]228it [02:14,  1.41it/s]229it [02:14,  1.43it/s]230it [02:15,  1.41it/s]231it [02:16,  1.38it/s]232it [02:17,  1.36it/s]233it [02:17,  1.35it/s]234it [02:18,  1.35it/s]235it [02:19,  1.26it/s]236it [02:21,  1.04s/it]237it [02:22,  1.14s/it]238it [02:24,  1.25s/it]239it [02:24,  1.14s/it]240it [02:25,  1.03s/it]241it [02:26,  1.01it/s]242it [02:27,  1.01it/s]243it [02:28,  1.02s/it]244it [02:29,  1.04it/s]245it [02:30,  1.03it/s]246it [02:32,  1.14s/it]247it [02:33,  1.17s/it]248it [02:34,  1.19s/it]249it [02:35,  1.18s/it]250it [02:36,  1.20s/it]251it [02:37,  1.08s/it]252it [02:38,  1.02s/it]253it [02:39,  1.03s/it]254it [02:40,  1.00s/it]255it [02:41,  1.02it/s]256it [02:42,  1.03it/s]257it [02:43,  1.01s/it]258it [02:44,  1.01it/s]259it [02:45,  1.00it/s]260it [02:46,  1.01s/it]261it [02:47,  1.06s/it]262it [02:48,  1.02s/it]263it [02:49,  1.04it/s]264it [02:50,  1.11it/s]265it [02:50,  1.15it/s]266it [02:51,  1.14it/s]267it [02:52,  1.12it/s]268it [02:53,  1.08it/s]269it [02:54,  1.15it/s]270it [02:54,  1.51it/s]271it [02:54,  1.96it/s]272it [02:55,  2.46it/s]273it [02:55,  3.08it/s]274it [02:55,  3.62it/s]275it [02:55,  3.91it/s]276it [02:55,  4.35it/s]277it [02:56,  3.68it/s]278it [02:56,  3.93it/s]279it [02:56,  4.30it/s]280it [02:56,  4.40it/s]281it [02:56,  4.71it/s]282it [02:57,  4.48it/s]283it [02:57,  4.64it/s]284it [02:57,  5.31it/s]285it [02:57,  5.38it/s]286it [02:57,  6.19it/s]287it [02:58,  3.95it/s]288it [02:58,  3.97it/s]289it [02:58,  3.19it/s]290it [02:59,  3.29it/s]291it [02:59,  2.83it/s]292it [03:00,  2.57it/s]293it [03:00,  2.00it/s]294it [03:01,  1.94it/s]295it [03:01,  2.16it/s]296it [03:02,  2.37it/s]297it [03:02,  3.01it/s]298it [03:02,  3.23it/s]299it [03:02,  3.80it/s]300it [03:02,  4.20it/s]301it [03:03,  4.08it/s]302it [03:03,  2.45it/s]303it [03:04,  2.32it/s]304it [03:04,  2.47it/s]305it [03:04,  2.71it/s]306it [03:05,  1.97it/s]307it [03:06,  2.07it/s]308it [03:06,  2.25it/s]309it [03:07,  2.28it/s]310it [03:08,  1.48it/s]311it [03:08,  1.95it/s]312it [03:08,  2.47it/s]314it [03:08,  3.55it/s]316it [03:09,  4.77it/s]317it [03:09,  5.02it/s]319it [03:09,  5.48it/s]320it [03:09,  5.55it/s]321it [03:09,  5.45it/s]322it [03:10,  5.74it/s]323it [03:10,  5.56it/s]324it [03:10,  5.57it/s]325it [03:10,  6.34it/s]327it [03:10,  6.36it/s]328it [03:10,  5.99it/s]329it [03:11,  5.23it/s]330it [03:11,  4.40it/s]331it [03:11,  4.72it/s]332it [03:12,  3.74it/s]333it [03:12,  3.00it/s]334it [03:12,  3.26it/s]335it [03:13,  2.82it/s]336it [03:13,  2.84it/s]337it [03:14,  2.68it/s]338it [03:14,  2.95it/s]339it [03:14,  2.47it/s]340it [03:15,  2.43it/s]341it [03:15,  2.60it/s]342it [03:15,  3.03it/s]343it [03:16,  3.41it/s]345it [03:16,  4.13it/s]346it [03:16,  3.76it/s]347it [03:16,  4.41it/s]348it [03:17,  4.43it/s]349it [03:17,  5.19it/s]350it [03:17,  5.28it/s]351it [03:17,  5.76it/s]352it [03:17,  6.36it/s]353it [03:17,  5.69it/s]354it [03:18,  6.33it/s]355it [03:18,  6.91it/s]356it [03:18,  6.55it/s]357it [03:18,  3.64it/s]358it [03:19,  2.21it/s]359it [03:20,  1.72it/s]360it [03:21,  1.59it/s]360it [03:21,  1.79it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:10,  3.94s/it]  6%|▌         | 2/34 [00:04<00:57,  1.80s/it]  9%|▉         | 3/34 [00:04<00:33,  1.07s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.37it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.85it/s] 18%|█▊        | 6/34 [00:05<00:11,  2.35it/s] 21%|██        | 7/34 [00:05<00:09,  2.83it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.27it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.65it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.96it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.21it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.39it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.54it/s] 41%|████      | 14/34 [00:06<00:04,  4.64it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.72it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.77it/s] 50%|█████     | 17/34 [00:07<00:03,  4.81it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.87it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.88it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.89it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.90it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.89it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.89it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.89it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.69it/s]100%|██████████| 34/34 [00:10<00:00,  3.13it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<01:49,  3.32s/it]  6%|▌         | 2/34 [00:03<00:47,  1.49s/it]  9%|▉         | 3/34 [00:03<00:27,  1.11it/s] 12%|█▏        | 4/34 [00:03<00:18,  1.59it/s] 15%|█▍        | 5/34 [00:04<00:13,  2.11it/s] 18%|█▊        | 6/34 [00:04<00:10,  2.61it/s] 21%|██        | 7/34 [00:04<00:08,  3.08it/s] 24%|██▎       | 8/34 [00:04<00:07,  3.49it/s] 26%|██▋       | 9/34 [00:04<00:06,  3.83it/s] 29%|██▉       | 10/34 [00:05<00:05,  4.10it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.32it/s] 35%|███▌      | 12/34 [00:05<00:04,  4.48it/s] 38%|███▊      | 13/34 [00:05<00:04,  4.60it/s] 41%|████      | 14/34 [00:05<00:04,  4.69it/s] 44%|████▍     | 15/34 [00:06<00:03,  4.76it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.80it/s] 50%|█████     | 17/34 [00:06<00:03,  4.83it/s] 53%|█████▎    | 18/34 [00:06<00:03,  4.85it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.87it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:07<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:07<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.89it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:08<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:08<00:01,  4.90it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:09<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:09<00:00,  4.90it/s]100%|██████████| 34/34 [00:09<00:00,  5.71it/s]100%|██████████| 34/34 [00:10<00:00,  3.35it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6553910374641418


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.955710955710956
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.15028320477714
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.82543812420455


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.53910064697266
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  6.49it/s]2it [00:00,  4.68it/s]3it [00:00,  5.05it/s]4it [00:00,  5.77it/s]5it [00:01,  3.93it/s]6it [00:01,  3.89it/s]7it [00:01,  4.16it/s]8it [00:01,  4.57it/s]9it [00:01,  5.26it/s]11it [00:02,  7.63it/s]13it [00:02,  9.43it/s]15it [00:02, 10.74it/s]17it [00:02, 11.53it/s]19it [00:02, 11.59it/s]21it [00:02, 12.29it/s]23it [00:02, 12.49it/s]25it [00:03, 12.83it/s]27it [00:03, 13.82it/s]29it [00:03, 15.22it/s]31it [00:03, 15.94it/s]33it [00:03, 15.24it/s]35it [00:03, 15.43it/s]37it [00:03, 16.27it/s]39it [00:03, 16.33it/s]41it [00:04, 16.27it/s]43it [00:04, 16.74it/s]45it [00:04, 17.18it/s]47it [00:04, 16.81it/s]49it [00:04, 17.20it/s]51it [00:04, 16.39it/s]53it [00:04, 17.06it/s]55it [00:04, 16.90it/s]57it [00:04, 17.01it/s]59it [00:05, 14.60it/s]61it [00:05, 13.11it/s]63it [00:05,  9.29it/s]65it [00:05, 10.63it/s]67it [00:06,  8.13it/s]69it [00:06,  9.17it/s]71it [00:06, 10.09it/s]73it [00:07,  6.83it/s]74it [00:07,  5.61it/s]75it [00:07,  3.81it/s]76it [00:08,  3.99it/s]77it [00:08,  3.92it/s]78it [00:08,  4.25it/s]79it [00:09,  3.05it/s]80it [00:09,  2.52it/s]81it [00:10,  2.49it/s]82it [00:10,  2.14it/s]83it [00:11,  2.15it/s]84it [00:11,  2.67it/s]86it [00:11,  3.88it/s]87it [00:11,  4.12it/s]88it [00:12,  3.55it/s]89it [00:12,  3.29it/s]90it [00:12,  3.44it/s]91it [00:13,  3.81it/s]93it [00:13,  4.69it/s]94it [00:13,  4.51it/s]95it [00:13,  4.78it/s]96it [00:13,  5.20it/s]97it [00:14,  4.34it/s]98it [00:14,  3.32it/s]99it [00:14,  3.45it/s]100it [00:15,  3.87it/s]101it [00:15,  3.53it/s]102it [00:15,  3.21it/s]103it [00:16,  2.66it/s]104it [00:16,  3.16it/s]105it [00:17,  2.71it/s]106it [00:17,  3.00it/s]107it [00:17,  2.95it/s]108it [00:17,  3.16it/s]109it [00:18,  2.66it/s]110it [00:18,  2.93it/s]111it [00:19,  3.11it/s]112it [00:19,  3.21it/s]113it [00:19,  2.96it/s]114it [00:19,  3.31it/s]115it [00:20,  2.78it/s]116it [00:20,  2.43it/s]117it [00:21,  1.83it/s]118it [00:22,  1.61it/s]119it [00:23,  1.45it/s]120it [00:23,  1.62it/s]121it [00:24,  1.97it/s]122it [00:24,  2.06it/s]123it [00:25,  1.88it/s]124it [00:25,  1.72it/s]125it [00:26,  1.55it/s]126it [00:27,  1.54it/s]127it [00:27,  1.58it/s]128it [00:28,  1.61it/s]129it [00:29,  1.48it/s]130it [00:30,  1.48it/s]131it [00:30,  1.42it/s]132it [00:31,  1.28it/s]133it [00:32,  1.24it/s]134it [00:33,  1.27it/s]135it [00:34,  1.32it/s]136it [00:34,  1.35it/s]137it [00:35,  1.42it/s]138it [00:36,  1.43it/s]139it [00:36,  1.49it/s]140it [00:37,  1.46it/s]141it [00:38,  1.40it/s]142it [00:38,  1.50it/s]143it [00:39,  1.49it/s]144it [00:40,  1.39it/s]145it [00:41,  1.36it/s]146it [00:41,  1.35it/s]147it [00:42,  1.31it/s]148it [00:43,  1.31it/s]149it [00:44,  1.36it/s]150it [00:44,  1.35it/s]151it [00:45,  1.37it/s]152it [00:46,  1.31it/s]153it [00:47,  1.27it/s]154it [00:48,  1.14it/s]155it [00:49,  1.11it/s]156it [00:50,  1.15it/s]157it [00:50,  1.53it/s]158it [00:50,  1.95it/s]159it [00:50,  2.37it/s]161it [00:50,  3.64it/s]162it [00:50,  4.07it/s]163it [00:51,  4.47it/s]164it [00:51,  5.22it/s]165it [00:51,  5.07it/s]166it [00:51,  4.91it/s]167it [00:51,  4.06it/s]168it [00:52,  3.34it/s]169it [00:52,  2.72it/s]170it [00:53,  2.42it/s]171it [00:53,  2.72it/s]172it [00:54,  2.33it/s]173it [00:54,  2.27it/s]174it [00:54,  2.67it/s]175it [00:55,  2.52it/s]176it [00:56,  2.12it/s]177it [00:56,  2.68it/s]178it [00:56,  3.20it/s]180it [00:56,  4.03it/s]181it [00:57,  3.51it/s]182it [00:57,  3.82it/s]183it [00:57,  3.95it/s]184it [00:58,  2.97it/s]185it [00:58,  3.13it/s]186it [00:58,  3.36it/s]187it [00:59,  2.75it/s]188it [00:59,  2.68it/s]189it [01:00,  2.31it/s]190it [01:00,  2.30it/s]191it [01:00,  2.47it/s]192it [01:01,  2.88it/s]193it [01:01,  3.10it/s]194it [01:02,  2.36it/s]195it [01:02,  2.41it/s]196it [01:02,  2.99it/s]197it [01:02,  3.55it/s]198it [01:02,  4.05it/s]199it [01:03,  3.79it/s]200it [01:03,  4.11it/s]201it [01:03,  3.76it/s]202it [01:03,  3.92it/s]203it [01:04,  2.97it/s]204it [01:04,  2.72it/s]205it [01:05,  2.26it/s]206it [01:05,  2.61it/s]207it [01:05,  3.30it/s]208it [01:06,  2.21it/s]209it [01:07,  2.18it/s]210it [01:07,  2.75it/s]211it [01:07,  2.85it/s]212it [01:07,  3.45it/s]213it [01:07,  4.10it/s]214it [01:08,  4.85it/s]215it [01:08,  4.12it/s]216it [01:08,  4.46it/s]217it [01:08,  3.38it/s]218it [01:09,  3.59it/s]219it [01:09,  3.10it/s]220it [01:09,  3.09it/s]221it [01:10,  3.25it/s]222it [01:10,  3.46it/s]223it [01:10,  4.10it/s]224it [01:10,  4.63it/s]225it [01:11,  3.71it/s]226it [01:11,  3.34it/s]227it [01:11,  3.43it/s]228it [01:12,  3.74it/s]229it [01:12,  2.80it/s]230it [01:13,  2.12it/s]231it [01:14,  1.77it/s]232it [01:14,  1.61it/s]233it [01:15,  1.59it/s]234it [01:16,  1.67it/s]235it [01:16,  1.57it/s]236it [01:17,  1.54it/s]237it [01:18,  1.59it/s]238it [01:18,  1.60it/s]239it [01:19,  1.65it/s]240it [01:19,  1.84it/s]241it [01:20,  1.73it/s]242it [01:21,  1.59it/s]243it [01:21,  1.52it/s]244it [01:22,  1.45it/s]245it [01:23,  1.49it/s]246it [01:24,  1.33it/s]247it [01:24,  1.36it/s]248it [01:25,  1.36it/s]249it [01:26,  1.38it/s]250it [01:26,  1.36it/s]251it [01:27,  1.37it/s]252it [01:28,  1.45it/s]253it [01:28,  1.51it/s]254it [01:29,  1.56it/s]255it [01:30,  1.50it/s]256it [01:30,  1.45it/s]257it [01:31,  1.47it/s]258it [01:32,  1.45it/s]259it [01:33,  1.40it/s]260it [01:33,  1.42it/s]261it [01:34,  1.45it/s]262it [01:35,  1.35it/s]263it [01:36,  1.31it/s]264it [01:36,  1.31it/s]265it [01:37,  1.30it/s]266it [01:38,  1.28it/s]267it [01:39,  1.37it/s]268it [01:39,  1.42it/s]269it [01:40,  1.42it/s]270it [01:41,  1.42it/s]271it [01:41,  1.42it/s]272it [01:42,  1.40it/s]273it [01:43,  1.40it/s]274it [01:43,  1.76it/s]275it [01:43,  2.20it/s]276it [01:44,  2.40it/s]277it [01:44,  2.09it/s]278it [01:45,  1.98it/s]279it [01:45,  2.42it/s]280it [01:45,  2.98it/s]281it [01:46,  2.58it/s]282it [01:46,  3.05it/s]283it [01:46,  2.39it/s]284it [01:47,  2.81it/s]285it [01:47,  2.72it/s]286it [01:47,  2.75it/s]287it [01:48,  2.80it/s]288it [01:48,  3.52it/s]289it [01:48,  3.38it/s]290it [01:49,  2.88it/s]291it [01:49,  2.36it/s]292it [01:49,  2.90it/s]293it [01:49,  3.56it/s]294it [01:50,  4.14it/s]295it [01:50,  4.65it/s]296it [01:50,  3.35it/s]297it [01:51,  2.82it/s]298it [01:51,  2.71it/s]299it [01:51,  2.81it/s]300it [01:52,  2.41it/s]301it [01:52,  2.83it/s]302it [01:53,  2.50it/s]303it [01:53,  2.53it/s]304it [01:53,  2.74it/s]305it [01:54,  3.04it/s]306it [01:55,  2.05it/s]307it [01:55,  1.85it/s]308it [01:55,  2.39it/s]309it [01:56,  2.30it/s]310it [01:57,  1.91it/s]311it [01:57,  1.93it/s]312it [01:57,  2.25it/s]313it [01:58,  2.51it/s]314it [01:58,  2.51it/s]315it [01:58,  2.78it/s]316it [01:59,  2.79it/s]317it [01:59,  2.90it/s]318it [01:59,  3.00it/s]319it [02:00,  2.88it/s]320it [02:00,  2.45it/s]321it [02:01,  2.31it/s]322it [02:01,  2.14it/s]323it [02:02,  2.04it/s]324it [02:02,  2.29it/s]325it [02:02,  2.90it/s]326it [02:02,  3.60it/s]327it [02:03,  3.67it/s]328it [02:03,  4.46it/s]329it [02:03,  3.76it/s]330it [02:03,  3.43it/s]331it [02:04,  3.39it/s]332it [02:04,  3.43it/s]333it [02:05,  2.81it/s]334it [02:05,  2.27it/s]335it [02:06,  1.86it/s]336it [02:07,  1.62it/s]337it [02:08,  1.49it/s]338it [02:08,  1.55it/s]339it [02:08,  1.79it/s]340it [02:09,  1.73it/s]341it [02:10,  1.76it/s]342it [02:10,  1.72it/s]343it [02:11,  1.71it/s]344it [02:11,  1.64it/s]345it [02:12,  1.60it/s]346it [02:13,  1.52it/s]347it [02:14,  1.46it/s]348it [02:14,  1.52it/s]349it [02:15,  1.52it/s]350it [02:16,  1.52it/s]351it [02:16,  1.61it/s]352it [02:17,  1.58it/s]353it [02:17,  1.61it/s]354it [02:18,  1.71it/s]355it [02:18,  1.75it/s]356it [02:19,  1.67it/s]357it [02:20,  1.56it/s]358it [02:20,  1.53it/s]359it [02:21,  1.52it/s]360it [02:22,  1.45it/s]360it [02:22,  2.53it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<01:52,  3.42s/it]  6%|▌         | 2/34 [00:03<00:55,  1.75s/it]  9%|▉         | 3/34 [00:04<00:32,  1.06s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.39it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.87it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.37it/s] 21%|██        | 7/34 [00:05<00:09,  2.85it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.28it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.66it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.97it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.22it/s] 35%|███▌      | 12/34 [00:06<00:04,  4.41it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.55it/s] 41%|████      | 14/34 [00:06<00:04,  4.65it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.73it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.78it/s] 50%|█████     | 17/34 [00:07<00:03,  4.82it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.87it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.88it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.89it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.90it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.91it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.91it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.72it/s]100%|██████████| 34/34 [00:10<00:00,  3.20it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<01:52,  3.42s/it]  6%|▌         | 2/34 [00:03<00:48,  1.53s/it]  9%|▉         | 3/34 [00:04<00:32,  1.04s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.41it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.89it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.39it/s] 21%|██        | 7/34 [00:04<00:09,  2.87it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.30it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.66it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.95it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.19it/s] 35%|███▌      | 12/34 [00:05<00:05,  4.37it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.51it/s] 41%|████      | 14/34 [00:06<00:04,  4.61it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.69it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.73it/s] 50%|█████     | 17/34 [00:06<00:03,  4.77it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.81it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.83it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.85it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:07<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.90it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.91it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.91it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.92it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.91it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.91it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.92it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.92it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.92it/s]100%|██████████| 34/34 [00:10<00:00,  5.73it/s]100%|██████████| 34/34 [00:10<00:00,  3.23it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6516737937927246


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.22144522144523
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.01998208346834
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.32299998558267


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.1673812866211
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 14.76it/s]4it [00:00, 14.81it/s]6it [00:00, 15.36it/s]8it [00:00, 15.57it/s]10it [00:00, 15.32it/s]12it [00:00, 16.36it/s]14it [00:00, 16.68it/s]16it [00:00, 16.73it/s]18it [00:01, 15.48it/s]20it [00:01, 15.81it/s]22it [00:01, 16.55it/s]24it [00:01, 16.51it/s]26it [00:01, 15.11it/s]28it [00:01, 15.76it/s]30it [00:01, 16.47it/s]32it [00:01, 16.44it/s]34it [00:02, 16.68it/s]36it [00:02, 17.32it/s]38it [00:02, 17.44it/s]40it [00:02, 17.25it/s]42it [00:02, 16.78it/s]44it [00:02, 16.61it/s]46it [00:02, 16.15it/s]48it [00:02, 16.25it/s]50it [00:03, 16.03it/s]52it [00:03, 15.81it/s]54it [00:03, 16.17it/s]56it [00:03, 16.52it/s]58it [00:03, 16.36it/s]60it [00:03, 14.33it/s]62it [00:03, 14.88it/s]64it [00:04,  9.82it/s]66it [00:04,  9.01it/s]68it [00:04, 10.09it/s]70it [00:04, 11.27it/s]72it [00:04, 12.52it/s]74it [00:05, 11.47it/s]76it [00:05,  7.98it/s]78it [00:05,  7.95it/s]79it [00:06,  6.87it/s]80it [00:06,  7.22it/s]82it [00:06,  7.73it/s]84it [00:06,  8.19it/s]85it [00:06,  8.11it/s]86it [00:06,  8.11it/s]87it [00:06,  8.29it/s]88it [00:07,  8.45it/s]90it [00:07,  9.04it/s]92it [00:07,  9.91it/s]94it [00:07,  8.04it/s]95it [00:07,  7.48it/s]96it [00:08,  7.82it/s]97it [00:08,  7.21it/s]98it [00:08,  6.50it/s]99it [00:08,  7.13it/s]101it [00:08,  7.49it/s]102it [00:08,  7.94it/s]103it [00:08,  8.08it/s]104it [00:09,  7.46it/s]105it [00:09,  7.32it/s]106it [00:09,  6.74it/s]107it [00:09,  6.99it/s]109it [00:09,  6.73it/s]110it [00:10,  6.94it/s]111it [00:10,  7.32it/s]112it [00:10,  7.10it/s]113it [00:10,  6.98it/s]115it [00:10,  6.51it/s]116it [00:10,  6.40it/s]117it [00:11,  6.13it/s]118it [00:11,  5.89it/s]119it [00:11,  5.11it/s]121it [00:11,  5.45it/s]122it [00:12,  5.88it/s]123it [00:12,  6.31it/s]125it [00:12,  7.92it/s]126it [00:12,  7.41it/s]128it [00:12,  8.23it/s]129it [00:12,  7.36it/s]130it [00:13,  6.25it/s]131it [00:13,  6.78it/s]132it [00:13,  6.73it/s]133it [00:13,  7.13it/s]135it [00:13,  7.98it/s]136it [00:13,  8.02it/s]138it [00:14,  8.77it/s]139it [00:14,  8.77it/s]140it [00:14,  8.88it/s]141it [00:14,  8.63it/s]142it [00:14,  8.66it/s]143it [00:14,  8.00it/s]144it [00:14,  8.26it/s]146it [00:14,  8.41it/s]148it [00:15,  8.30it/s]149it [00:15,  6.83it/s]151it [00:15,  7.48it/s]152it [00:15,  7.18it/s]153it [00:16,  7.19it/s]154it [00:16,  5.95it/s]155it [00:16,  6.38it/s]156it [00:16,  5.64it/s]157it [00:16,  6.18it/s]159it [00:16,  7.37it/s]161it [00:17,  7.34it/s]162it [00:17,  7.15it/s]163it [00:17,  7.40it/s]164it [00:17,  7.56it/s]165it [00:17,  7.17it/s]166it [00:17,  7.06it/s]167it [00:18,  6.60it/s]169it [00:18,  6.94it/s]171it [00:18,  8.47it/s]172it [00:18,  7.66it/s]173it [00:18,  6.68it/s]174it [00:19,  7.17it/s]175it [00:19,  7.11it/s]176it [00:19,  7.46it/s]177it [00:19,  7.25it/s]178it [00:19,  6.25it/s]179it [00:19,  6.25it/s]180it [00:19,  6.18it/s]181it [00:20,  6.09it/s]182it [00:20,  6.10it/s]184it [00:20,  7.92it/s]185it [00:20,  8.00it/s]186it [00:20,  7.08it/s]187it [00:20,  6.99it/s]188it [00:21,  7.58it/s]189it [00:21,  7.73it/s]191it [00:21,  8.58it/s]193it [00:21,  9.21it/s]195it [00:21,  7.36it/s]196it [00:22,  7.48it/s]197it [00:22,  7.61it/s]198it [00:22,  7.93it/s]200it [00:22,  8.96it/s]202it [00:22,  8.45it/s]203it [00:22,  7.94it/s]204it [00:22,  7.87it/s]205it [00:23,  5.93it/s]207it [00:23,  7.05it/s]208it [00:24,  4.00it/s]209it [00:24,  4.44it/s]210it [00:24,  4.81it/s]211it [00:24,  5.43it/s]213it [00:24,  6.56it/s]214it [00:24,  6.91it/s]216it [00:25,  8.17it/s]217it [00:25,  8.52it/s]218it [00:25,  7.44it/s]219it [00:25,  7.79it/s]220it [00:25,  8.21it/s]221it [00:25,  8.36it/s]222it [00:25,  8.16it/s]223it [00:25,  7.74it/s]224it [00:26,  8.21it/s]226it [00:26,  8.31it/s]227it [00:26,  7.76it/s]228it [00:26,  8.18it/s]229it [00:26,  7.79it/s]231it [00:26,  8.81it/s]233it [00:27,  8.02it/s]234it [00:27,  8.16it/s]235it [00:27,  6.93it/s]236it [00:27,  7.08it/s]237it [00:27,  7.32it/s]239it [00:27,  8.49it/s]240it [00:28,  8.35it/s]241it [00:28,  8.25it/s]242it [00:28,  7.43it/s]243it [00:28,  7.95it/s]244it [00:28,  7.40it/s]246it [00:29,  5.97it/s]247it [00:29,  6.40it/s]248it [00:29,  4.94it/s]249it [00:29,  3.83it/s]250it [00:30,  4.13it/s]251it [00:30,  3.50it/s]252it [00:30,  3.66it/s]253it [00:30,  3.92it/s]254it [00:31,  4.63it/s]255it [00:31,  5.33it/s]256it [00:31,  4.93it/s]257it [00:31,  4.63it/s]259it [00:31,  6.25it/s]261it [00:32,  7.61it/s]262it [00:32,  6.81it/s]263it [00:32,  6.84it/s]264it [00:32,  6.29it/s]265it [00:32,  6.93it/s]267it [00:32,  8.19it/s]268it [00:33,  5.70it/s]269it [00:33,  5.47it/s]270it [00:33,  5.20it/s]271it [00:33,  4.54it/s]272it [00:34,  4.48it/s]273it [00:34,  5.03it/s]274it [00:34,  5.31it/s]275it [00:34,  3.99it/s]276it [00:35,  4.28it/s]277it [00:35,  3.55it/s]278it [00:35,  3.98it/s]279it [00:36,  3.47it/s]280it [00:36,  4.02it/s]281it [00:36,  3.64it/s]282it [00:36,  3.48it/s]283it [00:37,  2.70it/s]284it [00:37,  3.36it/s]285it [00:38,  2.74it/s]286it [00:38,  2.48it/s]287it [00:38,  2.42it/s]288it [00:39,  2.88it/s]289it [00:39,  3.16it/s]290it [00:39,  3.36it/s]291it [00:39,  3.35it/s]292it [00:40,  3.06it/s]293it [00:40,  2.47it/s]294it [00:41,  2.15it/s]295it [00:42,  2.04it/s]296it [00:42,  2.46it/s]297it [00:42,  2.92it/s]298it [00:42,  3.13it/s]299it [00:43,  3.42it/s]300it [00:43,  3.43it/s]301it [00:43,  3.98it/s]302it [00:43,  4.45it/s]303it [00:43,  4.41it/s]304it [00:44,  3.78it/s]305it [00:44,  4.16it/s]306it [00:45,  2.36it/s]307it [00:45,  2.59it/s]308it [00:45,  2.64it/s]309it [00:46,  2.22it/s]310it [00:47,  1.78it/s]311it [00:47,  1.79it/s]312it [00:48,  2.22it/s]313it [00:48,  2.78it/s]314it [00:48,  2.93it/s]316it [00:48,  4.19it/s]318it [00:49,  5.00it/s]319it [00:49,  5.19it/s]320it [00:49,  5.30it/s]321it [00:49,  4.82it/s]322it [00:49,  4.88it/s]323it [00:50,  4.12it/s]324it [00:50,  3.30it/s]325it [00:50,  3.98it/s]326it [00:51,  4.00it/s]327it [00:51,  4.34it/s]328it [00:51,  4.53it/s]329it [00:51,  4.62it/s]330it [00:51,  4.48it/s]331it [00:52,  4.81it/s]332it [00:52,  5.62it/s]333it [00:52,  4.81it/s]334it [00:52,  4.68it/s]335it [00:52,  4.68it/s]336it [00:52,  5.50it/s]337it [00:53,  5.66it/s]338it [00:53,  6.39it/s]339it [00:53,  5.04it/s]340it [00:53,  4.65it/s]341it [00:54,  3.13it/s]342it [00:54,  2.97it/s]343it [00:54,  3.18it/s]344it [00:55,  3.26it/s]345it [00:55,  3.49it/s]346it [00:56,  2.72it/s]347it [00:56,  3.38it/s]348it [00:56,  3.89it/s]349it [00:56,  4.64it/s]350it [00:56,  5.47it/s]351it [00:56,  4.39it/s]352it [00:57,  4.80it/s]353it [00:57,  4.87it/s]354it [00:57,  5.24it/s]355it [00:57,  4.46it/s]356it [00:57,  4.41it/s]357it [00:58,  4.08it/s]358it [00:58,  4.27it/s]359it [00:58,  3.55it/s]360it [00:59,  4.15it/s]360it [00:59,  6.10it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<01:58,  3.60s/it]  6%|▌         | 2/34 [00:03<00:51,  1.60s/it]  9%|▉         | 3/34 [00:04<00:30,  1.00it/s] 12%|█▏        | 4/34 [00:04<00:20,  1.46it/s] 15%|█▍        | 5/34 [00:04<00:14,  1.96it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.46it/s] 21%|██        | 7/34 [00:04<00:09,  2.93it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.36it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.73it/s] 29%|██▉       | 10/34 [00:05<00:05,  4.02it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.26it/s] 35%|███▌      | 12/34 [00:05<00:04,  4.44it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.57it/s] 41%|████      | 14/34 [00:06<00:04,  4.66it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.74it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.79it/s] 50%|█████     | 17/34 [00:06<00:03,  4.82it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.85it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.88it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.88it/s] 65%|██████▍   | 22/34 [00:07<00:02,  4.89it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.90it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:08<00:01,  4.91it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.91it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.92it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.91it/s] 94%|█████████▍| 32/34 [00:09<00:00,  4.92it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.92it/s]100%|██████████| 34/34 [00:10<00:00,  5.67it/s]100%|██████████| 34/34 [00:10<00:00,  3.24it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967992782593
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:13,  4.05s/it]  6%|▌         | 2/34 [00:04<00:57,  1.79s/it]  9%|▉         | 3/34 [00:04<00:33,  1.07s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.38it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.86it/s] 18%|█▊        | 6/34 [00:05<00:11,  2.36it/s] 21%|██        | 7/34 [00:05<00:09,  2.84it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.28it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.65it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.96it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.21it/s] 35%|███▌      | 12/34 [00:06<00:04,  4.40it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.54it/s] 41%|████      | 14/34 [00:06<00:04,  4.64it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.72it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.77it/s] 50%|█████     | 17/34 [00:07<00:03,  4.81it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.87it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.88it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.89it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.90it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.90it/s] 71%|███████   | 24/34 [00:08<00:02,  4.91it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.91it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.91it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.91it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.91it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.91it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.91it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.91it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.91it/s]100%|██████████| 34/34 [00:10<00:00,  5.72it/s]100%|██████████| 34/34 [00:10<00:00,  3.12it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6516013145446777


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36968231201172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 50.38461538461539
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.2951468580309
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 37.66701060028767


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.1601333618164
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 16.00it/s]4it [00:00, 17.61it/s]6it [00:00, 17.60it/s]8it [00:00, 17.59it/s]10it [00:00, 16.91it/s]12it [00:00, 17.00it/s]14it [00:00, 17.03it/s]16it [00:00, 16.70it/s]18it [00:01, 15.64it/s]20it [00:01, 16.38it/s]22it [00:01, 16.15it/s]24it [00:01, 15.80it/s]26it [00:01, 14.70it/s]28it [00:01, 15.18it/s]30it [00:01, 15.14it/s]32it [00:01, 16.02it/s]34it [00:02, 16.41it/s]36it [00:02, 11.97it/s]38it [00:02,  9.17it/s]40it [00:02, 10.07it/s]42it [00:02, 11.14it/s]44it [00:03,  9.93it/s]46it [00:03,  5.63it/s]47it [00:04,  3.92it/s]48it [00:05,  3.09it/s]49it [00:05,  2.58it/s]50it [00:06,  2.53it/s]51it [00:06,  2.47it/s]52it [00:06,  3.02it/s]53it [00:06,  3.29it/s]55it [00:07,  3.81it/s]56it [00:08,  2.91it/s]57it [00:08,  2.57it/s]58it [00:08,  2.78it/s]59it [00:09,  2.30it/s]60it [00:09,  2.15it/s]61it [00:10,  2.19it/s]62it [00:10,  2.50it/s]63it [00:11,  2.07it/s]64it [00:11,  2.18it/s]65it [00:12,  2.06it/s]66it [00:12,  1.93it/s]67it [00:13,  2.19it/s]68it [00:13,  2.46it/s]69it [00:14,  2.29it/s]70it [00:14,  2.39it/s]71it [00:14,  2.18it/s]72it [00:15,  2.29it/s]73it [00:15,  2.69it/s]74it [00:15,  2.56it/s]75it [00:16,  2.05it/s]76it [00:17,  2.25it/s]77it [00:17,  2.60it/s]78it [00:17,  2.80it/s]79it [00:18,  2.64it/s]80it [00:18,  2.25it/s]81it [00:18,  2.63it/s]82it [00:19,  2.48it/s]83it [00:19,  2.21it/s]84it [00:20,  2.49it/s]85it [00:20,  2.13it/s]86it [00:21,  2.00it/s]87it [00:21,  1.92it/s]88it [00:22,  2.23it/s]89it [00:22,  2.19it/s]90it [00:23,  1.98it/s]91it [00:23,  1.95it/s]92it [00:24,  1.88it/s]93it [00:25,  1.80it/s]94it [00:25,  1.97it/s]95it [00:25,  1.91it/s]96it [00:26,  2.04it/s]97it [00:26,  2.00it/s]98it [00:27,  2.09it/s]99it [00:27,  2.28it/s]100it [00:27,  2.93it/s]101it [00:28,  3.07it/s]102it [00:28,  2.59it/s]103it [00:28,  3.22it/s]104it [00:29,  3.24it/s]105it [00:29,  2.63it/s]106it [00:30,  2.23it/s]107it [00:30,  2.08it/s]108it [00:31,  2.30it/s]109it [00:31,  2.08it/s]110it [00:31,  2.33it/s]111it [00:32,  2.39it/s]112it [00:32,  2.88it/s]113it [00:33,  2.56it/s]114it [00:33,  2.96it/s]115it [00:33,  2.33it/s]116it [00:34,  2.75it/s]117it [00:34,  2.99it/s]118it [00:34,  3.40it/s]119it [00:34,  4.00it/s]120it [00:35,  3.09it/s]121it [00:35,  2.77it/s]123it [00:36,  3.00it/s]124it [00:36,  2.56it/s]125it [00:37,  2.29it/s]126it [00:37,  2.14it/s]127it [00:38,  2.28it/s]128it [00:38,  2.08it/s]129it [00:39,  2.53it/s]130it [00:39,  2.53it/s]131it [00:39,  2.58it/s]132it [00:40,  2.33it/s]133it [00:40,  2.66it/s]134it [00:41,  2.24it/s]135it [00:41,  2.10it/s]136it [00:42,  1.96it/s]137it [00:42,  1.93it/s]138it [00:43,  1.84it/s]139it [00:43,  1.99it/s]140it [00:44,  2.43it/s]141it [00:44,  2.91it/s]142it [00:44,  2.93it/s]143it [00:44,  3.15it/s]144it [00:45,  3.85it/s]145it [00:45,  4.12it/s]146it [00:45,  2.95it/s]147it [00:46,  2.48it/s]148it [00:46,  2.75it/s]149it [00:47,  2.71it/s]150it [00:47,  2.36it/s]151it [00:47,  2.41it/s]152it [00:48,  2.71it/s]153it [00:48,  3.18it/s]154it [00:48,  2.61it/s]155it [00:49,  2.33it/s]156it [00:49,  2.43it/s]157it [00:50,  2.16it/s]158it [00:50,  2.09it/s]159it [00:51,  2.35it/s]160it [00:51,  2.42it/s]161it [00:52,  2.42it/s]162it [00:52,  3.00it/s]163it [00:52,  2.93it/s]164it [00:52,  2.84it/s]165it [00:53,  2.90it/s]166it [00:53,  2.54it/s]167it [00:54,  2.34it/s]168it [00:54,  2.47it/s]169it [00:54,  2.86it/s]170it [00:55,  3.28it/s]172it [00:55,  3.72it/s]173it [00:55,  3.36it/s]174it [00:56,  3.59it/s]175it [00:56,  3.79it/s]176it [00:56,  3.70it/s]177it [00:57,  3.18it/s]178it [00:57,  2.53it/s]179it [00:58,  2.19it/s]180it [00:58,  2.14it/s]181it [00:59,  2.02it/s]182it [00:59,  1.88it/s]183it [01:00,  1.84it/s]184it [01:00,  1.89it/s]185it [01:01,  2.07it/s]186it [01:01,  2.18it/s]187it [01:02,  2.35it/s]188it [01:02,  2.81it/s]189it [01:02,  3.31it/s]190it [01:02,  3.30it/s]191it [01:03,  2.82it/s]192it [01:03,  2.64it/s]194it [01:04,  3.23it/s]195it [01:04,  3.26it/s]196it [01:04,  3.45it/s]197it [01:04,  3.76it/s]198it [01:05,  4.53it/s]200it [01:05,  4.35it/s]201it [01:05,  4.92it/s]202it [01:05,  4.83it/s]203it [01:06,  3.65it/s]204it [01:06,  3.20it/s]205it [01:07,  2.49it/s]206it [01:07,  2.85it/s]207it [01:07,  2.82it/s]208it [01:08,  1.90it/s]209it [01:09,  1.91it/s]210it [01:09,  2.39it/s]211it [01:09,  2.60it/s]212it [01:10,  2.80it/s]213it [01:10,  2.67it/s]214it [01:10,  2.66it/s]215it [01:11,  2.40it/s]216it [01:11,  2.39it/s]217it [01:12,  2.19it/s]218it [01:12,  2.32it/s]219it [01:13,  2.25it/s]220it [01:13,  2.61it/s]221it [01:13,  3.06it/s]222it [01:14,  3.03it/s]223it [01:14,  2.65it/s]224it [01:14,  2.97it/s]225it [01:14,  3.57it/s]226it [01:15,  3.70it/s]227it [01:15,  4.02it/s]228it [01:15,  2.88it/s]229it [01:16,  2.42it/s]230it [01:17,  2.16it/s]231it [01:17,  2.09it/s]232it [01:18,  2.05it/s]233it [01:18,  2.55it/s]234it [01:18,  2.72it/s]235it [01:18,  2.87it/s]236it [01:19,  3.40it/s]237it [01:19,  3.80it/s]238it [01:19,  4.51it/s]239it [01:19,  4.82it/s]240it [01:19,  3.74it/s]241it [01:20,  2.93it/s]242it [01:20,  2.57it/s]243it [01:21,  2.48it/s]244it [01:21,  2.47it/s]245it [01:22,  2.46it/s]246it [01:22,  2.23it/s]247it [01:22,  2.71it/s]248it [01:23,  3.07it/s]249it [01:23,  3.43it/s]250it [01:23,  3.30it/s]251it [01:24,  3.27it/s]252it [01:24,  3.50it/s]253it [01:24,  4.11it/s]254it [01:24,  2.98it/s]255it [01:25,  2.51it/s]256it [01:25,  2.44it/s]257it [01:26,  2.22it/s]258it [01:26,  2.20it/s]259it [01:27,  2.09it/s]260it [01:27,  2.51it/s]261it [01:28,  2.50it/s]262it [01:28,  2.38it/s]263it [01:28,  2.94it/s]264it [01:29,  2.92it/s]265it [01:29,  3.05it/s]266it [01:29,  3.42it/s]267it [01:29,  3.11it/s]268it [01:30,  3.08it/s]269it [01:30,  3.02it/s]270it [01:30,  3.02it/s]271it [01:31,  2.59it/s]272it [01:31,  2.60it/s]273it [01:32,  2.37it/s]274it [01:32,  2.16it/s]275it [01:33,  1.97it/s]276it [01:34,  2.01it/s]277it [01:34,  1.79it/s]278it [01:35,  1.86it/s]279it [01:35,  2.35it/s]280it [01:35,  2.77it/s]281it [01:35,  3.47it/s]282it [01:35,  4.02it/s]283it [01:36,  4.24it/s]284it [01:36,  3.26it/s]285it [01:37,  2.82it/s]286it [01:37,  2.96it/s]287it [01:37,  3.39it/s]288it [01:37,  3.95it/s]289it [01:37,  4.27it/s]290it [01:38,  4.68it/s]291it [01:38,  3.42it/s]292it [01:39,  2.56it/s]293it [01:39,  2.22it/s]294it [01:40,  2.05it/s]295it [01:40,  2.09it/s]296it [01:41,  1.96it/s]297it [01:41,  1.88it/s]298it [01:42,  1.84it/s]299it [01:42,  1.97it/s]300it [01:43,  2.26it/s]301it [01:43,  2.92it/s]302it [01:43,  3.25it/s]303it [01:43,  3.36it/s]304it [01:43,  4.06it/s]305it [01:44,  3.00it/s]306it [01:45,  2.03it/s]307it [01:45,  2.26it/s]308it [01:45,  2.43it/s]309it [01:46,  2.99it/s]310it [01:46,  2.19it/s]311it [01:47,  2.28it/s]313it [01:47,  3.08it/s]314it [01:47,  3.23it/s]315it [01:48,  3.25it/s]316it [01:48,  3.04it/s]317it [01:48,  3.58it/s]318it [01:48,  4.13it/s]319it [01:49,  4.80it/s]320it [01:49,  4.95it/s]321it [01:49,  5.27it/s]322it [01:49,  5.61it/s]323it [01:49,  6.16it/s]325it [01:49,  7.08it/s]326it [01:50,  6.60it/s]327it [01:50,  6.55it/s]328it [01:50,  6.93it/s]329it [01:50,  6.82it/s]330it [01:50,  7.30it/s]331it [01:50,  7.47it/s]332it [01:50,  7.25it/s]333it [01:51,  6.81it/s]335it [01:51,  7.25it/s]336it [01:51,  6.97it/s]337it [01:51,  7.05it/s]338it [01:51,  6.84it/s]339it [01:51,  6.43it/s]340it [01:52,  5.64it/s]341it [01:52,  5.82it/s]342it [01:52,  6.12it/s]343it [01:52,  6.51it/s]344it [01:52,  5.18it/s]345it [01:53,  6.03it/s]346it [01:53,  5.24it/s]347it [01:53,  5.64it/s]348it [01:53,  5.41it/s]349it [01:53,  5.39it/s]351it [01:53,  7.08it/s]352it [01:54,  6.64it/s]354it [01:54,  8.25it/s]356it [01:54,  9.12it/s]358it [01:54,  8.60it/s]360it [01:54,  9.28it/s]360it [01:54,  3.13it/s]
Number of selected candidates = 133
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 133
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:18,  4.19s/it]  6%|▌         | 2/34 [00:04<01:07,  2.10s/it]  9%|▉         | 3/34 [00:05<00:38,  1.23s/it] 12%|█▏        | 4/34 [00:05<00:24,  1.21it/s] 15%|█▍        | 5/34 [00:05<00:17,  1.66it/s] 18%|█▊        | 6/34 [00:05<00:13,  2.14it/s] 21%|██        | 7/34 [00:05<00:10,  2.62it/s] 24%|██▎       | 8/34 [00:06<00:08,  3.08it/s] 26%|██▋       | 9/34 [00:06<00:07,  3.48it/s] 29%|██▉       | 10/34 [00:06<00:06,  3.82it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.09it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.31it/s] 38%|███▊      | 13/34 [00:07<00:04,  4.47it/s] 41%|████      | 14/34 [00:07<00:04,  4.58it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.67it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.73it/s] 50%|█████     | 17/34 [00:07<00:03,  4.77it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.80it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.82it/s] 59%|█████▉    | 20/34 [00:08<00:02,  4.81it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.82it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.83it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.83it/s] 71%|███████   | 24/34 [00:09<00:02,  4.85it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.86it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.87it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.87it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.88it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.88it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.89it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.89it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.88it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.88it/s]100%|██████████| 34/34 [00:11<00:00,  5.69it/s]100%|██████████| 34/34 [00:11<00:00,  2.96it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967992782593
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:14,  4.07s/it]  6%|▌         | 2/34 [00:04<00:57,  1.80s/it]  9%|▉         | 3/34 [00:04<00:33,  1.07s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.37it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.85it/s] 18%|█▊        | 6/34 [00:05<00:11,  2.34it/s] 21%|██        | 7/34 [00:05<00:09,  2.82it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.26it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.64it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.95it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.20it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.39it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.53it/s] 41%|████      | 14/34 [00:06<00:04,  4.63it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.71it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.76it/s] 50%|█████     | 17/34 [00:07<00:03,  4.80it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.83it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.84it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.86it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.88it/s] 71%|███████   | 24/34 [00:08<00:02,  4.89it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.89it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.89it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.89it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.72it/s]100%|██████████| 34/34 [00:10<00:00,  3.11it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6586540937423706


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36968231201172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 51.2937062937063
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 70.53697175685164
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 38.36101457939313


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.86540985107422
=========================          END          =========================


========================= ViLang Final Results of 10 runs, w/ 3 imgs per class=========================


[Clustering]
Clustering ACC: 50.61421911421912
Semantic ACC:   65.2246322631836
=========================          END          =========================
