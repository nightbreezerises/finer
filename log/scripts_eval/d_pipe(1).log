Namespace(config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/dog120_all.yml', alpha=0.7, N_tta=10, num_per_category='3', num_runs=10)
Number of GPUs: 1
Device ID: 0 Device Name: NVIDIA RTX A6000
['Wire-Haired Terrier', 'Whippet', 'Affenpinscher', 'King Charles Spaniel', 'Irish Setter', 'Basset Hound', 'Doberman Pinscher', 'Rottweiler', 'German Pinscher', 'Mixed Breed', 'Australian Shepherd', 'Saluki', 'Toy Terrier', 'Teddy Bear Terrier', 'Norfolk Terrier', 'Bernese Mountain Dog mix', 'Terrier Mix', 'Brown Labrador Retriever', 'Cairn Terrier', 'Boston Terrier', 'French Bulldog', 'Shepherd', 'Pembroke Welsh Corgi', 'English Bulldog', 'Yorkshire Terrier', 'Shih Tzu', 'Maltese', 'Chow Chow', 'Akita', 'Samoyed', 'Setter', 'Labrador Retriever', 'Bernese Mountain Dog puppy', 'Appenzeller Sennenhund', 'Rat Terrier', 'Bernese Mountain Dog', 'St. Bernard', 'Dachshund', 'Old English Sheepdog', 'Saint Bernard', 'Crossbreed', 'boston terrier', 'Terrier mix', 'Hound mix', 'Fox Terrier', 'Pit Bull', 'Chihuahua', 'Dachshund', 'Pomeranian', 'Weimaraner', 'Terrier', 'Standard Schnauzer', 'Scottie', 'Belgian Shepherd', 'Beagle mix', 'Boxer', 'Coonhound', 'Labrador Retriever', 'Boxer', 'Rottweiler', 'Cocker Spaniel', 'Poodle', 'Snub-Nosed Terrier', 'Hound', 'Border Terrier', 'boxer', 'Russian Taylor Dog', 'Siberian Husky', 'Bichon Frise', 'Portuguese Water Dog', 'Newfoundland', 'Dachshund', 'Shih Tzu', 'Pomeranian', 'Spitz Dog', 'Samoyed', 'Collie', 'West Highland White Terrier', 'French Bulldog', 'Hound Dog', 'Blue Tick Coonhound', 'Toy Poodle', 'Italian Greyhound', 'Boxer', 'Hound', 'Bullmastiff', 'St. Bernard Mix', 'Bloodhound', 'Boxer Puppy', 'Dutch Shepherd', 'American Cocker Spaniel', 'Doberman Pinscher', 'Miniature Poodle', 'Possible breeds', 'Corgi', 'Chihuahua', 'Smooth Fox Terrier', 'Shih Tzu', 'Chihuahua', 'Boston Terrier', 'Dalmatian', 'Beagle', 'Brown and White Spaniel', 'Shih Tzu', 'Chihuahua', 'Maltese', 'Basenji', 'Greater Swiss Mountain Dog', 'American Eskimo', 'Pointer', 'Belgian Shepherd', 'Pekingese', 'Wire Fox Terrier', 'Great Dane', 'Shar Pei', 'Afghan', 'Poodle', 'Corgi mix', 'St. Bernard', 'Chihuahua mix', 'Boxer', 'Shih Tzu', 'Bichon Frise', 'Lhasa Apso', 'bulldog', 'Husky', 'Hound mix', 'Shih Tzu', 'Pomeranian', 'Chow Chow', 'Alsatian', 'Staffordshire Bull Terrier', 'Dingo', 'Black and Tan Retriever', 'Briard', 'Springer Spaniel', 'Bernese Mountain Dog Mix', 'Afghan Hounds', 'Poodle mix', 'Husky', 'Alaskan Malamute', 'Samoyed', 'Rottweiler Mix', 'Coton de Tulear', 'Afghan Hound', 'Leonberger', 'Mixed Breed (possibly including St. Bernard)', 'Bulldog', 'Dachshund', 'Alaskan Klee Kai', 'Swiss Mountain Dog', 'Finnish Spitz', 'Rottweiler mix', 'Toy Fox Terrier', 'Silky Terrier', 'English Cocker Spaniel', 'Yorkie', 'Deutscher Schäferhund', 'Plott Hound', 'Akita', 'Havanese', 'Spitz', 'Irish Wolfhound', 'Terrier Dog', 'German Shepherd', 'Poodle', 'Cockapoo', 'Labrador Retriever', 'Fox Terrier', 'Rat Terrier', 'Terrier Mix', 'Black Terrier', 'Collie', 'Shetland Sheepdog', 'Rough Collie', 'Old English Sheepdog', 'Tibetan Terrier', 'Borzoi', 'Swiss Mountain Dog Mix', 'French Bulldog', 'Dachshund', 'Boston Terrier', 'African wild dog', 'Schnauzer', 'Fox Terrier', 'Welsh Terrier', 'Cardigan Welsh Corgi', 'Giant Schnauzer', 'Scottish Terrier', 'Mastiff', 'Shih Tzu', 'Chihuahua', 'Dachshund', 'Boxer Bulldog Mix', 'Dachshund', 'Basset Hound', 'Shar Pei', 'Boston Terrier', 'Border Collie', 'German Rottweiler', 'Highland Terrier', 'Chocolate Labrador Retriever', 'Golden Retriever', 'American Staffordshire Terrier', 'Lurcher', 'St. Bernard puppy', 'Foxhound', 'Dalmatian', 'English Setter', 'Toy Spaniel', 'Swiss St. Bernard', 'Spoodle', 'Alaskan Malamute', 'Chow Chow', 'Maltese', 'Pug', 'Terrier mix', 'Miniature Schnauzer', 'Yorkshire Terrier', 'Vizsla', 'Newfoundland', 'Old English Sheepdog', 'Bernese Mountain Dog', 'West Highland White Terrier', 'Dachshund', 'Bichon Frise', 'Bloodhound', 'Basset Hound', 'Bulldog', 'Basset Hound', 'Dachshund', 'Beagle', 'American Eskimo Dog', 'Bloodhound', 'Basset Hound', 'Rhodesian Ridgeback', 'Wire-haired Fox Terrier', 'Pit Bull Terrier', 'Teddy Bear Dog', 'American Bulldog', 'Chi', 'Bullmastiff', 'Rottweiler', 'Keeshond', 'Labrador Retriever', 'Golden Retriever', 'Bernese Mountain Dog', 'Brussels Griffon', 'Bloodhound', 'Boxer', 'Doberman Pinscher', 'Jack Russell Terrier', 'Rottweiler puppy', 'Japanese Chin', 'Cocker Spaniel', 'Irish Terrier', 'Dalmatian', 'Basset Hound', 'Boxer', 'Retriever mix', 'Chinese Crested', 'Pinscher', 'Japanese Spitz', 'Basset Hound', 'Bloodhound', 'Great Dane', 'King Charles Spaniel', 'Poodle', 'Cocker Spaniel', 'Flat-Coated Retriever', 'American Pit Bull Terrier', 'Hound dog', 'Belgian Malinois', 'Beagle', 'Basset Hound', 'Bloodhound', 'Siberian Husky', 'Alaskan Malamute', 'Samoyed', 'Miniature Pinscher', 'Shiba Inu', 'Aberdeen Terrier', 'Alaskan Husky', 'Greyhound', 'Pembroke Welsh Corgi', 'Cardigan Welsh Corgi', 'Corgi Mix', 'Papillon', 'Chihuahua', 'Shih Tzu', 'Spitz Mix', 'Red Irish Wolfhound', 'Tibetan Mastiff', 'Tibetan Spaniel', 'Airedale Terrier', 'Standard Poodle', 'Brittany Spaniel', 'Rhodesian Ridgeback', 'Parson Russell Terrier', 'Bull Terrier', 'Pharaoh Hound', 'Cairn Terrier', 'Beagle mix', 'African Wild Dog', 'Biewer Terrier', 'Great Pyrenees', 'Pomeranian', 'Beagle crossbreed', 'Manchester Terrier', 'Long-haired Chihuahua', 'Chihuahua Terrier mix', 'Dachshund-Terrier Mix', 'Old English Sheepdog', 'Briard', 'Komondor', 'Boxer Mix', 'Chinese Crested Dog']
0it [00:00, ?it/s]1it [00:00,  4.34it/s]3it [00:00,  8.72it/s]5it [00:00,  8.57it/s]7it [00:00, 10.78it/s]9it [00:00, 11.89it/s]11it [00:01, 12.99it/s]13it [00:01, 14.04it/s]15it [00:01, 15.47it/s]17it [00:01, 16.06it/s]19it [00:01, 16.93it/s]21it [00:01, 16.19it/s]23it [00:01, 15.28it/s]25it [00:01, 12.24it/s]27it [00:02, 11.30it/s]29it [00:02, 10.47it/s]31it [00:02,  8.20it/s]33it [00:02,  9.86it/s]35it [00:02, 11.10it/s]37it [00:03, 12.61it/s]39it [00:03,  9.21it/s]41it [00:03, 10.06it/s]43it [00:03, 10.69it/s]45it [00:03, 12.14it/s]47it [00:04, 12.99it/s]49it [00:04, 13.44it/s]52it [00:04, 15.66it/s]54it [00:04, 15.73it/s]56it [00:04, 16.67it/s]58it [00:04, 16.81it/s]60it [00:04, 17.40it/s]62it [00:04, 13.15it/s]64it [00:05, 14.25it/s]66it [00:05, 14.71it/s]68it [00:05, 14.17it/s]70it [00:05, 14.12it/s]72it [00:05, 13.78it/s]74it [00:05, 14.21it/s]76it [00:05, 13.84it/s]78it [00:06, 14.28it/s]80it [00:06, 15.11it/s]82it [00:06, 15.65it/s]84it [00:06, 15.95it/s]86it [00:06, 16.33it/s]88it [00:06, 15.46it/s]90it [00:06, 14.95it/s]92it [00:06, 14.34it/s]94it [00:07, 14.29it/s]96it [00:07, 14.67it/s]98it [00:07, 14.06it/s]100it [00:07, 13.80it/s]102it [00:07, 13.73it/s]104it [00:07, 13.72it/s]106it [00:08, 13.99it/s]108it [00:08, 14.00it/s]110it [00:08, 13.74it/s]112it [00:08, 15.14it/s]114it [00:08, 15.08it/s]116it [00:08, 14.91it/s]118it [00:08, 14.96it/s]120it [00:08, 15.31it/s]122it [00:09, 15.03it/s]124it [00:09, 14.78it/s]126it [00:09, 14.84it/s]128it [00:09, 13.92it/s]130it [00:09, 14.40it/s]132it [00:09, 14.66it/s]134it [00:09, 14.79it/s]136it [00:10, 14.90it/s]138it [00:10, 14.63it/s]140it [00:10, 14.28it/s]142it [00:10, 13.88it/s]144it [00:10, 13.69it/s]146it [00:11,  5.83it/s]148it [00:13,  2.56it/s]149it [00:14,  2.00it/s]150it [00:15,  1.75it/s]151it [00:15,  1.61it/s]152it [00:16,  1.52it/s]153it [00:17,  1.47it/s]154it [00:18,  1.40it/s]155it [00:19,  1.33it/s]156it [00:19,  1.29it/s]157it [00:20,  1.26it/s]158it [00:21,  1.23it/s]159it [00:23,  1.06s/it]160it [00:24,  1.01s/it]161it [00:24,  1.10it/s]162it [00:25,  1.16it/s]163it [00:27,  1.04s/it]164it [00:28,  1.19s/it]165it [00:29,  1.07s/it]166it [00:30,  1.02it/s]167it [00:32,  1.27s/it]168it [00:33,  1.41s/it]169it [00:35,  1.50s/it]170it [00:37,  1.62s/it]171it [00:39,  1.65s/it]172it [00:40,  1.70s/it]173it [00:42,  1.75s/it]174it [00:44,  1.77s/it]175it [00:46,  1.81s/it]176it [00:48,  1.76s/it]177it [00:49,  1.57s/it]178it [00:50,  1.32s/it]179it [00:50,  1.18s/it]180it [00:51,  1.14s/it]181it [00:52,  1.02s/it]182it [00:53,  1.05s/it]183it [00:54,  1.04it/s]184it [00:55,  1.04it/s]185it [00:56,  1.10it/s]186it [00:56,  1.40it/s]187it [00:56,  1.64it/s]188it [00:57,  1.85it/s]189it [00:57,  2.01it/s]190it [00:58,  1.69it/s]191it [00:58,  2.16it/s]192it [00:58,  2.45it/s]193it [00:59,  2.87it/s]194it [00:59,  3.15it/s]195it [00:59,  3.59it/s]196it [00:59,  3.32it/s]197it [01:00,  2.68it/s]198it [01:00,  3.08it/s]199it [01:01,  2.41it/s]200it [01:01,  2.31it/s]201it [01:02,  2.36it/s]202it [01:02,  2.53it/s]203it [01:02,  3.04it/s]204it [01:02,  3.51it/s]205it [01:03,  2.56it/s]206it [01:03,  2.49it/s]207it [01:04,  2.69it/s]208it [01:04,  3.16it/s]209it [01:04,  2.95it/s]210it [01:05,  3.25it/s]211it [01:05,  3.96it/s]212it [01:05,  4.03it/s]213it [01:05,  3.70it/s]214it [01:06,  3.67it/s]215it [01:06,  2.41it/s]216it [01:07,  1.89it/s]217it [01:08,  1.81it/s]218it [01:08,  1.74it/s]219it [01:09,  1.81it/s]220it [01:09,  2.31it/s]221it [01:09,  2.59it/s]222it [01:10,  2.84it/s]223it [01:10,  2.78it/s]224it [01:10,  2.71it/s]225it [01:11,  3.08it/s]226it [01:11,  3.84it/s]227it [01:11,  4.20it/s]228it [01:11,  3.71it/s]229it [01:12,  2.42it/s]230it [01:13,  1.94it/s]231it [01:13,  1.70it/s]232it [01:14,  1.47it/s]233it [01:15,  1.47it/s]234it [01:16,  1.46it/s]235it [01:17,  1.37it/s]236it [01:17,  1.35it/s]237it [01:18,  1.33it/s]238it [01:19,  1.30it/s]239it [01:20,  1.32it/s]240it [01:20,  1.31it/s]241it [01:21,  1.30it/s]242it [01:22,  1.29it/s]243it [01:23,  1.26it/s]244it [01:24,  1.27it/s]245it [01:24,  1.24it/s]246it [01:25,  1.29it/s]247it [01:26,  1.27it/s]248it [01:27,  1.29it/s]249it [01:28,  1.07it/s]250it [01:29,  1.10it/s]251it [01:30,  1.17it/s]252it [01:30,  1.22it/s]253it [01:31,  1.18it/s]254it [01:32,  1.23it/s]255it [01:33,  1.25it/s]256it [01:34,  1.25it/s]257it [01:34,  1.28it/s]258it [01:35,  1.23it/s]259it [01:36,  1.27it/s]260it [01:37,  1.25it/s]261it [01:37,  1.30it/s]262it [01:38,  1.23it/s]263it [01:39,  1.25it/s]264it [01:40,  1.22it/s]265it [01:41,  1.21it/s]266it [01:42,  1.25it/s]267it [01:42,  1.22it/s]268it [01:43,  1.25it/s]269it [01:44,  1.31it/s]270it [01:45,  1.33it/s]271it [01:45,  1.35it/s]272it [01:46,  1.36it/s]273it [01:48,  1.01s/it]274it [01:49,  1.24s/it]275it [01:51,  1.40s/it]276it [01:53,  1.47s/it]277it [01:54,  1.53s/it]278it [01:55,  1.33s/it]279it [01:56,  1.15s/it]280it [01:57,  1.03s/it]281it [01:58,  1.06it/s]282it [01:58,  1.13it/s]283it [01:59,  1.08it/s]284it [02:00,  1.42it/s]285it [02:00,  1.55it/s]286it [02:01,  1.59it/s]288it [02:01,  2.66it/s]289it [02:01,  3.15it/s]290it [02:01,  3.80it/s]291it [02:01,  4.37it/s]293it [02:01,  6.27it/s]295it [02:01,  8.17it/s]297it [02:02,  8.47it/s]299it [02:02, 10.22it/s]301it [02:02, 11.39it/s]303it [02:02, 12.15it/s]305it [02:02, 12.73it/s]307it [02:02, 13.19it/s]309it [02:02, 14.67it/s]311it [02:03, 13.75it/s]313it [02:03, 13.64it/s]315it [02:03,  7.87it/s]317it [02:03,  9.14it/s]319it [02:04,  9.75it/s]321it [02:04, 10.72it/s]323it [02:04,  7.86it/s]325it [02:04,  6.77it/s]327it [02:05,  7.59it/s]329it [02:05,  8.47it/s]331it [02:05,  9.21it/s]333it [02:05, 10.07it/s]335it [02:05, 11.07it/s]337it [02:05, 11.65it/s]339it [02:06, 10.13it/s]341it [02:06, 11.35it/s]343it [02:06, 11.76it/s]345it [02:06, 12.40it/s]347it [02:06, 12.88it/s]349it [02:06, 13.49it/s]351it [02:07, 13.67it/s]353it [02:07, 13.68it/s]355it [02:07,  7.98it/s]357it [02:07,  8.93it/s]359it [02:08,  7.67it/s]360it [02:08,  4.87it/s]360it [02:08,  2.80it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]  3%|▎         | 1/34 [00:05<03:02,  5.52s/it]  6%|▌         | 2/34 [00:05<01:18,  2.45s/it]  9%|▉         | 3/34 [00:06<00:44,  1.43s/it] 12%|█▏        | 4/34 [00:06<00:29,  1.02it/s] 15%|█▍        | 5/34 [00:06<00:20,  1.42it/s] 18%|█▊        | 6/34 [00:06<00:15,  1.76it/s] 21%|██        | 7/34 [00:07<00:12,  2.23it/s] 24%|██▎       | 8/34 [00:07<00:10,  2.48it/s] 26%|██▋       | 9/34 [00:07<00:08,  2.93it/s] 29%|██▉       | 10/34 [00:07<00:07,  3.04it/s] 32%|███▏      | 11/34 [00:08<00:06,  3.44it/s] 35%|███▌      | 12/34 [00:08<00:06,  3.57it/s] 38%|███▊      | 13/34 [00:08<00:05,  3.89it/s] 41%|████      | 14/34 [00:08<00:04,  4.15it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.36it/s] 47%|████▋     | 16/34 [00:09<00:03,  4.51it/s] 50%|█████     | 17/34 [00:09<00:03,  4.62it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.70it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.76it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.80it/s] 62%|██████▏   | 21/34 [00:10<00:02,  4.83it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.86it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.87it/s] 71%|███████   | 24/34 [00:10<00:02,  4.89it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.91it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.91it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.91it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.92it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.92it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.92it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.92it/s]100%|██████████| 34/34 [00:12<00:00,  5.20it/s]100%|██████████| 34/34 [00:12<00:00,  2.63it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:33,  4.65s/it]  6%|▌         | 2/34 [00:04<01:05,  2.04s/it]  9%|▉         | 3/34 [00:05<00:37,  1.20s/it] 12%|█▏        | 4/34 [00:05<00:25,  1.16it/s] 15%|█▍        | 5/34 [00:05<00:19,  1.50it/s] 18%|█▊        | 6/34 [00:06<00:15,  1.81it/s] 21%|██        | 7/34 [00:06<00:11,  2.28it/s] 24%|██▎       | 8/34 [00:06<00:10,  2.47it/s] 26%|██▋       | 9/34 [00:06<00:08,  2.92it/s] 29%|██▉       | 10/34 [00:07<00:07,  3.30it/s] 32%|███▏      | 11/34 [00:07<00:06,  3.66it/s] 35%|███▌      | 12/34 [00:07<00:05,  3.96it/s] 38%|███▊      | 13/34 [00:07<00:04,  4.20it/s] 41%|████      | 14/34 [00:07<00:04,  4.36it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.46it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.55it/s] 50%|█████     | 17/34 [00:08<00:03,  4.61it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.69it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.75it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.78it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.81it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.84it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.86it/s] 71%|███████   | 24/34 [00:09<00:02,  4.87it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.84it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.85it/s] 79%|███████▉  | 27/34 [00:10<00:01,  4.86it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.87it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.88it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.84it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.85it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.87it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.87it/s]100%|██████████| 34/34 [00:11<00:00,  5.62it/s]100%|██████████| 34/34 [00:12<00:00,  2.82it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6513696908950806


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.39160839160839
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.52617107754439
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.45994297469391


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.13697052001953
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 12.81it/s]4it [00:00, 12.71it/s]6it [00:00,  9.25it/s]8it [00:00, 10.41it/s]10it [00:00, 12.22it/s]12it [00:01, 12.25it/s]14it [00:01, 12.47it/s]16it [00:01, 12.58it/s]18it [00:01, 12.55it/s]20it [00:01, 12.68it/s]22it [00:01, 12.62it/s]24it [00:01, 13.12it/s]26it [00:02,  9.10it/s]28it [00:02, 10.14it/s]30it [00:02,  9.84it/s]32it [00:03,  4.85it/s]33it [00:03,  4.18it/s]34it [00:04,  4.41it/s]35it [00:04,  4.54it/s]36it [00:04,  4.60it/s]37it [00:05,  2.74it/s]38it [00:06,  1.97it/s]39it [00:07,  1.72it/s]40it [00:07,  1.56it/s]41it [00:08,  1.49it/s]42it [00:09,  1.38it/s]43it [00:10,  1.43it/s]44it [00:10,  1.34it/s]45it [00:11,  1.36it/s]46it [00:12,  1.42it/s]47it [00:12,  1.43it/s]48it [00:13,  1.44it/s]49it [00:14,  1.47it/s]50it [00:14,  1.51it/s]51it [00:15,  1.49it/s]52it [00:16,  1.47it/s]53it [00:17,  1.22it/s]54it [00:18,  1.19it/s]55it [00:19,  1.22it/s]56it [00:19,  1.26it/s]57it [00:20,  1.25it/s]58it [00:21,  1.27it/s]59it [00:22,  1.30it/s]60it [00:22,  1.25it/s]61it [00:23,  1.29it/s]62it [00:24,  1.30it/s]63it [00:25,  1.29it/s]64it [00:26,  1.28it/s]65it [00:26,  1.26it/s]66it [00:27,  1.27it/s]67it [00:28,  1.28it/s]68it [00:29,  1.30it/s]69it [00:29,  1.33it/s]70it [00:30,  1.29it/s]71it [00:31,  1.31it/s]72it [00:32,  1.36it/s]73it [00:33,  1.26it/s]74it [00:33,  1.30it/s]75it [00:34,  1.27it/s]76it [00:35,  1.25it/s]77it [00:36,  1.22it/s]78it [00:37,  1.22it/s]79it [00:38,  1.15it/s]80it [00:38,  1.19it/s]81it [00:39,  1.20it/s]82it [00:40,  1.20it/s]83it [00:41,  1.23it/s]84it [00:41,  1.27it/s]85it [00:42,  1.26it/s]86it [00:43,  1.22it/s]87it [00:44,  1.25it/s]88it [00:45,  1.25it/s]89it [00:46,  1.21it/s]90it [00:46,  1.24it/s]91it [00:47,  1.24it/s]92it [00:48,  1.29it/s]93it [00:49,  1.27it/s]94it [00:49,  1.30it/s]95it [00:50,  1.33it/s]96it [00:51,  1.31it/s]97it [00:52,  1.34it/s]98it [00:52,  1.34it/s]99it [00:53,  1.34it/s]100it [00:54,  1.35it/s]101it [00:55,  1.31it/s]102it [00:55,  1.32it/s]103it [00:56,  1.33it/s]104it [00:57,  1.29it/s]105it [00:58,  1.20it/s]106it [00:59,  1.15it/s]107it [01:00,  1.16it/s]108it [01:01,  1.17it/s]109it [01:01,  1.22it/s]110it [01:02,  1.22it/s]111it [01:03,  1.19it/s]112it [01:04,  1.19it/s]113it [01:05,  1.20it/s]114it [01:05,  1.25it/s]115it [01:06,  1.24it/s]116it [01:07,  1.23it/s]117it [01:08,  1.25it/s]118it [01:09,  1.28it/s]119it [01:09,  1.30it/s]120it [01:10,  1.32it/s]121it [01:12,  1.03s/it]122it [01:14,  1.36s/it]123it [01:16,  1.72s/it]124it [01:19,  1.93s/it]125it [01:21,  2.15s/it]126it [01:23,  2.04s/it]127it [01:24,  1.71s/it]128it [01:25,  1.40s/it]129it [01:26,  1.20s/it]130it [01:26,  1.05s/it]131it [01:27,  1.02it/s]132it [01:28,  1.11it/s]133it [01:29,  1.14it/s]134it [01:29,  1.16it/s]135it [01:30,  1.15it/s]136it [01:31,  1.20it/s]137it [01:32,  1.21it/s]138it [01:33,  1.24it/s]139it [01:33,  1.28it/s]140it [01:34,  1.29it/s]141it [01:35,  1.28it/s]142it [01:36,  1.32it/s]143it [01:36,  1.30it/s]144it [01:37,  1.30it/s]145it [01:38,  1.29it/s]146it [01:39,  1.28it/s]147it [01:40,  1.30it/s]148it [01:40,  1.30it/s]149it [01:41,  1.33it/s]150it [01:42,  1.28it/s]151it [01:43,  1.22it/s]152it [01:44,  1.16it/s]153it [01:45,  1.18it/s]154it [01:45,  1.17it/s]155it [01:46,  1.15it/s]156it [01:47,  1.18it/s]157it [01:48,  1.27it/s]158it [01:49,  1.31it/s]159it [01:49,  1.33it/s]160it [01:50,  1.32it/s]161it [01:51,  1.26it/s]162it [01:52,  1.20it/s]163it [01:53,  1.18it/s]164it [01:54,  1.16it/s]165it [01:54,  1.18it/s]166it [01:55,  1.11it/s]167it [01:56,  1.10it/s]168it [01:57,  1.10it/s]169it [01:58,  1.14it/s]170it [01:59,  1.14it/s]171it [02:00,  1.16it/s]172it [02:00,  1.23it/s]173it [02:01,  1.17it/s]174it [02:02,  1.18it/s]175it [02:03,  1.22it/s]176it [02:04,  1.21it/s]177it [02:05,  1.24it/s]178it [02:05,  1.25it/s]179it [02:06,  1.25it/s]180it [02:07,  1.26it/s]181it [02:08,  1.18it/s]182it [02:09,  1.17it/s]183it [02:10,  1.22it/s]184it [02:10,  1.21it/s]185it [02:11,  1.17it/s]186it [02:12,  1.17it/s]187it [02:13,  1.20it/s]188it [02:14,  1.18it/s]189it [02:15,  1.18it/s]190it [02:17,  1.23s/it]191it [02:18,  1.12s/it]192it [02:18,  1.00s/it]193it [02:19,  1.03it/s]194it [02:20,  1.11it/s]195it [02:21,  1.23it/s]196it [02:21,  1.29it/s]197it [02:22,  1.32it/s]198it [02:23,  1.34it/s]199it [02:24,  1.28it/s]200it [02:25,  1.23it/s]201it [02:25,  1.17it/s]202it [02:26,  1.14it/s]203it [02:27,  1.19it/s]204it [02:28,  1.19it/s]205it [02:29,  1.31it/s]206it [02:30,  1.18it/s]207it [02:31,  1.16it/s]208it [02:31,  1.19it/s]209it [02:32,  1.20it/s]210it [02:33,  1.20it/s]211it [02:34,  1.23it/s]212it [02:34,  1.26it/s]213it [02:35,  1.23it/s]214it [02:36,  1.24it/s]215it [02:37,  1.27it/s]216it [02:38,  1.20it/s]217it [02:39,  1.06s/it]218it [02:40,  1.04s/it]219it [02:41,  1.04it/s]220it [02:43,  1.21s/it]221it [02:44,  1.21s/it]222it [02:45,  1.15s/it]223it [02:46,  1.04s/it]224it [02:47,  1.03it/s]225it [02:48,  1.10it/s]226it [02:48,  1.15it/s]227it [02:49,  1.13it/s]228it [02:50,  1.15it/s]229it [02:51,  1.20it/s]230it [02:52,  1.23it/s]231it [02:52,  1.21it/s]232it [02:53,  1.15it/s]233it [02:54,  1.16it/s]234it [02:55,  1.17it/s]235it [02:56,  1.21it/s]236it [02:57,  1.20it/s]237it [02:58,  1.19it/s]238it [02:58,  1.24it/s]239it [02:59,  1.23it/s]240it [03:00,  1.23it/s]241it [03:01,  1.21it/s]242it [03:02,  1.19it/s]243it [03:02,  1.25it/s]244it [03:03,  1.29it/s]245it [03:04,  1.29it/s]246it [03:05,  1.31it/s]247it [03:05,  1.31it/s]248it [03:06,  1.32it/s]249it [03:08,  1.04it/s]250it [03:09,  1.02it/s]251it [03:09,  1.04it/s]252it [03:10,  1.10it/s]253it [03:11,  1.14it/s]254it [03:12,  1.14it/s]255it [03:14,  1.28s/it]256it [03:17,  1.64s/it]257it [03:19,  1.86s/it]258it [03:21,  2.03s/it]259it [03:24,  2.22s/it]260it [03:26,  2.12s/it]261it [03:28,  2.11s/it]262it [03:30,  2.16s/it]263it [03:32,  1.95s/it]264it [03:33,  1.67s/it]265it [03:34,  1.60s/it]266it [03:35,  1.33s/it]267it [03:36,  1.16s/it]268it [03:37,  1.05s/it]269it [03:37,  1.01s/it]270it [03:38,  1.05it/s]271it [03:39,  1.14it/s]272it [03:40,  1.16it/s]273it [03:41,  1.18it/s]274it [03:41,  1.42it/s]276it [03:41,  2.02it/s]277it [03:42,  1.88it/s]278it [03:43,  1.93it/s]280it [03:43,  3.00it/s]282it [03:43,  3.30it/s]283it [03:43,  3.77it/s]284it [03:44,  4.00it/s]286it [03:44,  5.38it/s]287it [03:44,  4.20it/s]288it [03:45,  3.11it/s]289it [03:45,  3.53it/s]291it [03:45,  5.10it/s]292it [03:46,  3.81it/s]293it [03:46,  4.07it/s]295it [03:46,  5.87it/s]297it [03:46,  7.40it/s]299it [03:46,  9.04it/s]301it [03:46, 10.09it/s]303it [03:47, 10.81it/s]305it [03:47, 11.60it/s]307it [03:47, 12.01it/s]309it [03:47, 13.35it/s]311it [03:47, 12.52it/s]313it [03:47, 13.00it/s]315it [03:47, 13.68it/s]317it [03:47, 14.22it/s]319it [03:48, 11.57it/s]321it [03:48, 12.05it/s]323it [03:48, 11.69it/s]325it [03:48, 12.75it/s]327it [03:48, 11.46it/s]329it [03:49, 10.54it/s]331it [03:49, 11.18it/s]333it [03:49, 11.25it/s]335it [03:49, 11.69it/s]337it [03:49,  9.13it/s]339it [03:50,  6.99it/s]341it [03:50,  8.20it/s]343it [03:50,  9.28it/s]345it [03:50,  9.58it/s]347it [03:51,  6.07it/s]348it [03:51,  6.46it/s]349it [03:51,  5.88it/s]350it [03:51,  6.35it/s]351it [03:52,  5.00it/s]352it [03:52,  4.69it/s]354it [03:52,  5.76it/s]355it [03:52,  6.01it/s]356it [03:53,  3.81it/s]357it [03:54,  2.89it/s]358it [03:54,  2.34it/s]359it [03:55,  2.17it/s]360it [03:55,  1.92it/s]360it [03:55,  1.53it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:19,  4.23s/it]  6%|▌         | 2/34 [00:05<01:17,  2.41s/it]  9%|▉         | 3/34 [00:05<00:44,  1.45s/it] 12%|█▏        | 4/34 [00:05<00:28,  1.04it/s] 15%|█▍        | 5/34 [00:06<00:19,  1.45it/s] 18%|█▊        | 6/34 [00:06<00:14,  1.91it/s] 21%|██        | 7/34 [00:06<00:12,  2.16it/s] 24%|██▎       | 8/34 [00:06<00:10,  2.60it/s] 26%|██▋       | 9/34 [00:07<00:08,  3.01it/s] 29%|██▉       | 10/34 [00:07<00:07,  3.39it/s] 32%|███▏      | 11/34 [00:07<00:06,  3.71it/s] 35%|███▌      | 12/34 [00:07<00:05,  3.98it/s] 38%|███▊      | 13/34 [00:07<00:04,  4.21it/s] 41%|████      | 14/34 [00:08<00:04,  4.33it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.48it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.57it/s] 50%|█████     | 17/34 [00:08<00:03,  4.62it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.70it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.75it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.79it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.82it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.81it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.80it/s] 71%|███████   | 24/34 [00:10<00:02,  4.69it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.63it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.60it/s] 79%|███████▉  | 27/34 [00:10<00:01,  4.58it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.55it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.54it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.53it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.51it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.52it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.48it/s]100%|██████████| 34/34 [00:12<00:00,  5.27it/s]100%|██████████| 34/34 [00:12<00:00,  2.72it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:38,  4.82s/it]  6%|▌         | 2/34 [00:05<01:18,  2.44s/it]  9%|▉         | 3/34 [00:05<00:44,  1.42s/it] 12%|█▏        | 4/34 [00:06<00:28,  1.06it/s] 15%|█▍        | 5/34 [00:06<00:19,  1.48it/s] 18%|█▊        | 6/34 [00:06<00:14,  1.93it/s] 21%|██        | 7/34 [00:06<00:11,  2.40it/s] 24%|██▎       | 8/34 [00:06<00:09,  2.86it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.29it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.63it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.94it/s] 35%|███▌      | 12/34 [00:07<00:05,  4.19it/s] 38%|███▊      | 13/34 [00:07<00:04,  4.38it/s] 41%|████      | 14/34 [00:08<00:04,  4.49it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.60it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.67it/s] 50%|█████     | 17/34 [00:08<00:03,  4.74it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.78it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.82it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.80it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.83it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.84it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.86it/s] 71%|███████   | 24/34 [00:10<00:02,  4.87it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.87it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.09it/s] 79%|███████▉  | 27/34 [00:11<00:02,  3.31it/s] 82%|████████▏ | 28/34 [00:11<00:02,  2.91it/s] 85%|████████▌ | 29/34 [00:11<00:01,  2.69it/s] 88%|████████▊ | 30/34 [00:12<00:01,  2.56it/s] 91%|█████████ | 31/34 [00:12<00:01,  2.74it/s] 94%|█████████▍| 32/34 [00:12<00:00,  3.15it/s] 97%|█████████▋| 33/34 [00:13<00:00,  3.50it/s]100%|██████████| 34/34 [00:13<00:00,  4.30it/s]100%|██████████| 34/34 [00:13<00:00,  2.53it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6517574787139893


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.49650349650349
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.80531958055363
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.66412938137964


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.17575073242188
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  4.43it/s]2it [00:00,  1.93it/s]3it [00:01,  1.86it/s]4it [00:02,  1.85it/s]5it [00:03,  1.43it/s]6it [00:03,  1.55it/s]7it [00:04,  1.68it/s]8it [00:04,  1.66it/s]9it [00:05,  1.67it/s]10it [00:05,  1.66it/s]11it [00:06,  1.61it/s]12it [00:07,  1.62it/s]13it [00:07,  1.94it/s]14it [00:07,  2.26it/s]15it [00:08,  2.06it/s]16it [00:08,  1.88it/s]17it [00:09,  1.79it/s]18it [00:09,  2.06it/s]20it [00:10,  3.39it/s]21it [00:10,  4.04it/s]23it [00:10,  5.71it/s]25it [00:10,  7.45it/s]27it [00:10,  8.59it/s]29it [00:10,  9.79it/s]31it [00:10, 10.28it/s]33it [00:10, 12.03it/s]35it [00:11, 13.11it/s]37it [00:11,  9.68it/s]39it [00:11, 10.69it/s]41it [00:11, 10.51it/s]43it [00:11, 11.21it/s]45it [00:12, 12.02it/s]47it [00:12, 12.46it/s]49it [00:12, 13.42it/s]52it [00:12, 15.38it/s]54it [00:12, 14.56it/s]56it [00:13,  6.80it/s]58it [00:13,  6.09it/s]60it [00:13,  7.52it/s]62it [00:14,  5.82it/s]63it [00:14,  4.33it/s]64it [00:15,  3.76it/s]65it [00:15,  2.91it/s]66it [00:16,  2.48it/s]67it [00:17,  2.06it/s]68it [00:18,  1.67it/s]69it [00:18,  1.55it/s]70it [00:19,  1.49it/s]71it [00:20,  1.46it/s]72it [00:21,  1.39it/s]73it [00:21,  1.42it/s]74it [00:22,  1.35it/s]75it [00:23,  1.37it/s]76it [00:24,  1.33it/s]77it [00:24,  1.39it/s]78it [00:25,  1.39it/s]79it [00:26,  1.40it/s]80it [00:26,  1.40it/s]81it [00:27,  1.31it/s]82it [00:28,  1.30it/s]83it [00:29,  1.23it/s]84it [00:30,  1.25it/s]85it [00:31,  1.24it/s]86it [00:31,  1.22it/s]87it [00:32,  1.19it/s]88it [00:33,  1.10it/s]89it [00:34,  1.10it/s]90it [00:35,  1.17it/s]91it [00:36,  1.20it/s]92it [00:37,  1.16it/s]93it [00:38,  1.16it/s]94it [00:38,  1.21it/s]95it [00:39,  1.26it/s]96it [00:40,  1.24it/s]97it [00:41,  1.18it/s]98it [00:42,  1.19it/s]99it [00:43,  1.20it/s]100it [00:43,  1.19it/s]101it [00:44,  1.23it/s]102it [00:45,  1.29it/s]103it [00:46,  1.33it/s]104it [00:46,  1.37it/s]105it [00:47,  1.34it/s]106it [00:48,  1.38it/s]107it [00:48,  1.53it/s]108it [00:48,  1.87it/s]109it [00:49,  2.17it/s]110it [00:49,  2.08it/s]111it [00:50,  2.10it/s]112it [00:50,  2.07it/s]113it [00:51,  1.94it/s]114it [00:51,  1.81it/s]115it [00:52,  1.71it/s]116it [00:53,  1.60it/s]117it [00:54,  1.51it/s]118it [00:54,  1.48it/s]119it [00:55,  1.45it/s]120it [00:56,  1.48it/s]121it [00:56,  1.68it/s]122it [00:57,  1.55it/s]123it [00:58,  1.47it/s]124it [00:58,  1.37it/s]125it [00:59,  1.34it/s]126it [01:00,  1.30it/s]127it [01:01,  1.28it/s]128it [01:02,  1.31it/s]129it [01:02,  1.37it/s]130it [01:03,  1.38it/s]131it [01:04,  1.37it/s]132it [01:04,  1.40it/s]133it [01:05,  1.31it/s]134it [01:06,  1.25it/s]135it [01:07,  1.26it/s]136it [01:08,  1.33it/s]137it [01:08,  1.32it/s]138it [01:09,  1.25it/s]139it [01:10,  1.24it/s]140it [01:11,  1.26it/s]141it [01:12,  1.30it/s]142it [01:12,  1.30it/s]143it [01:13,  1.35it/s]144it [01:14,  1.37it/s]145it [01:14,  1.38it/s]146it [01:15,  1.38it/s]147it [01:16,  1.34it/s]148it [01:17,  1.32it/s]149it [01:17,  1.30it/s]150it [01:18,  1.33it/s]151it [01:19,  1.31it/s]152it [01:20,  1.37it/s]153it [01:20,  1.38it/s]154it [01:21,  1.28it/s]155it [01:22,  1.27it/s]156it [01:23,  1.28it/s]157it [01:24,  1.30it/s]158it [01:25,  1.16it/s]159it [01:26,  1.15it/s]160it [01:27,  1.07it/s]161it [01:28,  1.03it/s]162it [01:29,  1.03it/s]163it [01:29,  1.13it/s]164it [01:30,  1.18it/s]165it [01:31,  1.23it/s]166it [01:32,  1.22it/s]167it [01:33,  1.16it/s]168it [01:33,  1.18it/s]169it [01:34,  1.22it/s]170it [01:35,  1.24it/s]171it [01:36,  1.24it/s]172it [01:36,  1.32it/s]173it [01:37,  1.29it/s]174it [01:38,  1.14it/s]175it [01:40,  1.16s/it]176it [01:42,  1.37s/it]177it [01:44,  1.49s/it]178it [01:46,  1.61s/it]179it [01:47,  1.59s/it]180it [01:49,  1.61s/it]181it [01:51,  1.63s/it]182it [01:52,  1.54s/it]183it [01:53,  1.32s/it]184it [01:53,  1.17s/it]185it [01:55,  1.12s/it]186it [01:55,  1.06s/it]187it [01:56,  1.02it/s]188it [01:57,  1.12it/s]189it [01:58,  1.21it/s]190it [01:58,  1.22it/s]191it [01:59,  1.30it/s]192it [02:00,  1.41it/s]193it [02:00,  1.41it/s]194it [02:01,  1.37it/s]195it [02:02,  1.41it/s]196it [02:02,  1.71it/s]197it [02:02,  2.04it/s]198it [02:03,  2.23it/s]199it [02:03,  2.00it/s]200it [02:04,  2.10it/s]201it [02:04,  1.93it/s]202it [02:05,  1.87it/s]203it [02:05,  2.17it/s]204it [02:06,  2.02it/s]205it [02:06,  1.88it/s]206it [02:07,  1.60it/s]207it [02:08,  1.64it/s]208it [02:08,  1.65it/s]209it [02:09,  1.85it/s]210it [02:09,  1.72it/s]211it [02:10,  1.78it/s]212it [02:11,  1.71it/s]213it [02:11,  1.61it/s]214it [02:12,  1.71it/s]215it [02:12,  1.71it/s]216it [02:13,  1.69it/s]217it [02:14,  1.69it/s]218it [02:14,  1.52it/s]219it [02:15,  1.65it/s]220it [02:15,  1.66it/s]221it [02:16,  1.88it/s]222it [02:16,  2.10it/s]223it [02:17,  1.95it/s]224it [02:17,  2.34it/s]225it [02:18,  2.12it/s]226it [02:18,  1.85it/s]227it [02:19,  1.64it/s]228it [02:20,  1.55it/s]229it [02:21,  1.47it/s]230it [02:21,  1.41it/s]231it [02:22,  1.40it/s]232it [02:23,  1.38it/s]233it [02:24,  1.31it/s]234it [02:25,  1.26it/s]235it [02:25,  1.27it/s]236it [02:26,  1.31it/s]237it [02:27,  1.28it/s]238it [02:28,  1.19it/s]239it [02:29,  1.21it/s]240it [02:29,  1.20it/s]241it [02:30,  1.38it/s]242it [02:31,  1.43it/s]243it [02:31,  1.46it/s]244it [02:32,  1.42it/s]245it [02:33,  1.28it/s]246it [02:34,  1.24it/s]247it [02:35,  1.24it/s]248it [02:35,  1.27it/s]249it [02:36,  1.15it/s]250it [02:37,  1.16it/s]251it [02:38,  1.16it/s]252it [02:39,  1.14it/s]253it [02:40,  1.18it/s]254it [02:41,  1.20it/s]255it [02:41,  1.22it/s]256it [02:42,  1.19it/s]257it [02:43,  1.23it/s]258it [02:44,  1.26it/s]259it [02:44,  1.30it/s]260it [02:45,  1.28it/s]261it [02:46,  1.26it/s]262it [02:47,  1.21it/s]263it [02:48,  1.20it/s]264it [02:49,  1.22it/s]265it [02:49,  1.26it/s]266it [02:50,  1.32it/s]267it [02:51,  1.32it/s]268it [02:52,  1.35it/s]269it [02:52,  1.26it/s]270it [02:53,  1.29it/s]271it [02:54,  1.27it/s]272it [02:55,  1.23it/s]273it [02:56,  1.23it/s]274it [02:56,  1.28it/s]275it [02:57,  1.30it/s]276it [02:58,  1.27it/s]277it [02:59,  1.29it/s]278it [02:59,  1.28it/s]279it [03:00,  1.32it/s]280it [03:01,  1.36it/s]281it [03:02,  1.34it/s]282it [03:02,  1.31it/s]283it [03:03,  1.30it/s]284it [03:04,  1.30it/s]285it [03:05,  1.28it/s]286it [03:05,  1.33it/s]287it [03:06,  1.29it/s]288it [03:07,  1.24it/s]289it [03:08,  1.21it/s]290it [03:09,  1.23it/s]291it [03:10,  1.28it/s]292it [03:10,  1.30it/s]293it [03:11,  1.32it/s]294it [03:12,  1.34it/s]295it [03:12,  1.38it/s]296it [03:13,  1.39it/s]297it [03:14,  1.31it/s]298it [03:15,  1.32it/s]299it [03:15,  1.33it/s]300it [03:16,  1.37it/s]301it [03:17,  1.41it/s]302it [03:18,  1.35it/s]303it [03:18,  1.35it/s]304it [03:19,  1.35it/s]305it [03:20,  1.27it/s]306it [03:21,  1.25it/s]307it [03:22,  1.23it/s]308it [03:22,  1.36it/s]309it [03:23,  1.38it/s]310it [03:24,  1.44it/s]311it [03:24,  1.45it/s]312it [03:25,  1.36it/s]313it [03:26,  1.32it/s]314it [03:27,  1.34it/s]315it [03:27,  1.35it/s]316it [03:28,  1.38it/s]317it [03:29,  1.37it/s]318it [03:29,  1.37it/s]319it [03:30,  1.51it/s]320it [03:31,  1.49it/s]321it [03:31,  1.44it/s]322it [03:32,  1.41it/s]323it [03:33,  1.37it/s]324it [03:34,  1.34it/s]325it [03:35,  1.30it/s]326it [03:35,  1.29it/s]327it [03:36,  1.17it/s]328it [03:37,  1.18it/s]329it [03:38,  1.22it/s]330it [03:39,  1.26it/s]331it [03:40,  1.25it/s]332it [03:40,  1.25it/s]333it [03:41,  1.27it/s]334it [03:42,  1.27it/s]335it [03:43,  1.20it/s]336it [03:44,  1.24it/s]337it [03:44,  1.21it/s]338it [03:45,  1.24it/s]339it [03:47,  1.14s/it]340it [03:49,  1.26s/it]341it [03:50,  1.13s/it]342it [03:50,  1.02s/it]343it [03:51,  1.06it/s]344it [03:52,  1.12it/s]345it [03:53,  1.17it/s]346it [03:53,  1.18it/s]347it [03:54,  1.19it/s]348it [03:55,  1.20it/s]349it [03:56,  1.22it/s]350it [03:57,  1.22it/s]351it [03:57,  1.26it/s]352it [03:58,  1.26it/s]353it [03:59,  1.27it/s]354it [04:00,  1.24it/s]355it [04:01,  1.27it/s]356it [04:01,  1.27it/s]357it [04:02,  1.32it/s]358it [04:03,  1.24it/s]359it [04:04,  1.20it/s]360it [04:05,  1.22it/s]360it [04:05,  1.47it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:03,  5.55s/it]  6%|▌         | 2/34 [00:05<01:17,  2.41s/it]  9%|▉         | 3/34 [00:05<00:43,  1.40s/it] 12%|█▏        | 4/34 [00:06<00:27,  1.08it/s] 15%|█▍        | 5/34 [00:06<00:19,  1.50it/s] 18%|█▊        | 6/34 [00:06<00:14,  1.95it/s] 21%|██        | 7/34 [00:06<00:11,  2.42it/s] 24%|██▎       | 8/34 [00:06<00:09,  2.88it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.30it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.66it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.96it/s] 35%|███▌      | 12/34 [00:07<00:05,  4.20it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.39it/s] 41%|████      | 14/34 [00:08<00:04,  4.49it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.60it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.68it/s] 50%|█████     | 17/34 [00:08<00:03,  4.74it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.78it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.81it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.79it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.82it/s] 65%|██████▍   | 22/34 [00:09<00:02,  4.84it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.83it/s] 71%|███████   | 24/34 [00:10<00:02,  4.85it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.86it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.86it/s] 79%|███████▉  | 27/34 [00:10<00:01,  4.83it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.85it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.85it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.86it/s] 91%|█████████ | 31/34 [00:11<00:00,  4.87it/s] 94%|█████████▍| 32/34 [00:11<00:00,  4.87it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.83it/s]100%|██████████| 34/34 [00:12<00:00,  5.64it/s]100%|██████████| 34/34 [00:12<00:00,  2.73it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:04,  5.59s/it]  6%|▌         | 2/34 [00:05<01:17,  2.42s/it]  9%|▉         | 3/34 [00:06<00:43,  1.41s/it] 12%|█▏        | 4/34 [00:06<00:28,  1.07it/s] 15%|█▍        | 5/34 [00:06<00:19,  1.48it/s] 18%|█▊        | 6/34 [00:06<00:14,  1.94it/s] 21%|██        | 7/34 [00:06<00:11,  2.40it/s] 24%|██▎       | 8/34 [00:07<00:09,  2.83it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.22it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.59it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.89it/s] 35%|███▌      | 12/34 [00:07<00:05,  4.11it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.28it/s] 41%|████      | 14/34 [00:08<00:04,  4.45it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.50it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.60it/s] 50%|█████     | 17/34 [00:09<00:04,  3.58it/s] 53%|█████▎    | 18/34 [00:09<00:05,  3.05it/s] 56%|█████▌    | 19/34 [00:10<00:05,  2.78it/s] 59%|█████▉    | 20/34 [00:10<00:05,  2.62it/s] 62%|██████▏   | 21/34 [00:10<00:05,  2.51it/s] 65%|██████▍   | 22/34 [00:11<00:04,  2.91it/s] 68%|██████▊   | 23/34 [00:11<00:03,  3.31it/s] 71%|███████   | 24/34 [00:11<00:02,  3.67it/s] 74%|███████▎  | 25/34 [00:11<00:02,  3.97it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.21it/s] 79%|███████▉  | 27/34 [00:12<00:01,  4.40it/s] 82%|████████▏ | 28/34 [00:12<00:01,  4.54it/s] 85%|████████▌ | 29/34 [00:12<00:01,  4.65it/s] 88%|████████▊ | 30/34 [00:12<00:00,  4.71it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.76it/s] 94%|█████████▍| 32/34 [00:13<00:00,  4.70it/s] 97%|█████████▋| 33/34 [00:13<00:00,  3.70it/s]100%|██████████| 34/34 [00:13<00:00,  3.94it/s]100%|██████████| 34/34 [00:13<00:00,  2.43it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6501280665397644


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 47.5990675990676
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.24221193518564
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 34.75135180977843


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.01280975341797
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 11.43it/s]4it [00:00,  6.56it/s]5it [00:00,  4.70it/s]6it [00:01,  5.48it/s]8it [00:01,  5.98it/s]10it [00:01,  7.85it/s]11it [00:01,  7.39it/s]13it [00:01,  9.07it/s]15it [00:01,  9.71it/s]17it [00:02, 10.77it/s]19it [00:02, 10.04it/s]21it [00:02, 11.23it/s]23it [00:02, 12.06it/s]25it [00:02, 12.93it/s]27it [00:02, 13.23it/s]29it [00:02, 13.92it/s]31it [00:03, 13.89it/s]33it [00:03, 14.05it/s]35it [00:03, 14.45it/s]37it [00:03, 13.84it/s]39it [00:03, 13.65it/s]41it [00:03, 14.00it/s]43it [00:04, 13.62it/s]45it [00:04, 14.12it/s]47it [00:04, 14.03it/s]49it [00:04, 13.99it/s]52it [00:04, 15.54it/s]54it [00:04, 15.16it/s]56it [00:04, 15.36it/s]58it [00:04, 15.69it/s]60it [00:05, 16.27it/s]62it [00:05, 15.29it/s]64it [00:05, 15.97it/s]66it [00:05, 15.62it/s]68it [00:05, 15.83it/s]70it [00:05, 15.09it/s]72it [00:06, 11.18it/s]74it [00:06,  9.91it/s]76it [00:06, 11.30it/s]78it [00:06, 12.73it/s]80it [00:07,  7.49it/s]82it [00:07,  4.65it/s]83it [00:08,  3.84it/s]84it [00:08,  3.02it/s]85it [00:09,  2.47it/s]86it [00:10,  2.14it/s]87it [00:11,  1.87it/s]88it [00:11,  1.65it/s]89it [00:12,  1.52it/s]90it [00:13,  1.46it/s]91it [00:14,  1.36it/s]92it [00:15,  1.33it/s]93it [00:15,  1.26it/s]94it [00:16,  1.30it/s]95it [00:17,  1.28it/s]96it [00:18,  1.27it/s]97it [00:19,  1.26it/s]98it [00:19,  1.26it/s]99it [00:20,  1.29it/s]100it [00:21,  1.32it/s]101it [00:22,  1.29it/s]102it [00:22,  1.30it/s]103it [00:23,  1.35it/s]104it [00:24,  1.34it/s]105it [00:25,  1.32it/s]106it [00:25,  1.34it/s]107it [00:26,  1.37it/s]108it [00:27,  1.37it/s]109it [00:27,  1.39it/s]110it [00:28,  1.38it/s]111it [00:29,  1.33it/s]112it [00:30,  1.34it/s]113it [00:30,  1.32it/s]114it [00:31,  1.25it/s]115it [00:32,  1.17it/s]116it [00:33,  1.16it/s]117it [00:34,  1.12it/s]118it [00:35,  1.13it/s]119it [00:36,  1.14it/s]120it [00:37,  1.15it/s]121it [00:38,  1.18it/s]122it [00:38,  1.21it/s]123it [00:39,  1.20it/s]124it [00:40,  1.24it/s]125it [00:41,  1.24it/s]126it [00:41,  1.28it/s]127it [00:42,  1.31it/s]128it [00:43,  1.22it/s]129it [00:44,  1.19it/s]130it [00:45,  1.18it/s]131it [00:46,  1.26it/s]132it [00:47,  1.14it/s]133it [00:48,  1.14it/s]134it [00:48,  1.21it/s]135it [00:49,  1.21it/s]136it [00:50,  1.27it/s]137it [00:51,  1.24it/s]138it [00:51,  1.27it/s]139it [00:52,  1.26it/s]140it [00:53,  1.31it/s]141it [00:54,  1.34it/s]142it [00:54,  1.31it/s]143it [00:55,  1.32it/s]144it [00:56,  1.29it/s]145it [00:57,  1.31it/s]146it [00:58,  1.25it/s]147it [00:58,  1.24it/s]148it [00:59,  1.24it/s]149it [01:00,  1.20it/s]150it [01:01,  1.17it/s]151it [01:02,  1.14it/s]152it [01:03,  1.20it/s]153it [01:03,  1.28it/s]154it [01:04,  1.28it/s]155it [01:05,  1.35it/s]156it [01:05,  1.34it/s]157it [01:06,  1.36it/s]158it [01:07,  1.35it/s]159it [01:08,  1.21it/s]160it [01:09,  1.16it/s]161it [01:10,  1.18it/s]162it [01:10,  1.23it/s]163it [01:11,  1.24it/s]164it [01:12,  1.37it/s]165it [01:12,  1.39it/s]166it [01:13,  1.36it/s]167it [01:15,  1.01s/it]168it [01:17,  1.20s/it]169it [01:18,  1.34s/it]170it [01:20,  1.41s/it]171it [01:21,  1.20s/it]172it [01:21,  1.03s/it]173it [01:22,  1.08it/s]174it [01:22,  1.18it/s]175it [01:23,  1.22it/s]176it [01:24,  1.26it/s]177it [01:25,  1.25it/s]178it [01:26,  1.30it/s]179it [01:26,  1.26it/s]180it [01:27,  1.28it/s]181it [01:28,  1.27it/s]182it [01:29,  1.22it/s]183it [01:29,  1.28it/s]184it [01:30,  1.28it/s]185it [01:31,  1.20it/s]186it [01:32,  1.25it/s]187it [01:33,  1.30it/s]188it [01:33,  1.28it/s]189it [01:34,  1.22it/s]190it [01:36,  1.13s/it]191it [01:37,  1.03s/it]192it [01:38,  1.07it/s]193it [01:38,  1.14it/s]194it [01:39,  1.17it/s]195it [01:41,  1.05s/it]196it [01:42,  1.13s/it]197it [01:43,  1.06s/it]198it [01:44,  1.05it/s]199it [01:45,  1.06it/s]200it [01:45,  1.12it/s]201it [01:46,  1.18it/s]202it [01:47,  1.23it/s]203it [01:48,  1.26it/s]204it [01:48,  1.23it/s]205it [01:49,  1.19it/s]206it [01:50,  1.18it/s]207it [01:51,  1.21it/s]208it [01:52,  1.24it/s]209it [01:53,  1.25it/s]210it [01:53,  1.31it/s]211it [01:54,  1.31it/s]212it [01:55,  1.31it/s]213it [01:56,  1.30it/s]214it [01:56,  1.32it/s]215it [01:57,  1.35it/s]216it [01:58,  1.34it/s]217it [01:59,  1.32it/s]218it [01:59,  1.29it/s]219it [02:00,  1.33it/s]220it [02:01,  1.36it/s]221it [02:01,  1.38it/s]222it [02:02,  1.38it/s]223it [02:03,  1.40it/s]224it [02:04,  1.38it/s]225it [02:04,  1.32it/s]226it [02:05,  1.32it/s]227it [02:06,  1.31it/s]228it [02:07,  1.32it/s]229it [02:07,  1.31it/s]230it [02:08,  1.36it/s]231it [02:09,  1.32it/s]232it [02:10,  1.28it/s]233it [02:11,  1.29it/s]234it [02:11,  1.27it/s]235it [02:12,  1.26it/s]236it [02:13,  1.27it/s]237it [02:14,  1.31it/s]238it [02:14,  1.31it/s]239it [02:15,  1.28it/s]240it [02:16,  1.25it/s]241it [02:17,  1.25it/s]242it [02:18,  1.20it/s]243it [02:19,  1.21it/s]244it [02:20,  1.18it/s]245it [02:20,  1.20it/s]246it [02:21,  1.19it/s]247it [02:22,  1.19it/s]248it [02:23,  1.18it/s]249it [02:24,  1.01it/s]250it [02:25,  1.04it/s]251it [02:26,  1.09it/s]252it [02:28,  1.17s/it]253it [02:30,  1.56s/it]254it [02:32,  1.66s/it]255it [02:34,  1.71s/it]256it [02:36,  1.87s/it]257it [02:38,  1.87s/it]258it [02:40,  1.90s/it]259it [02:42,  2.02s/it]260it [02:44,  1.98s/it]261it [02:46,  2.01s/it]262it [02:48,  2.04s/it]263it [02:50,  1.96s/it]264it [02:51,  1.75s/it]265it [02:52,  1.47s/it]266it [02:53,  1.25s/it]267it [02:54,  1.15s/it]268it [02:55,  1.05s/it]269it [02:55,  1.02it/s]270it [02:56,  1.10it/s]271it [02:57,  1.14it/s]272it [02:58,  1.15it/s]273it [02:59,  1.16it/s]274it [03:00,  1.18it/s]275it [03:00,  1.17it/s]276it [03:01,  1.20it/s]277it [03:02,  1.22it/s]278it [03:03,  1.22it/s]279it [03:04,  1.27it/s]280it [03:04,  1.33it/s]281it [03:05,  1.34it/s]282it [03:06,  1.31it/s]283it [03:07,  1.26it/s]284it [03:07,  1.23it/s]285it [03:08,  1.25it/s]286it [03:09,  1.24it/s]287it [03:10,  1.31it/s]288it [03:10,  1.29it/s]289it [03:11,  1.29it/s]290it [03:12,  1.32it/s]291it [03:13,  1.35it/s]292it [03:13,  1.31it/s]293it [03:14,  1.35it/s]294it [03:15,  1.31it/s]295it [03:16,  1.31it/s]296it [03:16,  1.32it/s]297it [03:17,  1.34it/s]298it [03:18,  1.41it/s]299it [03:18,  1.45it/s]300it [03:19,  1.41it/s]301it [03:20,  1.44it/s]302it [03:21,  1.37it/s]303it [03:21,  1.48it/s]304it [03:22,  1.46it/s]305it [03:23,  1.38it/s]306it [03:24,  1.35it/s]307it [03:24,  1.33it/s]308it [03:25,  1.33it/s]309it [03:26,  1.31it/s]310it [03:27,  1.28it/s]311it [03:28,  1.22it/s]312it [03:28,  1.28it/s]313it [03:29,  1.30it/s]314it [03:30,  1.28it/s]315it [03:31,  1.32it/s]316it [03:31,  1.34it/s]317it [03:32,  1.33it/s]318it [03:33,  1.32it/s]319it [03:34,  1.30it/s]320it [03:34,  1.27it/s]321it [03:35,  1.25it/s]322it [03:36,  1.26it/s]323it [03:37,  1.26it/s]324it [03:38,  1.23it/s]325it [03:39,  1.21it/s]326it [03:39,  1.25it/s]327it [03:40,  1.26it/s]328it [03:41,  1.29it/s]329it [03:42,  1.29it/s]330it [03:42,  1.29it/s]331it [03:43,  1.26it/s]332it [03:44,  1.28it/s]333it [03:45,  1.32it/s]334it [03:45,  1.34it/s]335it [03:46,  1.21it/s]336it [03:47,  1.13it/s]337it [03:48,  1.16it/s]338it [03:49,  1.13it/s]339it [03:50,  1.01it/s]340it [03:51,  1.09it/s]341it [03:52,  1.13it/s]342it [03:53,  1.19it/s]343it [03:54,  1.16it/s]344it [03:54,  1.18it/s]345it [03:55,  1.26it/s]346it [03:56,  1.29it/s]347it [03:57,  1.32it/s]348it [03:57,  1.31it/s]349it [03:58,  1.52it/s]350it [03:58,  1.64it/s]351it [03:59,  1.67it/s]352it [03:59,  1.93it/s]353it [04:00,  1.73it/s]354it [04:01,  1.57it/s]355it [04:01,  1.56it/s]356it [04:02,  1.84it/s]357it [04:02,  1.71it/s]358it [04:03,  1.70it/s]360it [04:03,  2.81it/s]360it [04:03,  1.48it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:18,  4.20s/it]  6%|▌         | 2/34 [00:04<00:59,  1.85s/it]  9%|▉         | 3/34 [00:04<00:34,  1.10s/it] 12%|█▏        | 4/34 [00:04<00:22,  1.34it/s] 15%|█▍        | 5/34 [00:05<00:16,  1.81it/s] 18%|█▊        | 6/34 [00:05<00:13,  2.12it/s] 21%|██        | 7/34 [00:05<00:10,  2.60it/s] 24%|██▎       | 8/34 [00:05<00:08,  3.06it/s] 26%|██▋       | 9/34 [00:05<00:07,  3.46it/s] 29%|██▉       | 10/34 [00:06<00:06,  3.81it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.08it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.29it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.30it/s] 41%|████      | 14/34 [00:07<00:04,  4.32it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.32it/s] 47%|████▋     | 16/34 [00:07<00:04,  4.01it/s] 50%|█████     | 17/34 [00:07<00:04,  4.20it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.38it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.48it/s] 59%|█████▉    | 20/34 [00:08<00:03,  4.55it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.60it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.64it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.67it/s] 71%|███████   | 24/34 [00:09<00:02,  4.69it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.74it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.71it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.76it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.76it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.79it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.75it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.79it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.77it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.80it/s]100%|██████████| 34/34 [00:11<00:00,  5.61it/s]100%|██████████| 34/34 [00:11<00:00,  2.96it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:00,  5.48s/it]  6%|▌         | 2/34 [00:05<01:21,  2.54s/it]  9%|▉         | 3/34 [00:06<00:45,  1.48s/it] 12%|█▏        | 4/34 [00:06<00:29,  1.02it/s] 15%|█▍        | 5/34 [00:06<00:21,  1.37it/s] 18%|█▊        | 6/34 [00:06<00:15,  1.81it/s] 21%|██        | 7/34 [00:07<00:11,  2.28it/s] 24%|██▎       | 8/34 [00:07<00:09,  2.73it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.15it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.54it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.86it/s] 35%|███▌      | 12/34 [00:08<00:05,  4.12it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.33it/s] 41%|████      | 14/34 [00:08<00:04,  4.48it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.56it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.65it/s] 50%|█████     | 17/34 [00:09<00:03,  4.70it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.75it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.75it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.78it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.80it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.77it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.80it/s] 71%|███████   | 24/34 [00:10<00:02,  4.81it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.82it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.73it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.52it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.62it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.69it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.69it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.74it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.78it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.80it/s]100%|██████████| 34/34 [00:12<00:00,  5.61it/s]100%|██████████| 34/34 [00:12<00:00,  2.64it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6538708209991455


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.75291375291375
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.5103821660226
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.36104038587664


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.3870849609375
=========================          END          =========================
0it [00:00, ?it/s]1it [00:02,  2.37s/it]2it [00:04,  2.34s/it]3it [00:07,  2.46s/it]4it [00:10,  2.58s/it]5it [00:13,  2.73s/it]6it [00:15,  2.77s/it]7it [00:18,  2.83s/it]8it [00:21,  2.75s/it]9it [00:24,  2.75s/it]10it [00:27,  2.85s/it]11it [00:30,  2.87s/it]12it [00:32,  2.84s/it]13it [00:35,  2.63s/it]14it [00:37,  2.59s/it]15it [00:39,  2.48s/it]16it [00:41,  2.37s/it]17it [00:44,  2.42s/it]18it [00:46,  2.39s/it]19it [00:48,  2.29s/it]20it [00:50,  2.24s/it]21it [00:51,  1.87s/it]22it [00:53,  1.75s/it]23it [00:55,  1.76s/it]24it [00:57,  1.92s/it]25it [00:59,  1.84s/it]26it [01:01,  1.98s/it]27it [01:03,  2.07s/it]28it [01:05,  2.02s/it]29it [01:07,  2.08s/it]30it [01:09,  2.09s/it]31it [01:11,  2.06s/it]32it [01:13,  1.88s/it]33it [01:14,  1.58s/it]34it [01:15,  1.32s/it]35it [01:15,  1.13s/it]36it [01:16,  1.06s/it]37it [01:17,  1.00it/s]38it [01:18,  1.04it/s]39it [01:19,  1.10it/s]40it [01:19,  1.19it/s]41it [01:20,  1.21it/s]42it [01:21,  1.24it/s]43it [01:22,  1.18it/s]44it [01:23,  1.21it/s]45it [01:23,  1.20it/s]46it [01:24,  1.23it/s]47it [01:25,  1.27it/s]48it [01:26,  1.30it/s]49it [01:26,  1.31it/s]50it [01:27,  1.33it/s]51it [01:28,  1.34it/s]52it [01:29,  1.30it/s]53it [01:30,  1.28it/s]54it [01:30,  1.29it/s]55it [01:31,  1.29it/s]56it [01:32,  1.27it/s]57it [01:33,  1.20it/s]58it [01:34,  1.13it/s]59it [01:35,  1.15it/s]60it [01:36,  1.13it/s]61it [01:37,  1.09it/s]62it [01:37,  1.13it/s]63it [01:38,  1.17it/s]64it [01:39,  1.22it/s]65it [01:40,  1.24it/s]66it [01:40,  1.29it/s]67it [01:41,  1.31it/s]68it [01:42,  1.29it/s]69it [01:43,  1.22it/s]70it [01:44,  1.12it/s]71it [01:45,  1.10it/s]72it [01:46,  1.18it/s]73it [01:46,  1.19it/s]74it [01:47,  1.20it/s]75it [01:48,  1.13it/s]76it [01:49,  1.07it/s]77it [01:50,  1.08it/s]78it [01:51,  1.03it/s]79it [01:52,  1.03it/s]80it [01:53,  1.00it/s]81it [01:54,  1.02s/it]82it [01:55,  1.02s/it]83it [01:56,  1.02s/it]84it [01:58,  1.24s/it]85it [01:59,  1.17s/it]87it [01:59,  1.52it/s]89it [01:59,  2.34it/s]90it [02:00,  2.78it/s]91it [02:00,  2.94it/s]92it [02:00,  3.10it/s]93it [02:00,  3.32it/s]94it [02:00,  3.92it/s]95it [02:01,  3.81it/s]96it [02:01,  3.81it/s]97it [02:01,  3.87it/s]98it [02:01,  4.10it/s]99it [02:02,  4.91it/s]101it [02:02,  6.73it/s]102it [02:02,  7.21it/s]103it [02:02,  7.05it/s]104it [02:02,  6.67it/s]105it [02:02,  7.02it/s]106it [02:03,  4.24it/s]107it [02:03,  2.77it/s]108it [02:04,  1.74it/s]109it [02:05,  1.53it/s]110it [02:06,  1.45it/s]111it [02:07,  1.37it/s]112it [02:08,  1.30it/s]113it [02:09,  1.25it/s]114it [02:10,  1.20it/s]115it [02:11,  1.15it/s]116it [02:11,  1.19it/s]117it [02:12,  1.25it/s]118it [02:13,  1.23it/s]119it [02:14,  1.18it/s]120it [02:15,  1.20it/s]121it [02:16,  1.06it/s]122it [02:17,  1.07it/s]123it [02:18,  1.07it/s]124it [02:18,  1.09it/s]125it [02:19,  1.10it/s]126it [02:20,  1.16it/s]127it [02:20,  1.45it/s]128it [02:21,  1.37it/s]129it [02:22,  1.37it/s]130it [02:23,  1.37it/s]131it [02:23,  1.40it/s]132it [02:24,  1.37it/s]133it [02:25,  1.37it/s]134it [02:26,  1.40it/s]135it [02:26,  1.34it/s]136it [02:27,  1.35it/s]137it [02:28,  1.34it/s]138it [02:29,  1.26it/s]139it [02:30,  1.25it/s]140it [02:30,  1.29it/s]141it [02:31,  1.26it/s]142it [02:32,  1.27it/s]143it [02:33,  1.29it/s]144it [02:33,  1.29it/s]145it [02:34,  1.30it/s]146it [02:35,  1.31it/s]147it [02:36,  1.30it/s]148it [02:36,  1.34it/s]149it [02:37,  1.23it/s]150it [02:38,  1.18it/s]151it [02:39,  1.23it/s]152it [02:40,  1.27it/s]153it [02:41,  1.29it/s]154it [02:41,  1.34it/s]155it [02:42,  1.37it/s]156it [02:43,  1.31it/s]157it [02:44,  1.20it/s]158it [02:45,  1.21it/s]159it [02:45,  1.22it/s]160it [02:46,  1.26it/s]161it [02:47,  1.27it/s]162it [02:48,  1.29it/s]163it [02:48,  1.30it/s]164it [02:50,  1.09s/it]165it [02:51,  1.07s/it]166it [02:52,  1.05it/s]167it [02:53,  1.09it/s]168it [02:53,  1.18it/s]169it [02:54,  1.23it/s]170it [02:55,  1.24it/s]171it [02:56,  1.26it/s]172it [02:57,  1.26it/s]173it [02:57,  1.23it/s]174it [02:58,  1.25it/s]175it [02:59,  1.29it/s]176it [03:00,  1.31it/s]177it [03:02,  1.17s/it]178it [03:04,  1.45s/it]179it [03:06,  1.57s/it]180it [03:08,  1.67s/it]181it [03:10,  1.76s/it]182it [03:12,  1.89s/it]183it [03:15,  2.16s/it]184it [03:17,  2.28s/it]185it [03:20,  2.47s/it]186it [03:22,  2.43s/it]187it [03:24,  2.21s/it]188it [03:26,  2.12s/it]189it [03:28,  2.13s/it]190it [03:30,  2.20s/it]191it [03:33,  2.19s/it]192it [03:35,  2.15s/it]193it [03:36,  2.05s/it]194it [03:38,  2.01s/it]195it [03:40,  2.00s/it]196it [03:43,  2.10s/it]197it [03:45,  2.25s/it]198it [03:47,  2.24s/it]199it [03:50,  2.27s/it]200it [03:52,  2.23s/it]201it [03:55,  2.32s/it]202it [03:57,  2.29s/it]203it [03:59,  2.21s/it]204it [03:59,  1.77s/it]205it [04:00,  1.45s/it]206it [04:01,  1.25s/it]207it [04:02,  1.10s/it]208it [04:02,  1.03it/s]209it [04:03,  1.12it/s]210it [04:04,  1.23it/s]211it [04:04,  1.30it/s]212it [04:05,  1.26it/s]213it [04:06,  1.30it/s]214it [04:07,  1.37it/s]215it [04:07,  1.37it/s]216it [04:08,  1.36it/s]217it [04:09,  1.34it/s]218it [04:10,  1.39it/s]219it [04:10,  1.37it/s]220it [04:11,  1.45it/s]221it [04:12,  1.39it/s]222it [04:12,  1.40it/s]223it [04:13,  1.40it/s]224it [04:14,  1.41it/s]225it [04:14,  1.43it/s]226it [04:15,  1.59it/s]227it [04:16,  1.52it/s]228it [04:16,  1.49it/s]229it [04:17,  1.59it/s]230it [04:17,  1.86it/s]231it [04:18,  2.03it/s]232it [04:18,  2.45it/s]233it [04:18,  2.74it/s]234it [04:18,  3.01it/s]235it [04:19,  3.19it/s]236it [04:19,  3.19it/s]237it [04:19,  3.12it/s]238it [04:20,  3.26it/s]239it [04:20,  3.41it/s]240it [04:20,  3.36it/s]241it [04:20,  3.93it/s]242it [04:20,  4.06it/s]243it [04:21,  2.88it/s]244it [04:22,  2.60it/s]245it [04:22,  2.80it/s]246it [04:22,  2.60it/s]247it [04:22,  3.13it/s]248it [04:23,  3.02it/s]249it [04:24,  2.05it/s]250it [04:24,  1.83it/s]251it [04:25,  1.67it/s]252it [04:26,  1.61it/s]253it [04:26,  1.50it/s]254it [04:27,  1.44it/s]255it [04:28,  1.48it/s]256it [04:29,  1.49it/s]257it [04:29,  1.79it/s]258it [04:30,  1.57it/s]259it [04:30,  1.56it/s]260it [04:31,  1.50it/s]261it [04:32,  1.51it/s]262it [04:32,  1.43it/s]263it [04:33,  1.37it/s]264it [04:34,  1.37it/s]265it [04:35,  1.34it/s]266it [04:36,  1.23it/s]267it [04:37,  1.01s/it]268it [04:38,  1.08s/it]269it [04:40,  1.11s/it]270it [04:41,  1.04s/it]271it [04:41,  1.03it/s]272it [04:42,  1.06it/s]273it [04:43,  1.08it/s]274it [04:44,  1.15it/s]275it [04:45,  1.18it/s]276it [04:45,  1.23it/s]277it [04:46,  1.29it/s]278it [04:47,  1.31it/s]279it [04:48,  1.30it/s]280it [04:48,  1.23it/s]281it [04:49,  1.20it/s]282it [04:50,  1.26it/s]283it [04:51,  1.29it/s]284it [04:52,  1.28it/s]285it [04:52,  1.28it/s]286it [04:53,  1.28it/s]287it [04:54,  1.31it/s]288it [04:55,  1.27it/s]289it [04:55,  1.30it/s]290it [04:56,  1.33it/s]291it [04:57,  1.28it/s]292it [04:57,  1.51it/s]293it [04:58,  1.58it/s]294it [04:58,  1.87it/s]295it [04:59,  1.92it/s]296it [04:59,  1.80it/s]297it [05:00,  1.93it/s]298it [05:00,  2.27it/s]299it [05:01,  2.17it/s]301it [05:01,  3.53it/s]303it [05:01,  4.98it/s]304it [05:01,  4.72it/s]306it [05:01,  6.25it/s]308it [05:01,  8.26it/s]310it [05:02,  7.24it/s]312it [05:03,  3.95it/s]313it [05:03,  3.28it/s]314it [05:04,  3.35it/s]315it [05:04,  3.73it/s]316it [05:04,  3.42it/s]317it [05:04,  3.31it/s]318it [05:05,  3.82it/s]319it [05:05,  4.15it/s]320it [05:05,  3.86it/s]321it [05:06,  2.79it/s]322it [05:06,  2.70it/s]323it [05:06,  2.62it/s]324it [05:07,  2.54it/s]325it [05:07,  2.55it/s]326it [05:08,  2.86it/s]327it [05:08,  2.76it/s]328it [05:08,  2.51it/s]329it [05:09,  1.95it/s]330it [05:09,  2.17it/s]331it [05:10,  2.56it/s]332it [05:10,  2.53it/s]333it [05:10,  3.03it/s]334it [05:10,  3.82it/s]335it [05:11,  3.65it/s]336it [05:11,  4.40it/s]337it [05:11,  4.62it/s]338it [05:11,  4.73it/s]339it [05:12,  3.39it/s]340it [05:12,  3.02it/s]341it [05:13,  2.80it/s]342it [05:13,  3.30it/s]343it [05:13,  2.43it/s]344it [05:14,  1.85it/s]345it [05:14,  2.21it/s]346it [05:15,  2.41it/s]347it [05:15,  2.29it/s]348it [05:16,  2.21it/s]349it [05:16,  2.57it/s]350it [05:17,  2.37it/s]351it [05:17,  2.35it/s]352it [05:17,  2.50it/s]353it [05:18,  2.58it/s]354it [05:18,  2.00it/s]355it [05:19,  1.59it/s]356it [05:20,  1.42it/s]357it [05:21,  1.32it/s]358it [05:22,  1.27it/s]359it [05:23,  1.28it/s]360it [05:24,  1.24it/s]360it [05:24,  1.11it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:05<03:09,  5.73s/it]  6%|▌         | 2/34 [00:05<01:19,  2.48s/it]  9%|▉         | 3/34 [00:06<00:44,  1.44s/it] 12%|█▏        | 4/34 [00:06<00:28,  1.05it/s] 15%|█▍        | 5/34 [00:06<00:19,  1.46it/s] 18%|█▊        | 6/34 [00:06<00:14,  1.91it/s] 21%|██        | 7/34 [00:06<00:11,  2.38it/s] 24%|██▎       | 8/34 [00:07<00:09,  2.82it/s] 26%|██▋       | 9/34 [00:07<00:07,  3.23it/s] 29%|██▉       | 10/34 [00:07<00:06,  3.57it/s] 32%|███▏      | 11/34 [00:07<00:05,  3.86it/s] 35%|███▌      | 12/34 [00:08<00:05,  4.11it/s] 38%|███▊      | 13/34 [00:08<00:04,  4.28it/s] 41%|████      | 14/34 [00:08<00:04,  4.40it/s] 44%|████▍     | 15/34 [00:08<00:04,  4.49it/s] 47%|████▋     | 16/34 [00:08<00:03,  4.59it/s] 50%|█████     | 17/34 [00:09<00:03,  4.63it/s] 53%|█████▎    | 18/34 [00:09<00:03,  4.66it/s] 56%|█████▌    | 19/34 [00:09<00:03,  4.73it/s] 59%|█████▉    | 20/34 [00:09<00:02,  4.73it/s] 62%|██████▏   | 21/34 [00:09<00:02,  4.78it/s] 65%|██████▍   | 22/34 [00:10<00:02,  4.77it/s] 68%|██████▊   | 23/34 [00:10<00:02,  4.76it/s] 71%|███████   | 24/34 [00:10<00:02,  4.80it/s] 74%|███████▎  | 25/34 [00:10<00:01,  4.78it/s] 76%|███████▋  | 26/34 [00:10<00:01,  4.81it/s] 79%|███████▉  | 27/34 [00:11<00:01,  4.79it/s] 82%|████████▏ | 28/34 [00:11<00:01,  4.82it/s] 85%|████████▌ | 29/34 [00:11<00:01,  4.76it/s] 88%|████████▊ | 30/34 [00:11<00:00,  4.71it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.68it/s] 94%|█████████▍| 32/34 [00:12<00:00,  4.63it/s] 97%|█████████▋| 33/34 [00:12<00:00,  4.59it/s]100%|██████████| 34/34 [00:12<00:00,  5.36it/s]100%|██████████| 34/34 [00:12<00:00,  2.66it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:22,  4.30s/it]  6%|▌         | 2/34 [00:04<01:01,  1.93s/it]  9%|▉         | 3/34 [00:04<00:36,  1.18s/it] 12%|█▏        | 4/34 [00:05<00:24,  1.24it/s] 15%|█▍        | 5/34 [00:05<00:17,  1.70it/s] 18%|█▊        | 6/34 [00:05<00:12,  2.18it/s] 21%|██        | 7/34 [00:05<00:10,  2.66it/s] 24%|██▎       | 8/34 [00:05<00:08,  3.11it/s] 26%|██▋       | 9/34 [00:06<00:07,  3.51it/s] 29%|██▉       | 10/34 [00:06<00:06,  3.84it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.11it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.32it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.48it/s] 41%|████      | 14/34 [00:07<00:04,  4.59it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.64it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.71it/s] 50%|█████     | 17/34 [00:07<00:03,  4.75it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.30it/s] 56%|█████▌    | 19/34 [00:08<00:04,  3.58it/s] 59%|█████▉    | 20/34 [00:08<00:04,  3.15it/s] 62%|██████▏   | 21/34 [00:09<00:04,  2.91it/s] 65%|██████▍   | 22/34 [00:09<00:04,  2.76it/s] 68%|██████▊   | 23/34 [00:10<00:04,  2.66it/s] 71%|███████   | 24/34 [00:10<00:03,  2.59it/s] 74%|███████▎  | 25/34 [00:10<00:03,  2.55it/s] 76%|███████▋  | 26/34 [00:11<00:03,  2.53it/s] 79%|███████▉  | 27/34 [00:11<00:02,  2.50it/s] 82%|████████▏ | 28/34 [00:12<00:02,  2.48it/s] 85%|████████▌ | 29/34 [00:12<00:02,  2.48it/s] 88%|████████▊ | 30/34 [00:12<00:01,  2.48it/s] 91%|█████████ | 31/34 [00:13<00:01,  2.44it/s] 94%|█████████▍| 32/34 [00:13<00:00,  2.42it/s] 97%|█████████▋| 33/34 [00:14<00:00,  2.40it/s]100%|██████████| 34/34 [00:14<00:00,  2.79it/s]100%|██████████| 34/34 [00:14<00:00,  2.33it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6503355503082275


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.64801864801865
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.614710853235
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.693360460914555


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.03355407714844
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 12.08it/s]4it [00:00, 12.13it/s]6it [00:00,  9.03it/s]8it [00:00, 10.54it/s]10it [00:00, 11.78it/s]12it [00:01, 11.62it/s]14it [00:01, 11.73it/s]16it [00:01, 11.64it/s]18it [00:01, 11.30it/s]20it [00:01, 11.83it/s]22it [00:01, 11.35it/s]24it [00:02, 11.96it/s]26it [00:02, 12.94it/s]28it [00:02,  8.61it/s]30it [00:02,  9.35it/s]32it [00:02, 10.14it/s]34it [00:03, 11.70it/s]36it [00:03, 12.57it/s]38it [00:03, 12.75it/s]40it [00:03, 13.05it/s]42it [00:03, 13.21it/s]44it [00:03, 12.99it/s]46it [00:03, 13.47it/s]48it [00:04, 13.45it/s]50it [00:04, 14.79it/s]52it [00:04, 15.37it/s]54it [00:04, 14.38it/s]56it [00:04, 14.72it/s]58it [00:04, 14.94it/s]60it [00:04, 15.68it/s]62it [00:04, 16.40it/s]64it [00:05, 16.81it/s]66it [00:05, 17.35it/s]68it [00:05, 15.42it/s]70it [00:05, 14.90it/s]72it [00:05, 14.71it/s]74it [00:05, 14.74it/s]76it [00:05, 14.47it/s]78it [00:06, 14.94it/s]80it [00:06, 13.79it/s]82it [00:06, 13.65it/s]84it [00:06, 11.68it/s]86it [00:06, 10.82it/s]88it [00:06, 11.28it/s]90it [00:07, 11.94it/s]92it [00:07, 12.02it/s]94it [00:07, 12.44it/s]96it [00:07, 13.12it/s]98it [00:07, 12.52it/s]100it [00:07, 13.13it/s]102it [00:08, 12.40it/s]104it [00:08, 12.21it/s]106it [00:08, 12.81it/s]108it [00:08, 12.29it/s]110it [00:08, 12.16it/s]112it [00:08, 13.31it/s]114it [00:08, 14.27it/s]116it [00:09, 14.27it/s]118it [00:09, 14.46it/s]120it [00:09, 15.09it/s]122it [00:09, 13.96it/s]124it [00:09, 14.34it/s]126it [00:09, 14.45it/s]128it [00:09, 14.13it/s]130it [00:10, 15.17it/s]132it [00:10, 15.71it/s]134it [00:10, 14.18it/s]136it [00:10, 14.35it/s]138it [00:10, 13.70it/s]140it [00:10, 13.27it/s]142it [00:10, 13.54it/s]144it [00:12,  4.29it/s]146it [00:12,  4.80it/s]148it [00:12,  5.82it/s]150it [00:12,  6.94it/s]152it [00:12,  8.15it/s]154it [00:13,  9.22it/s]156it [00:13,  5.47it/s]157it [00:14,  4.52it/s]158it [00:14,  4.26it/s]159it [00:14,  3.42it/s]160it [00:15,  3.32it/s]161it [00:15,  3.34it/s]162it [00:16,  2.86it/s]163it [00:16,  2.60it/s]164it [00:17,  2.30it/s]165it [00:17,  2.41it/s]166it [00:18,  2.14it/s]167it [00:18,  1.87it/s]168it [00:19,  1.93it/s]169it [00:19,  2.27it/s]170it [00:19,  2.14it/s]171it [00:20,  1.98it/s]172it [00:20,  2.40it/s]174it [00:20,  3.90it/s]176it [00:21,  5.37it/s]178it [00:21,  7.09it/s]180it [00:21,  8.50it/s]182it [00:21,  8.73it/s]184it [00:21,  8.40it/s]186it [00:21, 10.04it/s]188it [00:22, 10.85it/s]190it [00:22,  7.52it/s]192it [00:22,  8.82it/s]194it [00:22,  9.70it/s]196it [00:22, 10.85it/s]198it [00:23, 12.15it/s]200it [00:23, 13.12it/s]202it [00:23, 13.27it/s]204it [00:23, 14.01it/s]206it [00:23, 13.65it/s]208it [00:23, 13.73it/s]210it [00:23, 13.80it/s]212it [00:24, 10.86it/s]214it [00:24, 11.83it/s]216it [00:24, 12.15it/s]218it [00:24, 11.20it/s]220it [00:24, 12.58it/s]222it [00:24, 12.52it/s]224it [00:25, 12.16it/s]226it [00:25, 10.99it/s]228it [00:25, 11.67it/s]230it [00:25,  8.39it/s]232it [00:26,  9.17it/s]234it [00:26,  9.44it/s]236it [00:26, 10.37it/s]238it [00:26, 11.05it/s]240it [00:27,  5.76it/s]241it [00:28,  3.43it/s]242it [00:28,  2.80it/s]243it [00:29,  2.37it/s]244it [00:30,  2.02it/s]245it [00:30,  1.86it/s]246it [00:31,  1.80it/s]247it [00:32,  1.72it/s]248it [00:32,  1.77it/s]249it [00:33,  1.55it/s]250it [00:34,  1.47it/s]251it [00:35,  1.31it/s]252it [00:36,  1.21it/s]253it [00:37,  1.20it/s]254it [00:37,  1.29it/s]255it [00:38,  1.37it/s]256it [00:38,  1.39it/s]257it [00:40,  1.19it/s]258it [00:41,  1.10it/s]259it [00:41,  1.16it/s]260it [00:42,  1.08it/s]261it [00:43,  1.27it/s]262it [00:44,  1.18it/s]263it [00:45,  1.25it/s]264it [00:45,  1.31it/s]265it [00:46,  1.30it/s]266it [00:47,  1.46it/s]267it [00:47,  1.43it/s]268it [00:48,  1.41it/s]269it [00:49,  1.26it/s]270it [00:50,  1.30it/s]271it [00:51,  1.29it/s]272it [00:52,  1.18it/s]273it [00:52,  1.14it/s]274it [00:54,  1.04it/s]275it [00:55,  1.06s/it]276it [00:56,  1.09s/it]277it [00:57,  1.07it/s]278it [00:58,  1.05it/s]279it [00:59,  1.04it/s]280it [00:59,  1.09it/s]281it [01:00,  1.26it/s]282it [01:01,  1.34it/s]283it [01:02,  1.06it/s]284it [01:03,  1.10it/s]285it [01:03,  1.21it/s]286it [01:04,  1.31it/s]287it [01:05,  1.29it/s]288it [01:06,  1.28it/s]289it [01:06,  1.42it/s]290it [01:07,  1.49it/s]291it [01:07,  1.59it/s]292it [01:08,  1.42it/s]293it [01:09,  1.39it/s]294it [01:10,  1.37it/s]295it [01:10,  1.43it/s]296it [01:11,  1.45it/s]297it [01:12,  1.48it/s]298it [01:12,  1.51it/s]299it [01:13,  1.53it/s]300it [01:14,  1.40it/s]301it [01:15,  1.38it/s]302it [01:15,  1.34it/s]303it [01:16,  1.29it/s]304it [01:17,  1.38it/s]305it [01:17,  1.69it/s]306it [01:17,  2.16it/s]307it [01:18,  2.08it/s]308it [01:18,  2.00it/s]309it [01:19,  2.02it/s]310it [01:19,  1.99it/s]311it [01:20,  1.97it/s]312it [01:20,  2.11it/s]313it [01:21,  1.96it/s]314it [01:21,  1.90it/s]315it [01:22,  1.88it/s]316it [01:23,  1.75it/s]317it [01:23,  1.69it/s]318it [01:24,  1.74it/s]319it [01:24,  1.86it/s]320it [01:25,  1.85it/s]321it [01:25,  2.00it/s]322it [01:26,  1.83it/s]323it [01:26,  1.76it/s]324it [01:27,  1.72it/s]325it [01:27,  2.04it/s]326it [01:27,  2.62it/s]327it [01:28,  2.14it/s]328it [01:29,  1.92it/s]329it [01:29,  2.35it/s]330it [01:29,  2.32it/s]331it [01:30,  2.52it/s]332it [01:30,  2.68it/s]333it [01:31,  2.38it/s]334it [01:31,  2.78it/s]335it [01:31,  3.03it/s]336it [01:31,  3.18it/s]337it [01:31,  3.78it/s]338it [01:32,  3.89it/s]339it [01:32,  2.70it/s]340it [01:33,  2.42it/s]341it [01:33,  2.47it/s]342it [01:34,  2.23it/s]343it [01:34,  2.46it/s]344it [01:35,  2.22it/s]345it [01:35,  2.62it/s]346it [01:35,  2.76it/s]347it [01:35,  3.01it/s]348it [01:36,  2.74it/s]349it [01:36,  2.55it/s]350it [01:37,  2.22it/s]351it [01:37,  2.56it/s]352it [01:37,  3.05it/s]353it [01:37,  3.79it/s]354it [01:38,  2.88it/s]355it [01:39,  2.23it/s]356it [01:39,  1.91it/s]357it [01:40,  1.71it/s]358it [01:41,  1.51it/s]359it [01:42,  1.44it/s]360it [01:42,  1.66it/s]360it [01:42,  3.51it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:00,  3.65s/it]  6%|▌         | 2/34 [00:03<00:52,  1.64s/it]  9%|▉         | 3/34 [00:04<00:30,  1.02it/s] 12%|█▏        | 4/34 [00:04<00:20,  1.47it/s] 15%|█▍        | 5/34 [00:04<00:14,  1.97it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.47it/s] 21%|██        | 7/34 [00:04<00:09,  2.94it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.36it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.72it/s] 29%|██▉       | 10/34 [00:05<00:05,  4.01it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.23it/s] 35%|███▌      | 12/34 [00:05<00:04,  4.41it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.54it/s] 41%|████      | 14/34 [00:06<00:04,  4.64it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.72it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.77it/s] 50%|█████     | 17/34 [00:06<00:03,  4.81it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.83it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.85it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.86it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:07<00:02,  4.87it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.88it/s] 71%|███████   | 24/34 [00:08<00:02,  4.89it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.89it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.89it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.89it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.89it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.89it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.89it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.89it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.89it/s]100%|██████████| 34/34 [00:10<00:00,  5.70it/s]100%|██████████| 34/34 [00:10<00:00,  3.23it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967992782593
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:11,  3.99s/it]  6%|▌         | 2/34 [00:04<00:56,  1.76s/it]  9%|▉         | 3/34 [00:04<00:32,  1.05s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.39it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.88it/s] 18%|█▊        | 6/34 [00:05<00:11,  2.38it/s] 21%|██        | 7/34 [00:05<00:09,  2.86it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.30it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.67it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.98it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.22it/s] 35%|███▌      | 12/34 [00:06<00:04,  4.41it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.55it/s] 41%|████      | 14/34 [00:06<00:04,  4.65it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.72it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.78it/s] 50%|█████     | 17/34 [00:07<00:03,  4.81it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.87it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.88it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.89it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.89it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.89it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.90it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.72it/s]100%|██████████| 34/34 [00:10<00:00,  3.14it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6542661786079407


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36968231201172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.68298368298368
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.76124546642058
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.65335076157802


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.42662048339844
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.29s/it]2it [00:02,  1.29s/it]3it [00:04,  1.41s/it]4it [00:05,  1.46s/it]5it [00:07,  1.59s/it]6it [00:08,  1.56s/it]7it [00:10,  1.46s/it]8it [00:11,  1.41s/it]9it [00:12,  1.36s/it]10it [00:14,  1.60s/it]11it [00:16,  1.68s/it]12it [00:18,  1.69s/it]13it [00:19,  1.58s/it]14it [00:21,  1.52s/it]15it [00:22,  1.47s/it]16it [00:24,  1.47s/it]17it [00:25,  1.43s/it]18it [00:26,  1.40s/it]19it [00:28,  1.48s/it]20it [00:30,  1.72s/it]21it [00:32,  1.79s/it]22it [00:33,  1.65s/it]23it [00:35,  1.55s/it]24it [00:37,  1.62s/it]25it [00:38,  1.60s/it]26it [00:40,  1.72s/it]27it [00:42,  1.66s/it]28it [00:43,  1.60s/it]29it [00:45,  1.64s/it]30it [00:47,  1.74s/it]31it [00:48,  1.70s/it]32it [00:50,  1.62s/it]33it [00:51,  1.63s/it]34it [00:53,  1.64s/it]35it [00:54,  1.55s/it]36it [00:56,  1.60s/it]37it [00:58,  1.58s/it]38it [00:59,  1.58s/it]39it [01:01,  1.66s/it]40it [01:03,  1.64s/it]41it [01:05,  1.75s/it]42it [01:07,  1.79s/it]43it [01:08,  1.80s/it]44it [01:10,  1.82s/it]45it [01:12,  1.82s/it]46it [01:14,  1.80s/it]47it [01:15,  1.74s/it]48it [01:17,  1.76s/it]49it [01:19,  1.77s/it]50it [01:21,  1.75s/it]51it [01:23,  1.75s/it]52it [01:24,  1.74s/it]53it [01:26,  1.83s/it]54it [01:28,  1.82s/it]55it [01:29,  1.68s/it]56it [01:31,  1.53s/it]57it [01:32,  1.40s/it]58it [01:33,  1.34s/it]59it [01:35,  1.42s/it]60it [01:36,  1.48s/it]61it [01:38,  1.46s/it]62it [01:39,  1.45s/it]63it [01:40,  1.45s/it]64it [01:42,  1.58s/it]65it [01:44,  1.50s/it]66it [01:45,  1.35s/it]67it [01:46,  1.36s/it]68it [01:47,  1.26s/it]69it [01:48,  1.27s/it]70it [01:50,  1.28s/it]71it [01:51,  1.21s/it]72it [01:51,  1.08s/it]73it [01:52,  1.02it/s]74it [01:53,  1.06it/s]75it [01:54,  1.17it/s]76it [01:54,  1.28it/s]77it [01:56,  1.11it/s]78it [01:57,  1.13s/it]79it [01:59,  1.23s/it]80it [02:00,  1.34s/it]81it [02:02,  1.37s/it]82it [02:03,  1.30s/it]83it [02:04,  1.26s/it]84it [02:05,  1.27s/it]85it [02:07,  1.28s/it]86it [02:08,  1.24s/it]87it [02:09,  1.17s/it]88it [02:10,  1.07s/it]89it [02:10,  1.08it/s]90it [02:11,  1.16it/s]91it [02:12,  1.22it/s]92it [02:13,  1.12it/s]93it [02:14,  1.13it/s]94it [02:15,  1.01s/it]95it [02:16,  1.03s/it]96it [02:17,  1.01it/s]97it [02:18,  1.05it/s]98it [02:19,  1.02s/it]99it [02:20,  1.00it/s]100it [02:20,  1.11it/s]101it [02:21,  1.17it/s]102it [02:22,  1.06it/s]103it [02:23,  1.02it/s]104it [02:24,  1.01it/s]105it [02:25,  1.06it/s]106it [02:26,  1.15it/s]107it [02:27,  1.24it/s]108it [02:27,  1.28it/s]109it [02:28,  1.41it/s]110it [02:28,  1.79it/s]111it [02:28,  2.22it/s]112it [02:28,  2.79it/s]113it [02:29,  3.09it/s]115it [02:29,  4.24it/s]116it [02:29,  4.39it/s]117it [02:29,  4.42it/s]118it [02:30,  4.48it/s]119it [02:30,  4.81it/s]120it [02:30,  4.11it/s]121it [02:30,  3.64it/s]122it [02:31,  3.78it/s]123it [02:31,  3.13it/s]125it [02:31,  4.98it/s]127it [02:31,  6.80it/s]129it [02:31,  8.70it/s]131it [02:32, 10.23it/s]133it [02:32, 12.09it/s]135it [02:32, 13.33it/s]138it [02:32, 15.06it/s]140it [02:32, 15.54it/s]142it [02:32, 15.82it/s]144it [02:32, 16.07it/s]146it [02:33, 10.53it/s]148it [02:33,  5.59it/s]150it [02:34,  7.03it/s]152it [02:34,  8.66it/s]154it [02:34, 10.11it/s]156it [02:34, 11.30it/s]158it [02:34,  9.19it/s]160it [02:35,  7.70it/s]162it [02:35,  7.09it/s]164it [02:35,  7.78it/s]165it [02:35,  7.00it/s]166it [02:36,  3.53it/s]167it [02:37,  2.55it/s]168it [02:37,  2.60it/s]169it [02:37,  2.96it/s]170it [02:38,  3.29it/s]171it [02:38,  3.27it/s]172it [02:38,  3.88it/s]173it [02:38,  4.36it/s]174it [02:38,  4.67it/s]175it [02:39,  4.32it/s]176it [02:39,  3.81it/s]177it [02:40,  3.17it/s]178it [02:40,  2.85it/s]179it [02:40,  3.31it/s]180it [02:40,  3.23it/s]181it [02:41,  2.48it/s]182it [02:42,  2.08it/s]183it [02:43,  1.77it/s]184it [02:43,  1.82it/s]185it [02:44,  1.73it/s]186it [02:44,  1.68it/s]187it [02:45,  1.94it/s]188it [02:45,  1.85it/s]189it [02:46,  1.77it/s]190it [02:46,  2.00it/s]192it [02:46,  3.37it/s]194it [02:46,  4.94it/s]196it [02:47,  6.57it/s]199it [02:47,  9.38it/s]201it [02:47, 10.52it/s]204it [02:47, 12.76it/s]206it [02:47, 13.51it/s]208it [02:47, 14.08it/s]210it [02:47, 14.64it/s]213it [02:48, 15.92it/s]215it [02:48, 15.92it/s]217it [02:48, 16.30it/s]219it [02:48, 16.86it/s]221it [02:48, 16.19it/s]224it [02:48, 17.41it/s]227it [02:48, 18.88it/s]229it [02:48, 18.30it/s]231it [02:49, 18.57it/s]233it [02:49, 17.73it/s]235it [02:49, 16.85it/s]237it [02:49,  8.34it/s]239it [02:50,  6.22it/s]241it [02:50,  6.93it/s]243it [02:50,  7.82it/s]245it [02:50,  8.35it/s]247it [02:51,  8.89it/s]249it [02:51,  8.44it/s]251it [02:51,  8.14it/s]252it [02:51,  6.65it/s]254it [02:52,  7.93it/s]255it [02:52,  8.24it/s]256it [02:52,  7.35it/s]257it [02:52,  6.15it/s]258it [02:53,  4.35it/s]260it [02:53,  5.77it/s]262it [02:53,  7.52it/s]263it [02:53,  6.64it/s]264it [02:53,  5.94it/s]265it [02:54,  5.80it/s]266it [02:54,  4.11it/s]267it [02:55,  2.44it/s]268it [02:55,  2.82it/s]269it [02:55,  3.26it/s]270it [02:55,  3.59it/s]271it [02:56,  4.36it/s]272it [02:56,  3.96it/s]273it [02:56,  4.20it/s]274it [02:56,  4.46it/s]275it [02:56,  5.20it/s]276it [02:56,  5.91it/s]277it [02:57,  5.53it/s]278it [02:57,  6.17it/s]279it [02:57,  6.18it/s]280it [02:57,  4.97it/s]281it [02:57,  4.80it/s]282it [02:58,  3.61it/s]283it [02:58,  3.24it/s]284it [02:59,  3.42it/s]285it [02:59,  3.83it/s]286it [02:59,  4.15it/s]287it [02:59,  4.62it/s]288it [02:59,  4.28it/s]289it [03:00,  4.85it/s]290it [03:00,  5.66it/s]291it [03:00,  4.60it/s]292it [03:00,  4.05it/s]293it [03:00,  4.74it/s]295it [03:00,  7.31it/s]297it [03:01,  9.34it/s]299it [03:01, 11.41it/s]301it [03:01, 12.94it/s]303it [03:01, 14.02it/s]305it [03:01, 15.13it/s]307it [03:01, 15.57it/s]310it [03:01, 17.35it/s]312it [03:01, 16.42it/s]314it [03:02, 16.36it/s]316it [03:02, 16.91it/s]318it [03:02, 16.98it/s]320it [03:03,  6.57it/s]322it [03:03,  7.25it/s]324it [03:03,  8.54it/s]326it [03:03,  9.96it/s]328it [03:04,  5.95it/s]330it [03:05,  3.71it/s]331it [03:06,  2.42it/s]332it [03:07,  1.90it/s]333it [03:08,  1.63it/s]334it [03:08,  1.79it/s]335it [03:08,  2.01it/s]336it [03:09,  1.79it/s]337it [03:10,  1.61it/s]338it [03:11,  1.46it/s]339it [03:12,  1.13it/s]340it [03:13,  1.05it/s]341it [03:14,  1.11it/s]342it [03:15,  1.21it/s]343it [03:15,  1.27it/s]344it [03:16,  1.31it/s]345it [03:17,  1.33it/s]346it [03:18,  1.29it/s]347it [03:18,  1.30it/s]348it [03:19,  1.38it/s]349it [03:20,  1.44it/s]350it [03:20,  1.60it/s]351it [03:21,  1.58it/s]352it [03:22,  1.44it/s]353it [03:22,  1.51it/s]354it [03:23,  1.51it/s]355it [03:24,  1.46it/s]356it [03:24,  1.38it/s]357it [03:25,  1.31it/s]358it [03:26,  1.27it/s]359it [03:27,  1.27it/s]360it [03:28,  1.16it/s]360it [03:28,  1.73it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:06<03:18,  6.00s/it]  6%|▌         | 2/34 [00:06<01:23,  2.61s/it]  9%|▉         | 3/34 [00:06<00:51,  1.66s/it] 12%|█▏        | 4/34 [00:07<00:37,  1.23s/it] 15%|█▍        | 5/34 [00:07<00:25,  1.16it/s] 18%|█▊        | 6/34 [00:07<00:17,  1.56it/s] 21%|██        | 7/34 [00:07<00:13,  2.01it/s] 24%|██▎       | 8/34 [00:08<00:10,  2.47it/s] 26%|██▋       | 9/34 [00:08<00:08,  2.92it/s] 29%|██▉       | 10/34 [00:08<00:07,  3.34it/s] 32%|███▏      | 11/34 [00:08<00:06,  3.69it/s] 35%|███▌      | 12/34 [00:08<00:05,  3.98it/s] 38%|███▊      | 13/34 [00:09<00:04,  4.21it/s] 41%|████      | 14/34 [00:09<00:04,  4.39it/s] 44%|████▍     | 15/34 [00:09<00:04,  4.52it/s] 47%|████▋     | 16/34 [00:09<00:03,  4.62it/s] 50%|█████     | 17/34 [00:10<00:03,  4.69it/s] 53%|█████▎    | 18/34 [00:10<00:03,  4.74it/s] 56%|█████▌    | 19/34 [00:10<00:03,  4.78it/s] 59%|█████▉    | 20/34 [00:10<00:02,  4.81it/s] 62%|██████▏   | 21/34 [00:10<00:02,  4.83it/s] 65%|██████▍   | 22/34 [00:11<00:02,  4.85it/s] 68%|██████▊   | 23/34 [00:11<00:02,  4.85it/s] 71%|███████   | 24/34 [00:11<00:02,  4.86it/s] 74%|███████▎  | 25/34 [00:11<00:01,  4.86it/s] 76%|███████▋  | 26/34 [00:11<00:01,  4.87it/s] 79%|███████▉  | 27/34 [00:12<00:01,  4.87it/s] 82%|████████▏ | 28/34 [00:12<00:01,  4.88it/s] 85%|████████▌ | 29/34 [00:12<00:01,  4.88it/s] 88%|████████▊ | 30/34 [00:12<00:00,  4.88it/s] 91%|█████████ | 31/34 [00:12<00:00,  4.89it/s] 94%|█████████▍| 32/34 [00:13<00:00,  4.89it/s] 97%|█████████▋| 33/34 [00:13<00:00,  4.88it/s]100%|██████████| 34/34 [00:13<00:00,  5.70it/s]100%|██████████| 34/34 [00:13<00:00,  2.50it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:21,  4.29s/it]  6%|▌         | 2/34 [00:04<01:00,  1.89s/it]  9%|▉         | 3/34 [00:04<00:34,  1.12s/it] 12%|█▏        | 4/34 [00:04<00:22,  1.32it/s] 15%|█▍        | 5/34 [00:05<00:16,  1.79it/s] 18%|█▊        | 6/34 [00:05<00:12,  2.28it/s] 21%|██        | 7/34 [00:05<00:09,  2.75it/s] 24%|██▎       | 8/34 [00:05<00:08,  3.19it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.58it/s] 29%|██▉       | 10/34 [00:06<00:06,  3.90it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.15it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.34it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.49it/s] 41%|████      | 14/34 [00:06<00:04,  4.60it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.68it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.73it/s] 50%|█████     | 17/34 [00:07<00:03,  4.77it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.80it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.83it/s] 59%|█████▉    | 20/34 [00:08<00:02,  4.84it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.86it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.87it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.87it/s] 71%|███████   | 24/34 [00:09<00:02,  4.88it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.88it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.88it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.89it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.89it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.71it/s]100%|██████████| 34/34 [00:11<00:00,  3.04it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6489464044570923


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.36829836829837
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.54983304683037
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.03470309860581


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 64.89463806152344
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.55s/it]2it [00:03,  1.49s/it]3it [00:04,  1.51s/it]4it [00:05,  1.45s/it]5it [00:07,  1.50s/it]6it [00:08,  1.42s/it]7it [00:10,  1.42s/it]8it [00:11,  1.42s/it]9it [00:12,  1.40s/it]10it [00:14,  1.36s/it]11it [00:15,  1.42s/it]12it [00:17,  1.41s/it]13it [00:18,  1.32s/it]14it [00:19,  1.17s/it]15it [00:20,  1.11s/it]16it [00:20,  1.03s/it]17it [00:21,  1.02s/it]18it [00:22,  1.01it/s]19it [00:24,  1.07s/it]20it [00:25,  1.10s/it]21it [00:26,  1.00s/it]22it [00:26,  1.01it/s]23it [00:27,  1.04it/s]24it [00:28,  1.08it/s]25it [00:29,  1.07it/s]26it [00:30,  1.04s/it]27it [00:32,  1.09s/it]28it [00:33,  1.04s/it]29it [00:34,  1.01s/it]30it [00:34,  1.00it/s]31it [00:35,  1.02it/s]32it [00:36,  1.03it/s]33it [00:37,  1.07it/s]34it [00:38,  1.10it/s]35it [00:39,  1.11it/s]36it [00:39,  1.28it/s]37it [00:40,  1.67it/s]38it [00:40,  2.06it/s]39it [00:40,  2.41it/s]40it [00:40,  2.78it/s]41it [00:40,  3.38it/s]43it [00:41,  4.57it/s]44it [00:41,  5.13it/s]45it [00:41,  5.82it/s]46it [00:41,  5.92it/s]47it [00:41,  5.73it/s]48it [00:42,  5.81it/s]50it [00:42,  6.95it/s]51it [00:42,  7.03it/s]52it [00:42,  7.13it/s]53it [00:42,  6.89it/s]54it [00:42,  7.52it/s]55it [00:42,  6.57it/s]56it [00:43,  6.13it/s]57it [00:43,  4.81it/s]58it [00:43,  5.25it/s]59it [00:43,  5.33it/s]60it [00:43,  5.33it/s]61it [00:44,  5.27it/s]62it [00:44,  5.24it/s]63it [00:45,  2.66it/s]64it [00:45,  2.31it/s]65it [00:45,  2.84it/s]67it [00:46,  4.45it/s]68it [00:46,  5.11it/s]70it [00:46,  6.70it/s]72it [00:46,  7.77it/s]73it [00:46,  7.85it/s]74it [00:46,  7.23it/s]76it [00:47,  7.30it/s]77it [00:47,  6.88it/s]78it [00:47,  6.86it/s]79it [00:47,  7.26it/s]80it [00:47,  7.34it/s]81it [00:47,  7.57it/s]82it [00:47,  6.95it/s]83it [00:48,  6.94it/s]84it [00:48,  6.53it/s]85it [00:48,  5.84it/s]86it [00:48,  5.23it/s]87it [00:48,  5.05it/s]88it [00:49,  5.53it/s]89it [00:49,  5.14it/s]90it [00:49,  5.56it/s]92it [00:49,  6.91it/s]94it [00:49,  7.50it/s]95it [00:50,  7.42it/s]96it [00:50,  3.06it/s]97it [00:51,  2.83it/s]98it [00:51,  3.08it/s]99it [00:51,  3.59it/s]100it [00:51,  4.29it/s]102it [00:52,  5.47it/s]104it [00:52,  6.06it/s]105it [00:52,  5.89it/s]106it [00:52,  5.40it/s]107it [00:53,  5.45it/s]108it [00:53,  5.70it/s]109it [00:53,  5.41it/s]110it [00:53,  5.36it/s]112it [00:53,  7.01it/s]113it [00:53,  6.97it/s]114it [00:54,  6.50it/s]116it [00:54,  8.79it/s]118it [00:54, 10.92it/s]120it [00:54, 12.75it/s]122it [00:54, 13.91it/s]124it [00:54, 14.54it/s]126it [00:54, 15.59it/s]128it [00:54, 15.19it/s]130it [00:55, 15.86it/s]132it [00:55, 16.83it/s]134it [00:55, 16.45it/s]137it [00:55, 17.49it/s]139it [00:55, 16.85it/s]141it [00:55, 16.78it/s]143it [00:55, 17.28it/s]145it [00:55, 16.98it/s]147it [00:56, 16.94it/s]149it [00:56, 16.85it/s]151it [00:56, 16.49it/s]153it [00:56, 14.85it/s]155it [00:56, 14.28it/s]157it [00:56, 14.97it/s]159it [00:56, 15.60it/s]161it [00:56, 16.06it/s]163it [00:57, 16.59it/s]165it [00:57, 15.40it/s]167it [00:57, 13.89it/s]169it [00:57, 14.09it/s]171it [00:57, 14.41it/s]174it [00:57, 16.57it/s]176it [00:57, 16.67it/s]179it [00:58, 17.52it/s]181it [00:58, 16.89it/s]183it [00:58, 17.58it/s]185it [00:58, 17.04it/s]188it [00:58, 17.83it/s]190it [00:58, 11.71it/s]192it [00:59, 13.16it/s]194it [00:59, 13.85it/s]196it [00:59, 15.07it/s]199it [00:59, 16.46it/s]201it [00:59, 16.68it/s]203it [00:59, 11.18it/s]205it [00:59, 12.40it/s]207it [01:00, 13.19it/s]209it [01:00, 14.24it/s]212it [01:00, 16.07it/s]214it [01:00, 16.34it/s]216it [01:00, 11.92it/s]218it [01:01,  9.94it/s]220it [01:01,  7.71it/s]221it [01:01,  8.02it/s]222it [01:01,  6.18it/s]223it [01:02,  3.40it/s]224it [01:02,  3.84it/s]225it [01:02,  4.38it/s]226it [01:03,  4.20it/s]227it [01:03,  4.73it/s]228it [01:03,  4.84it/s]229it [01:03,  4.67it/s]230it [01:04,  4.14it/s]231it [01:04,  4.93it/s]232it [01:04,  4.80it/s]233it [01:04,  4.50it/s]234it [01:04,  4.26it/s]235it [01:05,  3.89it/s]236it [01:05,  3.91it/s]237it [01:05,  4.16it/s]238it [01:05,  3.77it/s]239it [01:06,  3.61it/s]240it [01:06,  3.85it/s]241it [01:06,  4.56it/s]243it [01:06,  6.75it/s]245it [01:06,  8.57it/s]247it [01:07,  9.81it/s]249it [01:07,  9.39it/s]251it [01:07, 11.06it/s]253it [01:07, 12.16it/s]255it [01:07, 13.43it/s]257it [01:07, 13.97it/s]259it [01:07, 15.03it/s]262it [01:08, 16.46it/s]264it [01:08, 17.04it/s]266it [01:08, 17.76it/s]268it [01:08, 16.38it/s]271it [01:08, 17.77it/s]273it [01:08, 17.82it/s]275it [01:08, 17.87it/s]277it [01:08, 17.50it/s]279it [01:09, 13.99it/s]281it [01:09, 13.42it/s]283it [01:09, 14.05it/s]285it [01:09, 13.88it/s]287it [01:09, 13.76it/s]289it [01:09, 13.76it/s]291it [01:09, 13.43it/s]293it [01:10,  8.79it/s]295it [01:10, 10.19it/s]297it [01:10, 10.85it/s]299it [01:10, 12.31it/s]301it [01:10, 13.02it/s]303it [01:11, 13.05it/s]305it [01:11, 13.20it/s]307it [01:11, 13.07it/s]309it [01:11, 14.48it/s]311it [01:11, 13.41it/s]313it [01:11, 13.13it/s]315it [01:11, 13.06it/s]317it [01:12, 13.87it/s]319it [01:12, 13.99it/s]321it [01:12, 14.52it/s]323it [01:12, 14.85it/s]325it [01:12, 16.02it/s]327it [01:12, 14.54it/s]329it [01:12, 14.70it/s]331it [01:13, 15.44it/s]333it [01:13, 15.88it/s]335it [01:13, 16.42it/s]337it [01:13, 16.93it/s]339it [01:13, 10.19it/s]341it [01:13, 11.46it/s]343it [01:14, 11.83it/s]345it [01:14, 11.37it/s]347it [01:14, 11.05it/s]349it [01:14, 11.50it/s]351it [01:14, 12.05it/s]353it [01:14, 12.26it/s]355it [01:14, 12.96it/s]357it [01:15, 12.76it/s]359it [01:15, 12.67it/s]360it [01:15,  4.78it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:11,  3.99s/it]  6%|▌         | 2/34 [00:04<00:56,  1.76s/it]  9%|▉         | 3/34 [00:04<00:32,  1.05s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.40it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.88it/s] 18%|█▊        | 6/34 [00:05<00:11,  2.38it/s] 21%|██        | 7/34 [00:05<00:09,  2.86it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.29it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.66it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.97it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.21it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.39it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.53it/s] 41%|████      | 14/34 [00:06<00:04,  4.63it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.70it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.75it/s] 50%|█████     | 17/34 [00:07<00:03,  4.79it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.82it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.84it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.85it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.88it/s] 71%|███████   | 24/34 [00:08<00:02,  4.88it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.88it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.88it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.88it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.88it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.88it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.88it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.88it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.88it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.87it/s]100%|██████████| 34/34 [00:10<00:00,  5.68it/s]100%|██████████| 34/34 [00:10<00:00,  3.13it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967396736145
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:28,  4.51s/it]  6%|▌         | 2/34 [00:04<01:03,  1.98s/it]  9%|▉         | 3/34 [00:04<00:36,  1.17s/it] 12%|█▏        | 4/34 [00:05<00:23,  1.27it/s] 15%|█▍        | 5/34 [00:05<00:16,  1.73it/s] 18%|█▊        | 6/34 [00:05<00:12,  2.21it/s] 21%|██        | 7/34 [00:05<00:10,  2.70it/s] 24%|██▎       | 8/34 [00:05<00:08,  3.14it/s] 26%|██▋       | 9/34 [00:06<00:07,  3.53it/s] 29%|██▉       | 10/34 [00:06<00:06,  3.85it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.11it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.31it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.46it/s] 41%|████      | 14/34 [00:07<00:04,  4.57it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.66it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.70it/s] 50%|█████     | 17/34 [00:07<00:03,  4.74it/s] 53%|█████▎    | 18/34 [00:08<00:03,  4.79it/s] 56%|█████▌    | 19/34 [00:08<00:03,  4.82it/s] 59%|█████▉    | 20/34 [00:08<00:02,  4.84it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.85it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.86it/s] 68%|██████▊   | 23/34 [00:09<00:02,  4.87it/s] 71%|███████   | 24/34 [00:09<00:02,  4.88it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.89it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.89it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:10<00:01,  4.90it/s] 85%|████████▌ | 29/34 [00:10<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.91it/s] 97%|█████████▋| 33/34 [00:11<00:00,  4.90it/s]100%|██████████| 34/34 [00:11<00:00,  5.72it/s]100%|██████████| 34/34 [00:11<00:00,  2.98it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6554720401763916


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36967468261719
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 48.75291375291375
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.71708875991744
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.807718021784254


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.54720306396484
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  5.91it/s]2it [00:00,  5.89it/s]3it [00:00,  5.60it/s]4it [00:00,  4.90it/s]5it [00:01,  3.20it/s]6it [00:01,  4.12it/s]7it [00:01,  4.62it/s]8it [00:01,  4.13it/s]9it [00:02,  3.26it/s]10it [00:02,  2.43it/s]11it [00:03,  3.00it/s]12it [00:03,  3.32it/s]13it [00:03,  3.61it/s]14it [00:03,  4.23it/s]15it [00:03,  4.40it/s]16it [00:04,  4.62it/s]17it [00:04,  4.75it/s]18it [00:04,  5.22it/s]19it [00:04,  5.20it/s]20it [00:04,  5.45it/s]21it [00:04,  5.95it/s]22it [00:05,  6.02it/s]23it [00:05,  6.37it/s]24it [00:05,  5.44it/s]25it [00:05,  5.37it/s]26it [00:05,  5.93it/s]27it [00:05,  5.46it/s]28it [00:06,  5.50it/s]29it [00:06,  4.33it/s]30it [00:06,  4.61it/s]31it [00:07,  4.08it/s]32it [00:07,  4.33it/s]33it [00:08,  2.47it/s]34it [00:08,  2.44it/s]35it [00:08,  3.08it/s]36it [00:08,  3.42it/s]37it [00:08,  4.16it/s]38it [00:09,  4.93it/s]39it [00:09,  5.50it/s]41it [00:09,  5.40it/s]42it [00:09,  5.27it/s]43it [00:09,  5.57it/s]44it [00:10,  5.87it/s]45it [00:10,  6.42it/s]46it [00:10,  6.64it/s]47it [00:10,  6.02it/s]48it [00:10,  6.06it/s]49it [00:10,  6.08it/s]51it [00:11,  6.36it/s]52it [00:11,  6.65it/s]53it [00:11,  6.57it/s]54it [00:11,  6.51it/s]55it [00:11,  6.80it/s]56it [00:11,  6.47it/s]57it [00:12,  6.67it/s]58it [00:12,  6.23it/s]60it [00:12,  6.94it/s]61it [00:12,  7.03it/s]62it [00:12,  6.63it/s]63it [00:12,  6.98it/s]64it [00:13,  6.25it/s]65it [00:13,  5.88it/s]66it [00:13,  5.96it/s]67it [00:13,  6.26it/s]68it [00:13,  6.33it/s]69it [00:13,  6.14it/s]70it [00:14,  5.99it/s]71it [00:14,  5.20it/s]72it [00:14,  5.31it/s]73it [00:14,  6.00it/s]75it [00:14,  7.74it/s]77it [00:14,  8.48it/s]79it [00:15,  7.91it/s]80it [00:15,  6.11it/s]81it [00:15,  6.32it/s]82it [00:15,  6.85it/s]83it [00:15,  7.26it/s]84it [00:16,  7.28it/s]85it [00:16,  6.76it/s]86it [00:16,  5.81it/s]87it [00:16,  5.86it/s]88it [00:16,  5.98it/s]89it [00:16,  5.90it/s]90it [00:17,  5.58it/s]91it [00:17,  6.07it/s]93it [00:17,  7.14it/s]94it [00:17,  6.79it/s]95it [00:17,  7.30it/s]97it [00:17,  9.04it/s]99it [00:18,  9.25it/s]100it [00:18,  7.90it/s]101it [00:18,  6.83it/s]102it [00:18,  6.79it/s]103it [00:18,  5.76it/s]104it [00:19,  6.09it/s]105it [00:19,  6.51it/s]106it [00:19,  7.09it/s]108it [00:19,  7.51it/s]109it [00:19,  5.90it/s]111it [00:20,  7.12it/s]112it [00:20,  6.53it/s]113it [00:20,  6.58it/s]114it [00:20,  6.62it/s]115it [00:20,  7.02it/s]116it [00:20,  6.61it/s]117it [00:21,  6.38it/s]118it [00:21,  6.49it/s]119it [00:21,  6.44it/s]120it [00:21,  6.35it/s]122it [00:21,  8.38it/s]124it [00:21, 10.79it/s]127it [00:21, 13.07it/s]129it [00:22, 13.85it/s]131it [00:22, 14.44it/s]133it [00:22, 15.57it/s]135it [00:22, 16.18it/s]138it [00:22, 17.63it/s]140it [00:22, 17.05it/s]142it [00:22, 17.50it/s]144it [00:22, 17.16it/s]146it [00:23, 17.28it/s]148it [00:23, 16.86it/s]150it [00:23, 16.74it/s]152it [00:23, 16.69it/s]154it [00:23, 16.38it/s]156it [00:23, 16.04it/s]158it [00:23, 16.82it/s]160it [00:23, 17.05it/s]162it [00:23, 16.91it/s]164it [00:24, 16.86it/s]166it [00:24, 16.56it/s]168it [00:24, 13.43it/s]170it [00:24, 12.35it/s]173it [00:24, 14.75it/s]175it [00:24, 14.61it/s]177it [00:25, 15.05it/s]179it [00:25, 15.64it/s]182it [00:25, 17.07it/s]184it [00:25, 16.35it/s]186it [00:25, 16.91it/s]188it [00:25, 15.39it/s]190it [00:26, 10.24it/s]192it [00:26, 11.08it/s]194it [00:26, 11.58it/s]196it [00:26, 11.76it/s]198it [00:26, 12.65it/s]200it [00:26, 12.90it/s]202it [00:26, 13.28it/s]204it [00:27, 13.73it/s]206it [00:27, 14.34it/s]208it [00:27, 15.31it/s]210it [00:27, 16.13it/s]213it [00:27, 17.47it/s]215it [00:27, 17.78it/s]217it [00:27, 17.98it/s]219it [00:27, 18.44it/s]221it [00:28, 18.43it/s]224it [00:28, 18.97it/s]226it [00:28, 18.26it/s]229it [00:28, 18.77it/s]231it [00:28, 18.78it/s]233it [00:28, 18.18it/s]235it [00:28, 17.88it/s]237it [00:28, 15.43it/s]239it [00:29, 15.82it/s]241it [00:29, 15.28it/s]243it [00:29, 15.42it/s]245it [00:29, 14.98it/s]247it [00:29, 14.59it/s]249it [00:29, 10.94it/s]251it [00:30, 11.59it/s]253it [00:30, 12.13it/s]255it [00:30, 12.81it/s]257it [00:30, 12.75it/s]259it [00:30, 13.58it/s]261it [00:30, 14.26it/s]263it [00:30, 14.07it/s]265it [00:31, 14.41it/s]267it [00:31, 13.87it/s]269it [00:31, 13.80it/s]271it [00:31, 13.83it/s]273it [00:31, 14.12it/s]275it [00:31, 14.20it/s]277it [00:31, 14.26it/s]279it [00:32, 13.94it/s]281it [00:32, 13.77it/s]283it [00:32, 14.58it/s]285it [00:32, 14.60it/s]287it [00:32, 14.22it/s]289it [00:32, 13.83it/s]291it [00:32, 13.62it/s]293it [00:33, 14.36it/s]295it [00:33, 15.28it/s]297it [00:33, 14.84it/s]300it [00:33, 15.73it/s]302it [00:33, 15.25it/s]304it [00:33, 14.69it/s]306it [00:33, 14.79it/s]308it [00:33, 15.69it/s]310it [00:34, 15.13it/s]312it [00:34, 14.17it/s]314it [00:34, 13.59it/s]316it [00:34, 14.03it/s]318it [00:34, 14.34it/s]320it [00:34, 14.16it/s]322it [00:34, 14.83it/s]324it [00:35, 14.37it/s]326it [00:35, 15.01it/s]328it [00:35, 13.99it/s]330it [00:35, 14.14it/s]332it [00:35, 14.22it/s]334it [00:35, 14.49it/s]336it [00:35, 14.54it/s]338it [00:36, 14.39it/s]340it [00:36, 11.79it/s]342it [00:36, 12.29it/s]344it [00:36, 13.12it/s]346it [00:36, 13.19it/s]348it [00:36, 13.75it/s]350it [00:37, 14.78it/s]352it [00:37, 15.54it/s]354it [00:37, 16.15it/s]356it [00:37, 16.44it/s]358it [00:37, 15.85it/s]360it [00:37, 12.64it/s]360it [00:37,  9.54it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:08,  3.90s/it]  6%|▌         | 2/34 [00:04<00:55,  1.73s/it]  9%|▉         | 3/34 [00:04<00:31,  1.03s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.42it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.91it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.40it/s] 21%|██        | 7/34 [00:05<00:09,  2.88it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.32it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.69it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.99it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.23it/s] 35%|███▌      | 12/34 [00:06<00:04,  4.42it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.56it/s] 41%|████      | 14/34 [00:06<00:04,  4.66it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.73it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.79it/s] 50%|█████     | 17/34 [00:07<00:03,  4.82it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.86it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.90it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.90it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.91it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.91it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.91it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.91it/s]100%|██████████| 34/34 [00:10<00:00,  5.73it/s]100%|██████████| 34/34 [00:10<00:00,  3.18it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536966800689697
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:02,  3.72s/it]  6%|▌         | 2/34 [00:03<00:52,  1.65s/it]  9%|▉         | 3/34 [00:04<00:30,  1.01it/s] 12%|█▏        | 4/34 [00:04<00:20,  1.47it/s] 15%|█▍        | 5/34 [00:04<00:14,  1.96it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.47it/s] 21%|██        | 7/34 [00:04<00:09,  2.94it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.37it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.74it/s] 29%|██▉       | 10/34 [00:05<00:05,  4.03it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.26it/s] 35%|███▌      | 12/34 [00:05<00:04,  4.43it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.57it/s] 41%|████      | 14/34 [00:06<00:04,  4.66it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.73it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.78it/s] 50%|█████     | 17/34 [00:06<00:03,  4.81it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.85it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.86it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.87it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.89it/s] 71%|███████   | 24/34 [00:08<00:02,  4.89it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.90it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.90it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.90it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.90it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.71it/s]100%|██████████| 34/34 [00:10<00:00,  3.22it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6515458822250366


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36966705322266
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 47.96037296037296
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.31493059231421
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 34.679521112879925


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.15458679199219
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  5.83it/s]2it [00:00,  6.54it/s]3it [00:00,  6.31it/s]4it [00:00,  5.72it/s]5it [00:01,  4.21it/s]7it [00:01,  5.70it/s]8it [00:01,  6.18it/s]9it [00:01,  6.57it/s]10it [00:01,  6.14it/s]11it [00:01,  6.26it/s]12it [00:02,  5.21it/s]14it [00:02,  6.26it/s]15it [00:02,  6.01it/s]17it [00:02,  7.10it/s]18it [00:02,  7.50it/s]19it [00:03,  7.23it/s]20it [00:03,  6.81it/s]21it [00:03,  6.14it/s]23it [00:03,  6.86it/s]24it [00:03,  7.14it/s]25it [00:03,  6.54it/s]26it [00:04,  5.93it/s]27it [00:04,  5.15it/s]28it [00:04,  5.83it/s]29it [00:04,  5.19it/s]30it [00:04,  5.44it/s]31it [00:05,  6.07it/s]32it [00:05,  6.29it/s]33it [00:05,  6.96it/s]34it [00:05,  7.44it/s]35it [00:05,  7.21it/s]36it [00:05,  7.22it/s]37it [00:05,  6.56it/s]38it [00:06,  6.83it/s]39it [00:06,  6.68it/s]40it [00:06,  6.49it/s]41it [00:06,  6.26it/s]42it [00:06,  6.13it/s]43it [00:06,  6.43it/s]44it [00:07,  5.36it/s]45it [00:07,  5.67it/s]47it [00:07,  6.35it/s]48it [00:07,  6.91it/s]49it [00:07,  6.93it/s]51it [00:08,  7.37it/s]52it [00:08,  6.73it/s]53it [00:08,  6.03it/s]54it [00:08,  6.16it/s]55it [00:08,  6.40it/s]56it [00:08,  6.40it/s]58it [00:09,  5.75it/s]59it [00:09,  5.82it/s]60it [00:09,  6.09it/s]61it [00:09,  5.79it/s]62it [00:09,  6.11it/s]63it [00:10,  5.49it/s]64it [00:10,  5.20it/s]65it [00:10,  5.05it/s]67it [00:10,  6.26it/s]68it [00:10,  6.88it/s]69it [00:11,  6.54it/s]71it [00:11,  7.49it/s]72it [00:11,  6.84it/s]73it [00:11,  6.54it/s]74it [00:11,  6.77it/s]75it [00:11,  6.81it/s]76it [00:12,  6.50it/s]77it [00:12,  7.20it/s]78it [00:12,  6.02it/s]79it [00:12,  6.59it/s]80it [00:12,  5.97it/s]82it [00:13,  5.48it/s]83it [00:13,  5.19it/s]84it [00:13,  5.58it/s]85it [00:13,  5.68it/s]86it [00:13,  6.30it/s]87it [00:13,  5.92it/s]88it [00:14,  6.61it/s]89it [00:14,  6.28it/s]90it [00:14,  6.55it/s]91it [00:14,  7.24it/s]92it [00:14,  7.57it/s]93it [00:14,  8.06it/s]95it [00:14,  8.84it/s]97it [00:15,  8.48it/s]98it [00:15,  7.42it/s]99it [00:15,  5.82it/s]100it [00:15,  5.52it/s]101it [00:16,  5.40it/s]102it [00:16,  5.09it/s]103it [00:16,  5.41it/s]104it [00:16,  4.85it/s]105it [00:16,  5.28it/s]106it [00:17,  5.39it/s]107it [00:17,  6.18it/s]108it [00:17,  6.10it/s]109it [00:17,  5.46it/s]110it [00:17,  5.91it/s]111it [00:17,  6.45it/s]114it [00:17, 10.90it/s]116it [00:18, 12.56it/s]118it [00:18, 13.55it/s]120it [00:18, 14.84it/s]122it [00:18, 15.56it/s]124it [00:18, 15.62it/s]126it [00:18, 16.48it/s]128it [00:18, 16.83it/s]130it [00:18, 17.39it/s]132it [00:18, 17.99it/s]134it [00:19, 18.05it/s]136it [00:19, 18.17it/s]138it [00:19, 16.53it/s]140it [00:19, 16.57it/s]142it [00:19, 16.88it/s]144it [00:19, 17.02it/s]146it [00:19, 16.70it/s]148it [00:19, 16.66it/s]150it [00:20, 16.27it/s]152it [00:20, 16.23it/s]154it [00:20, 16.10it/s]156it [00:20, 16.02it/s]158it [00:20, 15.96it/s]160it [00:20, 16.36it/s]162it [00:20, 16.33it/s]164it [00:20, 16.00it/s]166it [00:21, 15.08it/s]168it [00:21, 14.47it/s]170it [00:21, 15.00it/s]172it [00:21, 15.47it/s]174it [00:21, 16.13it/s]176it [00:21, 15.72it/s]178it [00:21, 16.65it/s]180it [00:21, 16.88it/s]182it [00:22, 16.83it/s]184it [00:22, 17.24it/s]186it [00:22, 17.86it/s]188it [00:22, 17.50it/s]190it [00:22, 10.76it/s]192it [00:22, 12.43it/s]194it [00:22, 13.66it/s]196it [00:23, 14.28it/s]198it [00:23, 15.57it/s]200it [00:23, 16.11it/s]202it [00:23, 15.81it/s]204it [00:23, 16.53it/s]206it [00:23, 17.03it/s]208it [00:23, 16.72it/s]210it [00:23, 17.32it/s]212it [00:23, 17.72it/s]214it [00:24, 17.22it/s]216it [00:24, 16.83it/s]218it [00:24, 15.89it/s]220it [00:24, 16.60it/s]222it [00:24, 16.09it/s]225it [00:24, 17.20it/s]228it [00:24, 18.65it/s]230it [00:25, 13.86it/s]232it [00:25, 14.39it/s]234it [00:25, 14.11it/s]236it [00:25, 14.03it/s]238it [00:25, 14.14it/s]240it [00:25, 13.60it/s]242it [00:26, 13.38it/s]244it [00:26, 13.10it/s]246it [00:26, 12.98it/s]248it [00:26, 13.15it/s]250it [00:26, 10.64it/s]252it [00:26, 11.51it/s]254it [00:27, 11.94it/s]256it [00:27, 11.75it/s]258it [00:27, 12.22it/s]260it [00:27, 13.76it/s]262it [00:27, 14.24it/s]264it [00:27, 14.37it/s]266it [00:27, 14.69it/s]268it [00:28, 14.08it/s]271it [00:28, 15.83it/s]273it [00:28, 15.92it/s]275it [00:28, 16.00it/s]277it [00:28, 15.88it/s]279it [00:28, 15.43it/s]281it [00:28, 14.97it/s]283it [00:28, 14.98it/s]285it [00:29, 14.38it/s]287it [00:29, 14.23it/s]289it [00:29, 13.80it/s]291it [00:29, 14.48it/s]293it [00:29, 15.20it/s]295it [00:29, 15.80it/s]297it [00:29, 16.32it/s]300it [00:30, 17.23it/s]302it [00:30, 16.91it/s]304it [00:30, 16.61it/s]306it [00:30, 16.33it/s]309it [00:30, 17.78it/s]311it [00:30, 16.42it/s]313it [00:30, 16.48it/s]315it [00:30, 16.05it/s]318it [00:31, 17.13it/s]320it [00:31, 16.59it/s]322it [00:31, 17.03it/s]324it [00:31, 16.63it/s]326it [00:31, 17.09it/s]328it [00:31, 16.42it/s]330it [00:31, 16.44it/s]332it [00:31, 16.16it/s]334it [00:32, 17.06it/s]336it [00:32, 17.35it/s]338it [00:32, 16.41it/s]340it [00:32, 13.17it/s]342it [00:32, 14.47it/s]344it [00:32, 15.71it/s]346it [00:32, 15.44it/s]348it [00:33, 16.12it/s]350it [00:33, 16.06it/s]352it [00:33, 16.52it/s]354it [00:33, 16.88it/s]356it [00:33, 16.86it/s]358it [00:33, 13.95it/s]360it [00:33, 14.13it/s]360it [00:33, 10.64it/s]
Number of selected candidates = 130
---> Each Classifier' shapes
	 GT_classifier = 120
	 ViLang_guessed = 130
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:03<02:07,  3.86s/it]  6%|▌         | 2/34 [00:04<00:54,  1.71s/it]  9%|▉         | 3/34 [00:04<00:31,  1.02s/it] 12%|█▏        | 4/34 [00:04<00:21,  1.43it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.92it/s] 18%|█▊        | 6/34 [00:04<00:11,  2.42it/s] 21%|██        | 7/34 [00:05<00:09,  2.90it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.33it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.71it/s] 29%|██▉       | 10/34 [00:05<00:05,  4.01it/s] 32%|███▏      | 11/34 [00:05<00:05,  4.25it/s] 35%|███▌      | 12/34 [00:06<00:04,  4.42it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.56it/s] 41%|████      | 14/34 [00:06<00:04,  4.65it/s] 44%|████▍     | 15/34 [00:06<00:04,  4.73it/s] 47%|████▋     | 16/34 [00:06<00:03,  4.78it/s] 50%|█████     | 17/34 [00:07<00:03,  4.82it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.85it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.87it/s] 59%|█████▉    | 20/34 [00:07<00:02,  4.88it/s] 62%|██████▏   | 21/34 [00:07<00:02,  4.88it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.89it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.90it/s] 71%|███████   | 24/34 [00:08<00:02,  4.90it/s] 74%|███████▎  | 25/34 [00:08<00:01,  4.90it/s] 76%|███████▋  | 26/34 [00:08<00:01,  4.90it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.90it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.91it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.91it/s] 88%|████████▊ | 30/34 [00:09<00:00,  4.91it/s] 91%|█████████ | 31/34 [00:09<00:00,  4.91it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.91it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.90it/s]100%|██████████| 34/34 [00:10<00:00,  5.72it/s]100%|██████████| 34/34 [00:10<00:00,  3.17it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.7536967992782593
---> Evaluating
  0%|          | 0/34 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  3%|▎         | 1/34 [00:04<02:16,  4.15s/it]  6%|▌         | 2/34 [00:04<00:58,  1.83s/it]  9%|▉         | 3/34 [00:04<00:33,  1.09s/it] 12%|█▏        | 4/34 [00:04<00:22,  1.36it/s] 15%|█▍        | 5/34 [00:04<00:15,  1.83it/s] 18%|█▊        | 6/34 [00:05<00:12,  2.33it/s] 21%|██        | 7/34 [00:05<00:09,  2.81it/s] 24%|██▎       | 8/34 [00:05<00:07,  3.25it/s] 26%|██▋       | 9/34 [00:05<00:06,  3.63it/s] 29%|██▉       | 10/34 [00:05<00:06,  3.95it/s] 32%|███▏      | 11/34 [00:06<00:05,  4.20it/s] 35%|███▌      | 12/34 [00:06<00:05,  4.39it/s] 38%|███▊      | 13/34 [00:06<00:04,  4.53it/s] 41%|████      | 14/34 [00:06<00:04,  4.64it/s] 44%|████▍     | 15/34 [00:07<00:04,  4.71it/s] 47%|████▋     | 16/34 [00:07<00:03,  4.77it/s] 50%|█████     | 17/34 [00:07<00:03,  4.81it/s] 53%|█████▎    | 18/34 [00:07<00:03,  4.84it/s] 56%|█████▌    | 19/34 [00:07<00:03,  4.86it/s] 59%|█████▉    | 20/34 [00:08<00:02,  4.87it/s] 62%|██████▏   | 21/34 [00:08<00:02,  4.88it/s] 65%|██████▍   | 22/34 [00:08<00:02,  4.88it/s] 68%|██████▊   | 23/34 [00:08<00:02,  4.88it/s] 71%|███████   | 24/34 [00:08<00:02,  4.88it/s] 74%|███████▎  | 25/34 [00:09<00:01,  4.88it/s] 76%|███████▋  | 26/34 [00:09<00:01,  4.88it/s] 79%|███████▉  | 27/34 [00:09<00:01,  4.88it/s] 82%|████████▏ | 28/34 [00:09<00:01,  4.89it/s] 85%|████████▌ | 29/34 [00:09<00:01,  4.89it/s] 88%|████████▊ | 30/34 [00:10<00:00,  4.89it/s] 91%|█████████ | 31/34 [00:10<00:00,  4.89it/s] 94%|█████████▍| 32/34 [00:10<00:00,  4.89it/s] 97%|█████████▋| 33/34 [00:10<00:00,  4.89it/s]100%|██████████| 34/34 [00:10<00:00,  5.70it/s]100%|██████████| 34/34 [00:10<00:00,  3.09it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([8580, 768])
gt_feats.shape torch.Size([8580, 768])
Semantic similarity score = 0.6551517248153687


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 56.841491841491845
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 72.58855407797449
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 41.80943733544862


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 75.36968231201172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 49.05594405594405
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 69.754443167353
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 35.49829870231334


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 65.51517486572266
=========================          END          =========================


========================= ViLang Final Results of 10 runs, w/ 3 imgs per class=========================


[Clustering]
Clustering ACC: 48.47086247086247
Semantic ACC:   65.22844696044922
=========================          END          =========================
