Namespace(mode='describe', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', num_per_category='3')
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'pet', 'num_classes': 37, 'num_base': 19, 'num_novel': 18, 'seed': 1, 'batch_size': 32, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'FlanT5-XXL', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'chaos', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/pet_37', 'expt_dir': './experiments/pet37', 'expt_dir_describe': './experiments/pet37/describe', 'path_vqa_questions': './experiments/pet37/describe/pet_vqa_questions', 'path_vqa_answers': './experiments/pet37/describe/pet_attributes_pairs', 'path_llm_prompts': './experiments/pet37/describe/pet_llm_prompts', 'expt_dir_guess': './experiments/pet37/guess', 'path_llm_replies_raw': './experiments/pet37/guess/pet_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/pet37/guess/pet_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/pet37/guess/pet_llm_gussed_names', 'expt_dir_grouping': './experiments/pet37/grouping'}
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/hdl/project/FineR/FineR_fullpipe/discovering.py:361 in <module>        │
│                                                                              │
│   358 │   │   """                                                            │
│   359 │   │   # build VQA Bot                                                │
│   360 │   │   if cfg['host'] in ["chaos", "YOUR_GPU_CLUSTER_NAME"]:          │
│ ❱ 361 │   │   │   vqa_bot = VQABot(model_tag=cfg['model_size_vqa'], device=' │
│   362 │   │   else:                                                          │
│   363 │   │   │   vqa_bot = VQABot(model_tag=cfg['model_size_vqa'], device=' │
│   364                                                                        │
│                                                                              │
│ /home/hdl/project/FineR/FineR_fullpipe/agents/vqa_bot.py:57 in __init__      │
│                                                                              │
│    54 │   │   # use local path load the model                                │
│    55 │   │   local_model_path = '/home/hdl/model/blip2-flan-t5-xxl'         │
│    56 │   │   # add "use_fast=False",ban fast tokenizer                      │
│ ❱  57 │   │   self.blip2_processor = Blip2Processor.from_pretrained(local_mo │
│    58 │   │   if device == 'cpu':                                            │
│    59 │   │   │   self.device = 'cpu'                                        │
│    60 │   │   │   self.blip2 = Blip2ForConditionalGeneration.from_pretrained │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/pro │
│ cessing_utils.py:184 in from_pretrained                                      │
│                                                                              │
│   181 │   │   │   │   [`~feature_extraction_utils.FeatureExtractionMixin.fro │
│   182 │   │   │   │   [`~tokenization_utils_base.PreTrainedTokenizer.from_pr │
│   183 │   │   """                                                            │
│ ❱ 184 │   │   args = cls._get_arguments_from_pretrained(pretrained_model_nam │
│   185 │   │   return cls(*args)                                              │
│   186 │                                                                      │
│   187 │   @classmethod                                                       │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/pro │
│ cessing_utils.py:228 in _get_arguments_from_pretrained                       │
│                                                                              │
│   225 │   │   │   else:                                                      │
│   226 │   │   │   │   attribute_class = getattr(transformers_module, class_n │
│   227 │   │   │                                                              │
│ ❱ 228 │   │   │   args.append(attribute_class.from_pretrained(pretrained_mod │
│   229 │   │   return args                                                    │
│   230 │                                                                      │
│   231 │   @property                                                          │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/mod │
│ els/auto/tokenization_auto.py:679 in from_pretrained                         │
│                                                                              │
│   676 │   │   │   │   raise ValueError(                                      │
│   677 │   │   │   │   │   f"Tokenizer class {tokenizer_class_candidate} does │
│   678 │   │   │   │   )                                                      │
│ ❱ 679 │   │   │   return tokenizer_class.from_pretrained(pretrained_model_na │
│   680 │   │                                                                  │
│   681 │   │   # Otherwise we have to be creative.                            │
│   682 │   │   # if model is an encoder decoder, the encoder tokenizer class  │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/tok │
│ enization_utils_base.py:1804 in from_pretrained                              │
│                                                                              │
│   1801 │   │   │   else:                                                     │
│   1802 │   │   │   │   logger.info(f"loading file {file_path} from cache at  │
│   1803 │   │                                                                 │
│ ❱ 1804 │   │   return cls._from_pretrained(                                  │
│   1805 │   │   │   resolved_vocab_files,                                     │
│   1806 │   │   │   pretrained_model_name_or_path,                            │
│   1807 │   │   │   init_configuration,                                       │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/tok │
│ enization_utils_base.py:1958 in _from_pretrained                             │
│                                                                              │
│   1955 │   │                                                                 │
│   1956 │   │   # Instantiate tokenizer.                                      │
│   1957 │   │   try:                                                          │
│ ❱ 1958 │   │   │   tokenizer = cls(*init_inputs, **init_kwargs)              │
│   1959 │   │   except OSError:                                               │
│   1960 │   │   │   raise OSError(                                            │
│   1961 │   │   │   │   "Unable to load vocabulary from file. "               │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/mod │
│ els/t5/tokenization_t5_fast.py:133 in __init__                               │
│                                                                              │
│   130 │   │   │   │   │   " tokens"                                          │
│   131 │   │   │   │   )                                                      │
│   132 │   │                                                                  │
│ ❱ 133 │   │   super().__init__(                                              │
│   134 │   │   │   vocab_file,                                                │
│   135 │   │   │   tokenizer_file=tokenizer_file,                             │
│   136 │   │   │   eos_token=eos_token,                                       │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/transformers/tok │
│ enization_utils_fast.py:111 in __init__                                      │
│                                                                              │
│   108 │   │   │   fast_tokenizer = copy.deepcopy(tokenizer_object)           │
│   109 │   │   elif fast_tokenizer_file is not None and not from_slow:        │
│   110 │   │   │   # We have a serialization from tokenizers which let us dir │
│ ❱ 111 │   │   │   fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_fi │
│   112 │   │   elif slow_tokenizer is not None:                               │
│   113 │   │   │   # We need to convert a slow tokenizer to build the backend │
│   114 │   │   │   fast_tokenizer = convert_slow_tokenizer(slow_tokenizer)    │
╰──────────────────────────────────────────────────────────────────────────────╯
Exception: data did not match any variant of untagged enum 
PyPreTokenizerTypeWrapper at line 964 column 3
Namespace(mode='guess', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', num_per_category='3')
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'pet', 'num_classes': 37, 'num_base': 19, 'num_novel': 18, 'seed': 1, 'batch_size': 32, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'FlanT5-XXL', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'chaos', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/pet_37', 'expt_dir': './experiments/pet37', 'expt_dir_describe': './experiments/pet37/describe', 'path_vqa_questions': './experiments/pet37/describe/pet_vqa_questions', 'path_vqa_answers': './experiments/pet37/describe/pet_attributes_pairs', 'path_llm_prompts': './experiments/pet37/describe/pet_llm_prompts', 'expt_dir_guess': './experiments/pet37/guess', 'path_llm_replies_raw': './experiments/pet37/guess/pet_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/pet37/guess/pet_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/pet37/guess/pet_llm_gussed_names', 'expt_dir_grouping': './experiments/pet37/grouping'}
0it [00:00, ?it/s]0it [01:51, ?it/s]
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_transport │
│ s/default.py:101 in map_httpcore_exceptions                                  │
│                                                                              │
│    98 │   if len(HTTPCORE_EXC_MAP) == 0:                                     │
│    99 │   │   HTTPCORE_EXC_MAP = _load_httpcore_exceptions()                 │
│   100 │   try:                                                               │
│ ❱ 101 │   │   yield                                                          │
│   102 │   except Exception as exc:                                           │
│   103 │   │   mapped_exc = None                                              │
│   104                                                                        │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_transport │
│ s/default.py:250 in handle_request                                           │
│                                                                              │
│   247 │   │   │   extensions=request.extensions,                             │
│   248 │   │   )                                                              │
│   249 │   │   with map_httpcore_exceptions():                                │
│ ❱ 250 │   │   │   resp = self._pool.handle_request(req)                      │
│   251 │   │                                                                  │
│   252 │   │   assert isinstance(resp.stream, typing.Iterable)                │
│   253                                                                        │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_sync/c │
│ onnection_pool.py:256 in handle_request                                      │
│                                                                              │
│   253 │   │   │   │   closing = self._assign_requests_to_connections()       │
│   254 │   │   │                                                              │
│   255 │   │   │   self._close_connections(closing)                           │
│ ❱ 256 │   │   │   raise exc from None                                        │
│   257 │   │                                                                  │
│   258 │   │   # Return the response. Note that in this case we still have to │
│   259 │   │   # the point at which the response is closed.                   │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_sync/c │
│ onnection_pool.py:236 in handle_request                                      │
│                                                                              │
│   233 │   │   │   │                                                          │
│   234 │   │   │   │   try:                                                   │
│   235 │   │   │   │   │   # Send the request on the assigned connection.     │
│ ❱ 236 │   │   │   │   │   response = connection.handle_request(              │
│   237 │   │   │   │   │   │   pool_request.request                           │
│   238 │   │   │   │   │   )                                                  │
│   239 │   │   │   │   except ConnectionNotAvailable:                         │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_sync/c │
│ onnection.py:101 in handle_request                                           │
│                                                                              │
│    98 │   │   │   │   │   │   )                                              │
│    99 │   │   except BaseException as exc:                                   │
│   100 │   │   │   self._connect_failed = True                                │
│ ❱ 101 │   │   │   raise exc                                                  │
│   102 │   │                                                                  │
│   103 │   │   return self._connection.handle_request(request)                │
│   104                                                                        │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_sync/c │
│ onnection.py:78 in handle_request                                            │
│                                                                              │
│    75 │   │   try:                                                           │
│    76 │   │   │   with self._request_lock:                                   │
│    77 │   │   │   │   if self._connection is None:                           │
│ ❱  78 │   │   │   │   │   stream = self._connect(request)                    │
│    79 │   │   │   │   │                                                      │
│    80 │   │   │   │   │   ssl_object = stream.get_extra_info("ssl_object")   │
│    81 │   │   │   │   │   http2_negotiated = (                               │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_sync/c │
│ onnection.py:124 in _connect                                                 │
│                                                                              │
│   121 │   │   │   │   │   │   "socket_options": self._socket_options,        │
│   122 │   │   │   │   │   }                                                  │
│   123 │   │   │   │   │   with Trace("connect_tcp", logger, request, kwargs) │
│ ❱ 124 │   │   │   │   │   │   stream = self._network_backend.connect_tcp(**k │
│   125 │   │   │   │   │   │   trace.return_value = stream                    │
│   126 │   │   │   │   else:                                                  │
│   127 │   │   │   │   │   kwargs = {                                         │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_backen │
│ ds/sync.py:215 in connect_tcp                                                │
│                                                                              │
│   212 │   │   │   )                                                          │
│   213 │   │   │   for option in socket_options:                              │
│   214 │   │   │   │   sock.setsockopt(*option)  # pragma: no cover           │
│ ❱ 215 │   │   │   sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) │
│   216 │   │   return SyncStream(sock)                                        │
│   217 │                                                                      │
│   218 │   def connect_unix_socket(                                           │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/contextlib.py:137 in __exit__  │
│                                                                              │
│   134 │   │   │   │   # tell if we get the same exception back               │
│   135 │   │   │   │   value = typ()                                          │
│   136 │   │   │   try:                                                       │
│ ❱ 137 │   │   │   │   self.gen.throw(typ, value, traceback)                  │
│   138 │   │   │   except StopIteration as exc:                               │
│   139 │   │   │   │   # Suppress StopIteration *unless* it's the same except │
│   140 │   │   │   │   # was passed to throw().  This prevents a StopIteratio │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpcore/_except │
│ ions.py:14 in map_exceptions                                                 │
│                                                                              │
│   11 │   except Exception as exc:  # noqa: PIE786                            │
│   12 │   │   for from_exc, to_exc in map.items():                            │
│   13 │   │   │   if isinstance(exc, from_exc):                               │
│ ❱ 14 │   │   │   │   raise to_exc(exc) from exc                              │
│   15 │   │   raise  # pragma: nocover                                        │
│   16                                                                         │
│   17                                                                         │
╰──────────────────────────────────────────────────────────────────────────────╯
ConnectError: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/openai/_base_cli │
│ ent.py:982 in request                                                        │
│                                                                              │
│    979 │   │   │                                                             │
│    980 │   │   │   response = None                                           │
│    981 │   │   │   try:                                                      │
│ ❱  982 │   │   │   │   response = self._client.send(                         │
│    983 │   │   │   │   │   request,                                          │
│    984 │   │   │   │   │   stream=stream or self._should_stream_response_bod │
│    985 │   │   │   │   │   **kwargs,                                         │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_client.py │
│ :914 in send                                                                 │
│                                                                              │
│    911 │   │                                                                 │
│    912 │   │   auth = self._build_request_auth(request, auth)                │
│    913 │   │                                                                 │
│ ❱  914 │   │   response = self._send_handling_auth(                          │
│    915 │   │   │   request,                                                  │
│    916 │   │   │   auth=auth,                                                │
│    917 │   │   │   follow_redirects=follow_redirects,                        │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_client.py │
│ :942 in _send_handling_auth                                                  │
│                                                                              │
│    939 │   │   │   request = next(auth_flow)                                 │
│    940 │   │   │                                                             │
│    941 │   │   │   while True:                                               │
│ ❱  942 │   │   │   │   response = self._send_handling_redirects(             │
│    943 │   │   │   │   │   request,                                          │
│    944 │   │   │   │   │   follow_redirects=follow_redirects,                │
│    945 │   │   │   │   │   history=history,                                  │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_client.py │
│ :979 in _send_handling_redirects                                             │
│                                                                              │
│    976 │   │   │   for hook in self._event_hooks["request"]:                 │
│    977 │   │   │   │   hook(request)                                         │
│    978 │   │   │                                                             │
│ ❱  979 │   │   │   response = self._send_single_request(request)             │
│    980 │   │   │   try:                                                      │
│    981 │   │   │   │   for hook in self._event_hooks["response"]:            │
│    982 │   │   │   │   │   hook(response)                                    │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_client.py │
│ :1014 in _send_single_request                                                │
│                                                                              │
│   1011 │   │   │   )                                                         │
│   1012 │   │                                                                 │
│   1013 │   │   with request_context(request=request):                        │
│ ❱ 1014 │   │   │   response = transport.handle_request(request)              │
│   1015 │   │                                                                 │
│   1016 │   │   assert isinstance(response.stream, SyncByteStream)            │
│   1017                                                                       │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_transport │
│ s/default.py:250 in handle_request                                           │
│                                                                              │
│   247 │   │   │   extensions=request.extensions,                             │
│   248 │   │   )                                                              │
│   249 │   │   with map_httpcore_exceptions():                                │
│ ❱ 250 │   │   │   resp = self._pool.handle_request(req)                      │
│   251 │   │                                                                  │
│   252 │   │   assert isinstance(resp.stream, typing.Iterable)                │
│   253                                                                        │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/contextlib.py:137 in __exit__  │
│                                                                              │
│   134 │   │   │   │   # tell if we get the same exception back               │
│   135 │   │   │   │   value = typ()                                          │
│   136 │   │   │   try:                                                       │
│ ❱ 137 │   │   │   │   self.gen.throw(typ, value, traceback)                  │
│   138 │   │   │   except StopIteration as exc:                               │
│   139 │   │   │   │   # Suppress StopIteration *unless* it's the same except │
│   140 │   │   │   │   # was passed to throw().  This prevents a StopIteratio │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/httpx/_transport │
│ s/default.py:118 in map_httpcore_exceptions                                  │
│                                                                              │
│   115 │   │   │   raise                                                      │
│   116 │   │                                                                  │
│   117 │   │   message = str(exc)                                             │
│ ❱ 118 │   │   raise mapped_exc(message) from exc                             │
│   119                                                                        │
│   120                                                                        │
│   121 class ResponseStream(SyncByteStream):                                  │
╰──────────────────────────────────────────────────────────────────────────────╯
ConnectError: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/tenacity/__init_ │
│ _.py:382 in __call__                                                         │
│                                                                              │
│   379 │   │   │   do = self.iter(retry_state=retry_state)                    │
│   380 │   │   │   if isinstance(do, DoAttempt):                              │
│   381 │   │   │   │   try:                                                   │
│ ❱ 382 │   │   │   │   │   result = fn(*args, **kwargs)                       │
│   383 │   │   │   │   except BaseException:  # noqa: B902                    │
│   384 │   │   │   │   │   retry_state.set_exception(sys.exc_info())  # type: │
│   385 │   │   │   │   else:                                                  │
│                                                                              │
│ /home/hdl/project/FineR/FineR_fullpipe/agents/llm_bot.py:57 in call_gpts     │
│                                                                              │
│    54 │   │   │   max_tokens=max_tokens                                      │
│    55 │   │   )                                                              │
│    56 │   else:                                                              │
│ ❱  57 │   │   response = client.chat.completions.create(                     │
│    58 │   │   │   model=model,                                               │
│    59 │   │   │   messages=chatgpt_messages,                                 │
│    60 │   │   │   temperature=temperature                                    │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/openai/_utils/_u │
│ tils.py:287 in wrapper                                                       │
│                                                                              │
│   284 │   │   │   │   │   else:                                              │
│   285 │   │   │   │   │   │   msg = f"Missing required argument: {quote(miss │
│   286 │   │   │   │   raise TypeError(msg)                                   │
│ ❱ 287 │   │   │   return func(*args, **kwargs)                               │
│   288 │   │                                                                  │
│   289 │   │   return wrapper  # type: ignore                                 │
│   290                                                                        │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/openai/resources │
│ /chat/completions/completions.py:1147 in create                              │
│                                                                              │
│   1144 │   │   timeout: float | httpx.Timeout | None | NotGiven = NOT_GIVEN, │
│   1145 │   ) -> ChatCompletion | Stream[ChatCompletionChunk]:                │
│   1146 │   │   validate_response_format(response_format)                     │
│ ❱ 1147 │   │   return self._post(                                            │
│   1148 │   │   │   "/chat/completions",                                      │
│   1149 │   │   │   body=maybe_transform(                                     │
│   1150 │   │   │   │   {                                                     │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/openai/_base_cli │
│ ent.py:1259 in post                                                          │
│                                                                              │
│   1256 │   │   opts = FinalRequestOptions.construct(                         │
│   1257 │   │   │   method="post", url=path, json_data=body, files=to_httpx_f │
│   1258 │   │   )                                                             │
│ ❱ 1259 │   │   return cast(ResponseT, self.request(cast_to, opts, stream=str │
│   1260 │                                                                     │
│   1261 │   def patch(                                                        │
│   1262 │   │   self,                                                         │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/openai/_base_cli │
│ ent.py:1014 in request                                                       │
│                                                                              │
│   1011 │   │   │   │   │   continue                                          │
│   1012 │   │   │   │                                                         │
│   1013 │   │   │   │   log.debug("Raising connection error")                 │
│ ❱ 1014 │   │   │   │   raise APIConnectionError(request=request) from err    │
│   1015 │   │   │                                                             │
│   1016 │   │   │   log.debug(                                                │
│   1017 │   │   │   │   'HTTP Response: %s %s "%i %s" %s',                    │
╰──────────────────────────────────────────────────────────────────────────────╯
APIConnectionError: Connection error.

The above exception was the direct cause of the following exception:

╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/hdl/project/FineR/FineR_fullpipe/discovering.py:394 in <module>        │
│                                                                              │
│   391 │   │   llm_bot = LLMBot(model=cfg['model_type_llm'])                  │
│   392 │   │                                                                  │
│   393 │   │   # run the main program                                         │
│ ❱ 394 │   │   raw_replies, jsoned_replies = main_guess(cfg, llm_bot, reasoni │
│   395 │   │                                                                  │
│   396 │   │   # save LLM replis                                              │
│   397 │   │   dump_json(cfg['path_llm_replies_raw'] + expt_id_suffix, raw_re │
│                                                                              │
│ /home/hdl/project/FineR/FineR_fullpipe/discovering.py:170 in main_guess      │
│                                                                              │
│   167 │                                                                      │
│   168 │   # LLM inferring                                                    │
│   169 │   for i, (key, prompt) in tqdm(enumerate(prompt_list.items())):      │
│ ❱ 170 │   │   raw_reply = bot.infer(prompt, temperature=0.9)  # use a high t │
│   171 │   │   used_tokens = bot.get_used_tokens()                            │
│   172 │   │                                                                  │
│   173 │   │   replies_raw[key] = raw_reply                                   │
│                                                                              │
│ /home/hdl/project/FineR/FineR_fullpipe/agents/llm_bot.py:118 in infer        │
│                                                                              │
│   115 │   │   return reply, total_prompt, n_tokens                           │
│   116 │                                                                      │
│   117 │   def infer(self, prompt, temperature=0.9):                          │
│ ❱ 118 │   │   reply, _, n_tokens = self.__query(prompt, temperature, max_tok │
│   119 │   │   self.total_tokens += n_tokens                                  │
│   120 │   │   return reply.strip()                                           │
│   121                                                                        │
│                                                                              │
│ /home/hdl/project/FineR/FineR_fullpipe/agents/llm_bot.py:108 in __query      │
│                                                                              │
│   105 │                                                                      │
│   106 │   def __query(self, prompt, temperature, max_token):                 │
│   107 │   │   total_prompt = prepare_chatgpt_message(prompt)                 │
│ ❱ 108 │   │   reply, n_tokens = call_gpts(                                   │
│   109 │   │   │   client=self.client,                                        │
│   110 │   │   │   chatgpt_messages=total_prompt,                             │
│   111 │   │   │   temperature=temperature,                                   │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/tenacity/__init_ │
│ _.py:289 in wrapped_f                                                        │
│                                                                              │
│   286 │   │                                                                  │
│   287 │   │   @functools.wraps(f)                                            │
│   288 │   │   def wrapped_f(*args: t.Any, **kw: t.Any) -> t.Any:             │
│ ❱ 289 │   │   │   return self(f, *args, **kw)                                │
│   290 │   │                                                                  │
│   291 │   │   def retry_with(*args: t.Any, **kwargs: t.Any) -> WrappedFn:    │
│   292 │   │   │   return self.copy(*args, **kwargs).wraps(f)                 │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/tenacity/__init_ │
│ _.py:379 in __call__                                                         │
│                                                                              │
│   376 │   │                                                                  │
│   377 │   │   retry_state = RetryCallState(retry_object=self, fn=fn, args=ar │
│   378 │   │   while True:                                                    │
│ ❱ 379 │   │   │   do = self.iter(retry_state=retry_state)                    │
│   380 │   │   │   if isinstance(do, DoAttempt):                              │
│   381 │   │   │   │   try:                                                   │
│   382 │   │   │   │   │   result = fn(*args, **kwargs)                       │
│                                                                              │
│ /home/hdl/miniconda3/envs/finer/lib/python3.9/site-packages/tenacity/__init_ │
│ _.py:326 in iter                                                             │
│                                                                              │
│   323 │   │   │   retry_exc = self.retry_error_cls(fut)                      │
│   324 │   │   │   if self.reraise:                                           │
│   325 │   │   │   │   raise retry_exc.reraise()                              │
│ ❱ 326 │   │   │   raise retry_exc from fut.exception()                       │
│   327 │   │                                                                  │
│   328 │   │   if self.wait:                                                  │
│   329 │   │   │   sleep = self.wait(retry_state)                             │
╰──────────────────────────────────────────────────────────────────────────────╯
RetryError: RetryError[<Future at 0x74856aaf5dc0 state=finished raised 
APIConnectionError>]
Namespace(mode='postprocess', config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', num_per_category='3')
{'setup': 'ours', 'experiment': 5.0, 'dataset_name': 'pet', 'num_classes': 37, 'num_base': 19, 'num_novel': 18, 'seed': 1, 'batch_size': 32, 'clustering_method': 'multi_clip_voting', 'model_size': 'ViT-B/16', 'model_size_vqa': 'FlanT5-XXL', 'model_type_llm': 'gpt-3.5-turbo', 'image_size': 224, 'verbose': False, 'host': 'chaos', 'num_workers': 16, 'device': 'cuda', 'device_count': '1', 'device_id': '0', 'data_dir': './datasets/pet_37', 'expt_dir': './experiments/pet37', 'expt_dir_describe': './experiments/pet37/describe', 'path_vqa_questions': './experiments/pet37/describe/pet_vqa_questions', 'path_vqa_answers': './experiments/pet37/describe/pet_attributes_pairs', 'path_llm_prompts': './experiments/pet37/describe/pet_llm_prompts', 'expt_dir_guess': './experiments/pet37/guess', 'path_llm_replies_raw': './experiments/pet37/guess/pet_llm_replies_raw', 'path_llm_replies_jsoned': './experiments/pet37/guess/pet_llm_replies_jsoned', 'path_llm_gussed_names': './experiments/pet37/guess/pet_llm_gussed_names', 'expt_dir_grouping': './experiments/pet37/grouping'}
Keeshond_0
{
    "Cairn Terrier": [
        "The dog in the photo is large with a spherical body shape and a snub nose.",
        "It has a short neck and legs with a thick leg shape.",
        "The dog has large square paws and toes.",
        "Its tail is stubby and wagging.",
        "The dog has a long and fluffy black and white coat with a tan and black coat pattern."
    ],
    "Pomeranian": [
        "The dog in the photo is large with a spherical body shape and a snub nose.",
        "It has a short neck and legs with a thick leg shape.",
        "The dog has large square paws and toes.",
        "Its tail is stubby and wagging.",
        "The dog has a long and fluffy black and white coat with a tan and black coat pattern."
    ],
    "Shih Tzu": [
        "The dog in the photo is large with a spherical body shape and a snub nose.",
        "It has a short neck and legs with a thick leg shape.",
        "The dog has large square paws and toes.",
        "Its tail is stubby and wagging.",
        "The dog has a long and fluffy black and white coat with a tan and black coat pattern."
    ]
}


Keeshond_1
{
    "Basset Hound, Bulldog, Boston Terrier": [
        "The dog in the photo is sitting on a couch.",
        "It has a medium-sized body with a hound-like shape.",
        "The dog has a large head with a snub nose, facial wrinkles, and short neck.",
        "Its legs are short, slender, and thin, with large round paws and splayed toes.",
        "The dog has a short and fluffy coat with a mix of black and white colors."
    ]
}


Keeshond_2
{
    "Hound, Boxer, Dalmatian": [
        "The dog in the photo is a large hound with a snub nose and a short, squarish body shape.",
        "It has a fluffy, short coat that is black and white in color.",
        "The dog has a stubby tail that is pointing to the left and square paws with thick legs.",
        "Its facial features include round eyes and erect ears, with a white nose and markings on its body.",
        "Overall, the dog appears to have the characteristics of a hound, boxer, or dalmatian."
    ]
}


English Cocker Spaniel_3
{
    "Cocker Spaniel": [
        "The dog in the photo is a medium-sized cocker spaniel with a large head and facial wrinkles.",
        "It has a short neck, short legs with a thick leg shape, and medium-sized paws.",
        "The dog has a short, smooth coat with a tan and white color pattern.",
        "Its fur is smooth and silky, and it has oblong-shaped brown eyes.",
        "The ears are erect, and the muzzle has a snub nose."
    ],
    "English Cocker Spaniel": [
        "The dog in the photo is a medium-sized cocker spaniel with a large head and facial wrinkles.",
        "It has a short neck, short legs with a thick leg shape, and medium-sized paws.",
        "The dog has a short, smooth coat with a tan and white color pattern.",
        "Its fur is smooth and silky, and it has oblong-shaped brown eyes.",
        "The ears are erect, and the muzzle has a snub nose."
    ],
    "American Cocker Spaniel": [
        "The dog in the photo is a medium-sized cocker spaniel with a large head and facial wrinkles.",
        "It has a short neck, short legs with a thick leg shape, and medium-sized paws.",
        "The dog has a short, smooth coat with a tan and white color pattern.",
        "Its fur is smooth and silky, and it has oblong-shaped brown eyes.",
        "The ears are erect, and the muzzle has a snub nose."
    ]
}


English Cocker Spaniel_4
{
    "Cocker Spaniel": [
        "The dog in the photo is a medium-sized cocker spaniel with a spherical head and a large size.",
        "It has short legs with a slender shape and thick paw size.",
        "The coat is short and smooth, with a brown and white color pattern and a tan patch.",
        "The fur is short and dense, and the overall appearance is fluffy.",
        "The dog has round brown eyes, erect ears, and a snout of medium length."
    ],
    "English Cocker Spaniel": [
        "The dog in the photo is a medium-sized cocker spaniel with a spherical head and a large size.",
        "It has short legs with a slender shape and thick paw size.",
        "The coat is short and smooth, with a brown and white color pattern and a tan patch.",
        "The fur is short and dense, and the overall appearance is fluffy.",
        "The dog has round brown eyes, erect ears, and a snout of medium length."
    ],
    "American Cocker Spaniel": [
        "The dog in the photo is a medium-sized cocker spaniel with a spherical head and a large size.",
        "It has short legs with a slender shape and thick paw size.",
        "The coat is short and smooth, with a brown and white color pattern and a tan patch.",
        "The fur is short and dense, and the overall appearance is fluffy.",
        "The dog has round brown eyes, erect ears, and a snout of medium length."
    ]
}


English Cocker Spaniel_5
{
    "Cocker Spaniel, Dachshund, Basset Hound": [
        "The dog in the photo is laying on a rug.",
        "It has a long body and medium size.",
        "The head shape resembles that of a cocker spaniel and is small in size.",
        "The dog has a white and brown coat with facial wrinkles.",
        "It has a short neck, short legs with slender and thin shape, and small square paws with square toes. The dog has a short and tucked under tail. The coat is brown and white in color, short in length, and has a smooth texture. The dog has round brown eyes, erect ears, a square muzzle, and a short snout with a snub nose. Overall, the dog has a long body and short legs and appears fluffy with white and brown facial and body markings."
    ]
}


Bombay_6
{
  "Bombay, Oriental Shorthair, American Shorthair": [
    "The cat in the photo is a black cat with a long body and a short tail.",
    "It has a spherical head and a large size.",
    "Its coat is black and short with a smooth texture.",
    "The cat has round green eyes and a snout with a medium length.",
    "It also has white markings on its face and body.",
  ]
}


Failed to decode JSON for key: Bombay_6
Bombay_7
{
  "Bombay, Oriental Shorthair, British Shorthair": [
    "This black cat has a long body and a rounded head.",
    "Its legs, neck, and tail are all short.",
    "The coat is solid black with a smooth and glossy texture.",
    "The cat's eyes are round and blue in color.",
    "It has white markings on the chest and belly, as well as a white nose and chin.",
  ]
}


Failed to decode JSON for key: Bombay_7
Bombay_8
{
  "Bombay, British Shorthair, Russian Blue": [
    "The cat in the photo is a small-bodied cat with a round body shape and small head.",
    "It has a short neck and short legs with a slender shape and thin thickness.",
    "The cat has large round paws with rounded toes.",
    "Its tail is stubby and tucked under the cat.",
    "The cat has a sleek black coat with soft and short fur."
  ]
}


Leonberger_9
{
   "Bulldog": [
      "The photo shows a woman petting a large, square-headed dog with a lot of wrinkles.",
      "The dog has a short neck and short legs with straight and thick paws.",
      "It has a stubby tail pointing to the left and a fluffy, long coat in brown and tan colors.",
      "The dog has a soft and fluffy fur with round brown eyes, erect ears, and a square muzzle.",
      "Overall, it has a large and muscular body with breed-specific markings of a white chest and fluffy appearance."
   ],
   "Chow Chow": [
      "The photo shows a woman petting a large, square-headed dog with a lot of wrinkles.",
      "The dog has a short neck and short legs with straight and thick paws.",
      "It has a stubby tail pointing to the left and a fluffy, long coat in brown and tan colors.",
      "The dog has a soft and fluffy fur with round brown eyes, erect ears, and a square muzzle.",
      "Overall, it has a large and muscular body with breed-specific markings of a white chest and fluffy appearance."
   ],
   "Mastiff": [
      "The photo shows a woman petting a large, square-headed dog with a lot of wrinkles.",
      "The dog has a short neck and short legs with straight and thick paws.",
      "It has a stubby tail pointing to the left and a fluffy, long coat in brown and tan colors.",
      "The dog has a soft and fluffy fur with round brown eyes, erect ears, and a square muzzle.",
      "Overall, it has a large and muscular body with breed-specific markings of a white chest and fluffy appearance."
   ]
}


Leonberger_10
{
    "Labrador Retriever, Boxer, Saint Bernard": [
        "The photo shows a large dog with a square head, short neck, and short legs.",
        "The dog has a thick leg shape and large paws with square paws and toes.",
        "Its tail is stubby and wagging.",
        "The dog has a brown coat with a tan and brown pattern, which is short and smooth.",
        "It has a soft and dense fur texture."
    ]
}


Leonberger_11
{
   "Bulldog": [
      "The dog in the photo is large with a snub nose and a lot of wrinkles on its face.",
      "It has short legs and a thick body.",
      "The dog has a stubby tail that is wagging.",
      "Its coat is short, fluffy, and has a mix of black and brown.",
      "The dog has round brown eyes, erect ears, and a square muzzle."
   ],
   "Boxer": [
      "The dog in the photo is large with a snub nose and a lot of wrinkles on its face.",
      "It has short legs and a thick body.",
      "The dog has a stubby tail that is wagging.",
      "Its coat is short, fluffy, and has a mix of black and brown.",
      "The dog has round brown eyes, erect ears, and a square muzzle."
   ],
   "Pug": [
      "The dog in the photo is large with a snub nose and a lot of wrinkles on its face.",
      "It has short legs and a thick body.",
      "The dog has a stubby tail that is wagging.",
      "Its coat is short, fluffy, and has a mix of black and brown.",
      "The dog has round brown eyes, erect ears, and a square muzzle."
   ]
}


Yorkshire Terrier_12
{
    "Yorkshire Terrier, Shih Tzu, Maltese": [
        "The dog in the photo is a small Yorkshire Terrier with a brown and black short coat.",
        "It has a fluffy appearance, with a square muzzle and snub nose.",
        "The dog has short legs, a stubby tail, and floppy ears that point forward.",
        "Overall, it is a small and adorable dog.",
        "It could possibly be a Yorkshire Terrier, Shih Tzu, or Maltese breed."
    ]
}


Yorkshire Terrier_13
{
"Yorkshire Terrier, Yorkie, Small Terrier": [
"The dog in the photo is a small Yorkie with a short and smooth tan and black coat.",
"It has a square muzzle, round brown eyes, and erect ears.",
"The dog has a short tail that is wagging and has a snub nose with a black color.",
"Its body is small and proportionate, with slender legs and square paws.",
"The dog has facial wrinkles and fluffy, soft fur."
]
}


Yorkshire Terrier_14
{
    "Yorkshire Terrier, Yorkie, Silky Terrier": [
        "The dog in the photo is a small Yorkie with a brown and white coat.",
        "It has a small body and head, with short legs and a stubby tail.",
        "The dog's fur is short and dense, with a smooth texture.",
        "It has round brown eyes and erect ears that are pinned back.",
        "Overall, the dog has a fluffy appearance and a squinty facial expression."
    ]
}


Boxer_15
{
    "Boxer, Bullmastiff, Rottweiler": [
        "The dog in the photo is a large Boxer with a muscular body.",
        "It has a square head with facial wrinkles, a short neck, and short legs with thick square paws.",
        "The coat is short and smooth, with a brown and black color pattern.",
        "The dog has round brown eyes, erect ears, and a short snout with a black nose.",
        "It has a square tail that is wagging. The overall appearance of the dog is sleek and it has breed-specific markings of a collar and leash."
    ]
}


Boxer_16
{
  "Boxer, Bulldog, Pitbull": [
    "The photo shows a large dog sitting in the snow.",
    "The dog has a boxer body shape and a boxer head shape, with a large head and facial wrinkles.",
    "Its neck and legs are short and thick, with square paws and square toes.",
    "The dog has a short, smooth coat in a solid brown color, and its fur is short and dense.",
    "It has round brown eyes, floppy ears, a square muzzle, and a short snout with a square nose. The dog has an overall muscular appearance, with breed-specific markings including a black nose and a white chest."
  ]
}


Boxer_17
{
   "Boxer, Bulldog, Pitbull": [
      "The dog in the photo is a large boxer with a muscular body shape and proportion.",
      "It has a short and dense coat with a smooth texture, which is brown and white in color.",
      "The dog has a square muzzle and a short snout, with round brown eyes and erect ears.",
      "Its tail is short and square-shaped, positioned in a wagging position.",
      "The dog has a short neck and legs, with thick and square-shaped paws. It has specific breed markings, such as white on the nose and brown and white body markings."
   ]
}


Shiba Inu_18
{
   "Shiba Inu":[
      "The photo depicts a medium-sized dog with a spherical body shape and a small head.",
      "It has short legs that are slender and thin, with large splayed paws and square toes.",
      "The dog has a stubby tail that points up.",
      "Its coat is brown and white, short in length, and has a smooth texture.",
      "The overall appearance of the dog is muscular, and it has facial markings with a white nose and body markings on its chest."
   ],
   "Bulldog":[
      "The photo depicts a medium-sized dog with a spherical body shape and a small head.",
      "It has short legs that are slender and thin, with large splayed paws and square toes.",
      "The dog has a stubby tail that points up.",
      "Its coat is brown and white, short in length, and has a smooth texture.",
      "The overall appearance of the dog is muscular, and it has facial markings with a white nose and body markings on its chest."
   ],
   "Boxer":[
      "The photo depicts a medium-sized dog with a spherical body shape and a small head.",
      "It has short legs that are slender and thin, with large splayed paws and square toes.",
      "The dog has a stubby tail that points up.",
      "Its coat is brown and white, short in length, and has a smooth texture.",
      "The overall appearance of the dog is muscular, and it has facial markings with a white nose and body markings on its chest."
   ]
}


Shiba Inu_19
{
    "Shiba Inu, Asian Samoyed, Labrador Retriever": [
        "The dog in the photo is standing in a field with green grass.",
        "It has a slender body and medium size.",
        "The dog has a snub nose and a large head.",
        "It has short legs with a stout, straight shape and a thick leg thickness.",
        "The dog has a short, slender tail that is tucked under."
    ]
}


Shiba Inu_20
{
  "Shiba Inu, Shih Tzu, Bulldog": [
    "The dog in the photo is large in size with a spherical body shape and a large spherical head.",
    "It has short neck and leg length, with slender and thin legs.",
    "The dog has large paws with a splayed paw shape and splayed toes.",
    "It has a short, slender tail that is tucked under its body.",
    "The dog's coat is brown and black in color, with a short and smooth texture."
  ]
}


Maine Coon_21
{
    "Possible Cat Breeds": [
        "The photo depicts a large, long-haired and fluffy orange cat laying on the floor with a ball.",
        "It has a long and slender body with a large spherical head.",
        "The cat has a squinty look and round brown eyes.",
        "Its legs are long and thick, with a slender leg shape.",
        "It also has a slender, long tail that is tucked under its body."
    ]
}


Maine Coon_22
{
  "Maine Coon, Norwegian Forest Cat, Siberian Cat": [
    "The cat in the photo is a large, long and slender cat with a round head and a long, fluffy coat.",
    "It has a long tail that points down and its body markings are white and gray.",
    "The cat has round blue eyes and a snub nose with a black color.",
    "Its ears are erect and pointing forward.",
    "The overall appearance of the cat is fluffy and it has breed-specific markings of being a long-haired cat."
  ]
}


Maine Coon_23
{
    "Maine Coon, Norwegian Forest Cat, Siberian Cat": [
        "This photo shows a large, long-haired cat with a round head and a long, slender body.",
        "The cat has a gray and white fluffy coat, long dense fur, and a stubby tail that is tucked.",
        "It has round green eyes and a yellow eye.",
        "The cat has a snout-shaped muzzle, short snout, and erect ears.",
        "It also has long whiskers and curved claws."
    ]
}


Saint Bernard_24
{
  "St. Bernard, Bernese Mountain Dog, Greater Swiss Mountain Dog": [
    "The dog in the photo is a large St. Bernard with a muscular body and a short tail.",
    "It has a white and brown coat, smooth fur, and brown eyes.",
    "The dog's head is large and has facial wrinkles and a black muzzle.",
    "Its legs are thick and have St. Bernard breed characteristics.",
    "The dog has a friendly and gentle appearance."
  ]
}


Saint Bernard_25
{
    "St. Bernard, Mastiff, Boxer": [
        "The photo shows two dogs sitting on the floor.",
        "The dogs appear to be of a large size, with a St. Bernard body shape, large head size, and short, thick legs.",
        "They have large, square paws and square toes.",
        "The dogs have a short, smooth coat that is brown and white in color, with a dense fur texture.",
        "They have round, brown eyes and erect ears."
    ]
}


Saint Bernard_26
{
  "St. Bernard, Newfoundland, Bernese Mountain Dog": [
    "The dog in the photo is a large St. Bernard with a square head and large, square paws.",
    "It has a short neck and short legs with a thick build.",
    "The dog has a short, smooth coat that is brown and white in color.",
    "It has a stubby tail that points up.",
    "The dog has round brown eyes and erect ears. Overall, it has a muscular appearance."
  ]
}


German Shorthaired_27
{
  "Poodle, Dalmatian, Bulldog": [
    "The dog in the photo has a spherical body shape and a small, spherical head.",
    "It has a short neck, short legs, and thin paws.",
    "The dog has a short, black and white coat with spots and stripes.",
    "Its tail is short and curled under the body, and it has a stocky overall body shape.",
    "The dog has a snub nose, round brown eyes, and a square muzzle."
  ]
}


German Shorthaired_28
{
  "Pointer, Dalmatian, Beagle": [
    "The dog in the photo is sitting on a carpeted floor.",
    "It has a long body and medium size.",
    "The head is small and has a pointer shape.",
    "The dog is wearing a red collar and has short neck and leg length.",
    "The legs are straight and thin, with small square paws and square toes."
  ]
}


German Shorthaired_29
{
    "Pointer, Dalmatian, Boston Terrier": [
        "The dog in the photo is a medium-sized dog with a long body and a large head.",
        "It has facial wrinkles, a short neck, and short, thin legs with round paws and square toes.",
        "The dog has a short, stubby tail that points to the left.",
        "Its coat is black and white, short, and smooth, with short and dense fur.",
        "The dog has round brown eyes, pointy ears positioned up, and sleek overall appearance."
    ]
}


Japanese Chin_30
{
   "Chihuahua": [
      "The dog in the photo is a small black and white dog with a short, smooth coat.",
      "It has a small body and short legs, resembling a chihuahua.",
      "The dog's head is also small with a snub nose, round eyes, and erect ears.",
      "It has a short tail that is wagging.",
      "Overall, the dog has a sleek appearance and is sitting in the grass."
   ],
   "Dalmatian": [
      "The dog in the photo is a small black and white dog with a short, smooth coat.",
      "It has a small body and short legs, resembling a chihuahua.",
      "The dog's head is also small with a snub nose, round eyes, and erect ears.",
      "It has a short tail that is wagging.",
      "Overall, the dog has a sleek appearance and is sitting in the grass."
   ],
   "Boston Terrier": [
      "The dog in the photo is a small black and white dog with a short, smooth coat.",
      "It has a small body and short legs, resembling a chihuahua.",
      "The dog's head is also small with a snub nose, round eyes, and erect ears.",
      "It has a short tail that is wagging.",
      "Overall, the dog has a sleek appearance and is sitting in the grass."
   ]
}


Japanese Chin_31
{
    "Chihuahua, Jack Russell Terrier, Pomeranian": [
        "The dog in the photo is a small chihuahua playing with a toy on a blanket.",
        "It has a short and squarish body shape with a fluffy appearance.",
        "The chihuahua has a short coat with a white and brown color pattern, as well as facial and body markings.",
        "Its legs are slender with thin paws, and it has a short, tucked under tail.",
        "The dog also has round brown eyes, erect ears, a square muzzle, and a snub nose."
    ]
}


Japanese Chin_32
{
    "Chihuahua, Toy Fox Terrier, Rat Terrier": [
        "The dog in the photo is a small Chihuahua with a fluffy, short coat.",
        "It has a round face with brown eyes and a black nose.",
        "The dog's body is long and compact with short legs.",
        "Its fur is smooth and silky, with white markings on the chest, belly, and facial area.",
        "The tail is short and wagging."
    ]
}


Sphynx_33
{
  "Sphynx, Devon Rex, Peterbald": [
    "The cat in the photo is a small-sized sphynx cat with a large head.",
    "It has a shaved head with facial wrinkles.",
    "The cat has a short neck and short spherical legs with a shaved leg thickness.",
    "Its paws are small with a typical paw shape.",
    "It has a stubby tail and a short white coat with a sphynx texture."
  ]
}


Sphynx_34
{
  "Sphynx, Devon Rex, Cornish Rex": [
    "The photo shows a small-sized sphynx cat with a large head and facial wrinkles.",
    "It has a short neck and short, spherical legs with small paws.",
    "The cat has splayed toes and a short tail.",
    "Its coat color is gray and the hair is short, shaved, and has a sphynx cat pattern.",
    "The cat has blue eyes and a snub nose, with blue-colored nose and whiskers."
  ]
}


Sphynx_35
{"Sphynx, Devon Rex, Bambino": [
    "The photo shows a person holding a small cat with a spherical body shape and a small spherical head.",
    "The cat has a shaved head and facial wrinkles. It has short legs with a spherical shape and thin thickness, and small round paws with splayed toes.",
    "The cat's tail is short and spherical, and it is sitting. Its coat is short, shaved, and gray and white in color.",
    "The cat is a Sphynx breed with round green eyes, forward-pointing spherical ears, and a medium-length snout. Its nose is black and it has a sleek overall appearance.",
    "The cat also has breed-specific markings with a shaved head and tail, and short whiskers and claws."
]}


Ragdoll_36
{
    "Ragdoll": [
        "The cat in the photo is long and slender, with a large body size and a round head.",
        "It has a long neck, short legs, and large round paws.",
        "The cat has a long and fluffy coat, with white and gray colors.",
        "It has blue eyes and a snub nose, along with long whiskers and round claws.",
        "The overall appearance of the cat is fluffy, and it has breed-specific markings of white with blue eyes and white with black spots."
    ],
    "Maine Coon": [
        "The cat in the photo is long and slender, with a large body size and a round head.",
        "It has a long neck, short legs, and large round paws.",
        "The cat has a long and fluffy coat, with white and gray colors.",
        "It has blue eyes and a snub nose, along with long whiskers and round claws.",
        "The overall appearance of the cat is fluffy, and it has breed-specific markings of white with blue eyes and white with black spots."
    ],
    "Siberian": [
        "The cat in the photo is long and slender, with a large body size and a round head.",
        "It has a long neck, short legs, and large round paws.",
        "The cat has a long and fluffy coat, with white and gray colors.",
        "It has blue eyes and a snub nose, along with long whiskers and round claws.",
        "The overall appearance of the cat is fluffy, and it has breed-specific markings of white with blue eyes and white with black spots."
    ]
}


Ragdoll_37
{
  "Siamese, Scottish Fold, British Shorthair": [
    "The cat in the photo is small in size with a long body and a round-shaped head.",
    "It has a squinty look on its face.",
    "The cat's body shape is slender.",
    "Its coat is white and gray with a few brown spots.",
    "The cat has blue eyes and a fluffy appearance."
  ]
}


Ragdoll_38
{
  "Exotic Shorthair, British Shorthair, Ragdoll": [
    "The cat in the photo is a small-sized white cat with a round body and a round head.",
    "It has short legs with a slender shape and thin thickness.",
    "The cat has small round paws with round toes.",
    "Its tail is short and stubby, tucked under the cat.",
    "The cat's coat is white with a fluffy and spotted texture."
  ]
}


Great Pyrenees_39
{
  "Bulldog, Boxer, Dalmatian": [
    "The photo shows a woman standing next to a large dog on a leash.",
    "The dog has a large body size and a snub nose.",
    "It is standing on a sidewalk and has short legs and a thick leg shape.",
    "The dog has large square paws and square toes.",
    "It has a short and stub tail that is wagging."
  ]
}


Great Pyrenees_40
{
    "Bulldog, Boxer, Dalmatian": [
        "The dog in the photo is a large white dog with a lot of wrinkles and a fluffy short coat.",
        "It has a large head, short neck, and short legs with square paws and toes.",
        "The dog has a stubby tail that is tucked under.",
        "Its overall body shape and proportion are large, and it has a square muzzle and a snub nose.",
        "The dog has round brown eyes, erect ears, and a black nose. It also has breed-specific markings of white with black spots on its body and face."
    ]
}


Great Pyrenees_41
{
  "Bulldog, Boxer, Samoyed": [
    "The dog in the photo is a large dog with a snub nose and a large head.",
    "It has wrinkles on its face and a short neck.",
    "Its legs are short and thin, with straight and square-shaped paws and toes.",
    "The dog has a stub tail that is wagging.",
    "Its coat is white, short, and has a smooth texture."
  ]
}


Egyptian Mau_42
{
    "Bengal, Abyssinian, Egyptian Mau": [
        "The cat in the photo is a medium-sized cat with a slender body and a small head.",
        "It has a smooth and silky short coat with a spotted tabby pattern.",
        "The cat has blue round eyes and a black snub nose.",
        "Its ears are erect and it has short whiskers.",
        "The cat has a slender tail that is tucked under its body and it has short legs with splayed paws."
    ]
}


Egyptian Mau_43
{
   "Bengal": [
      "The cat in the photo is a medium-sized cat with a slender body, short legs, and a long body.",
      "It has a short and dense, spotted coat with a white belly.",
      "The cat has a sleek appearance and a squinty expression.",
      "Its head is large with round blue eyes and a snout.",
      "The ears are slanted and pinned back, and it has short whiskers and long, slender claws."
   ],
   "Egyptian Mau": [
      "The cat in the photo is a medium-sized cat with a slender body, short legs, and a long body.",
      "It has a short and dense, spotted coat with a white belly.",
      "The cat has a sleek appearance and a squinty expression.",
      "Its head is large with round blue eyes and a snout.",
      "The ears are slanted and pinned back, and it has short whiskers and long, slender claws."
   ],
   "Russian Blue": [
      "The cat in the photo is a medium-sized cat with a slender body, short legs, and a long body.",
      "It has a short and dense, spotted coat with a white belly.",
      "The cat has a sleek appearance and a squinty expression.",
      "Its head is large with round blue eyes and a snout.",
      "The ears are slanted and pinned back, and it has short whiskers and long, slender claws."
   ]
}


Egyptian Mau_44
{
    "Siamese, Bengal, Abyssinian": [
        "The photo shows two small kittens sitting on a pink blanket.",
        "They have a slender body shape with short legs.",
        "Their snub nosed head is small, and they have a snout with facial wrinkles.",
        "The kittens have a sable coat with spots, and their fur is short and dense.",
        "They have blue eyes and erect ears. The overall appearance of the kittens is sleek, and they have markings of sable and white spots."
    ]
}


Wheaten Terrier_45
{
   "Basset Hound": [
      "The dog in the photo is a large hound with a snub-nosed head and a lot of wrinkles.",
      "It has a short neck and short straight legs with thick square-shaped paws and square toes.",
      "The dog has a stubby wagging tail and a short, fluffy coat that is light brown in color.",
      "It has round brown eyes, floppy ears, and a square muzzle with a short snout.",
      "The dog has a short and stocky overall body shape and is mostly white with brown markings on the nose and chest."
   ],
   "Bulldog": [
      "The dog in the photo is a large hound with a snub-nosed head and a lot of wrinkles.",
      "It has a short neck and short straight legs with thick square-shaped paws and square toes.",
      "The dog has a stubby wagging tail and a short, fluffy coat that is light brown in color.",
      "It has round brown eyes, floppy ears, and a square muzzle with a short snout.",
      "The dog has a short and stocky overall body shape and is mostly white with brown markings on the nose and chest."
   ],
   "Boxer": [
      "The dog in the photo is a large hound with a snub-nosed head and a lot of wrinkles.",
      "It has a short neck and short straight legs with thick square-shaped paws and square toes.",
      "The dog has a stubby wagging tail and a short, fluffy coat that is light brown in color.",
      "It has round brown eyes, floppy ears, and a square muzzle with a short snout.",
      "The dog has a short and stocky overall body shape and is mostly white with brown markings on the nose and chest."
   ]
}


Wheaten Terrier_46
{
    "Shih Tzu, Pekingese, Bichon Frise": [
        "The dog in the photo is a small and fluffy breed with a brown shaggy coat and a white collar.",
        "It has a short and squarish body shape with slender legs and small square paws.",
        "The dog has a snub nose, round brown eyes, and floppy ears.",
        "Its tail is stubby and wagging, and it has facial wrinkles and a wet nose.",
        "Overall, this dog has a cute and friendly appearance."
    ]
}


Wheaten Terrier_47
{
    "Pug, French Bulldog, Boston Terrier": [
        "The photo shows a man brushing his small dog's teeth.",
        "The dog has a spherical body shape, small head size, and short neck and legs.",
        "It has a snub-nosed head shape and round eyes.",
        "The dog's coat is short and fluffy, with a white and brown color pattern.",
        "It has a stubby tail and floppy ears. Overall, the dog has a short and stout body shape and is white with brown markings."
    ]
}


English Setter_48
{
"Dalmatian, Boston Terrier, French Bulldog": [
"The photo shows a small puppy with a spherical head and short neck.",
"It has straight and thin legs with small square paws and square toes.",
"The puppy has a short and fluffy white and brown spotted coat with soft and dense fur.",
"It has round brown eyes and floppy ears that are pointing forward.",
"The overall body shape is short and squarish, and the puppy has white and brown markings on its face and body."
]
}


English Setter_49
{
    "Dalmatian, English Setter, Bull Terrier": [
        "The dog in the photo is a large dog with a long body and a snub nosed head.",
        "It has short legs and thin paws with square toes.",
        "The dog has a short, stub tail that points up.",
        "It has a smooth, short and dense coat in a black and white spotted pattern.",
        "The dog's overall appearance is fluffy, with black and white facial and body markings."
    ]
}


English Setter_50
{
"Dalmatian, Basset Hound, English Pointer": [
"The dog in the photo is looking at the camera and has a long body with a medium size.",
"It has a spherical head with large facial wrinkles on its face.",
"The dog has a short neck and short, straight legs with thin, square paws and square toes.",
"It has a stub tail that is tucked.",
"The dog's coat is tan and white in color with a short, smooth, and spotted texture. It has soft and fluffy fur that is short and dense."
]
}


Pug_51
{
   "Pug, Bulldog, Boston Terrier": [
      "The dog in the photo is a small-sized pug with a short body and head.",
      "It has facial wrinkles and a short neck.",
      "The legs are stubby and thin, with small square paws and square toes.",
      "The dog has a short and stubby tail that is tucked under its body.",
      "Its coat is tan and white, with a smooth texture."
   ]
}


Pug_52
{
  "Pug, Bulldog, Boxer": [
    "The photo shows a small pug dog with a square body shape.",
    "It has a round head with a short muzzle and lots of facial wrinkles.",
    "The dog has short legs and a thick leg shape.",
    "Its paws are small and round, and it is sitting in the grass.",
    "The pug has a stubby tail and a short, smooth coat with a black and tan coloration."
  ]
}


Pug_53
{
    "Pug": [
        "The dog in the photo is a small, pug breed with a square body shape and short legs.",
        "It has a short, smooth coat in tan and black colors.",
        "The dog has facial wrinkles, round brown eyes, and floppy ears.",
        "Its tail is stubby and tucked, and it has a snub nose with a black color.",
        "The overall appearance of the dog is fluffy, and it has breed-specific markings including a black nose."
    ],
    "Pug Dog": [
        "The dog in the photo is a small, pug breed with a square body shape and short legs.",
        "It has a short, smooth coat in tan and black colors.",
        "The dog has facial wrinkles, round brown eyes, and floppy ears.",
        "Its tail is stubby and tucked, and it has a snub nose with a black color.",
        "The overall appearance of the dog is fluffy, and it has breed-specific markings including a black nose."
    ],
    "Small Pug": [
        "The dog in the photo is a small, pug breed with a square body shape and short legs.",
        "It has a short, smooth coat in tan and black colors.",
        "The dog has facial wrinkles, round brown eyes, and floppy ears.",
        "Its tail is stubby and tucked, and it has a snub nose with a black color.",
        "The overall appearance of the dog is fluffy, and it has breed-specific markings including a black nose."
    ]
}


Newfoundland_54
{
  "Bulldog, Boxer, Boston Terrier": [
    "The dog in the photo is a large and muscular dog with a snub nose and wrinkles on its face.",
    "It has short legs and a stubby tail that is tucked under its body.",
    "The dog has a brown coat that is short and curly, with soft and fluffy fur.",
    "Its eyes are round and brown, and it has floppy ears that are pointing forward.",
    "The dog also has a black snub nose and a white chest."
  ]
}


Newfoundland_55
{
   "Golden Retriever, Labrador Retriever, Bernese Mountain Dog": [
      "The dog in the photo is a large brown dog with a snout and a lot of wrinkles.",
      "It has a short neck, short legs, and slender legs with thick paws and square toes.",
      "The tail is stubby and wagging.",
      "Its coat is long, fluffy, and brown with a tan and brown pattern.",
      "The dog has round brown eyes, floppy ears, and a square muzzle."
   ]
}


Newfoundland_56
{
    "Tibetan Mastiff, Newfoundland, Leonberger": [
        "The dog in the photo is a large brown dog with a long, fluffy coat.",
        "It has a large head with facial wrinkles and round eyes.",
        "The dog has a short tail that is wagging, and its overall body shape is large and fluffy.",
        "The dog has a square muzzle, floppy ears, and a long snout.",
        "Its legs are short and slender with thick paws and square toes."
    ]
}


American Bulldog_57
{
    "Boxer, Bulldog, Boston Terrier": [
        "The dog in the photo is a large Boxer with a muscular body.",
        "It has a short, square-shaped head with a lot of wrinkles on its face.",
        "The dog has a short neck and short legs with thick, square-shaped paws.",
        "Its coat is short and smooth, with a white and brown color pattern.",
        "The dog has round brown eyes and floppy ears that are pinned back."
    ]
}


American Bulldog_58
{
    "Dalmatian, Boxer, Pointer": [
        "The dog in the photo is a large, muscular dog with a slender body and a short tail.",
        "It has a snub-nosed face with a square muzzle and erect ears.",
        "The dog has a smooth white and black coat with short and dense fur.",
        "It has round brown eyes and a black nose.",
        "The overall appearance of the dog is muscular, and it has white markings with black spots on its body."
    ]
}


American Bulldog_59
{
   "Dalmatian": [
      "The photo shows a man holding a small, fluffy puppy with a white coat and black spots.",
      "The puppy has a snub nose, short legs, and a stubby tail that is tucked under.",
      "It has round brown eyes and erect ears.",
      "The puppy's overall body shape is rectangular, and it has a soft and dense fur texture."
   ],
   "Bichon Frise": [
      "The photo shows a man holding a small, fluffy puppy with a white coat and black spots.",
      "The puppy has a snub nose, short legs, and a stubby tail that is tucked under.",
      "It has round brown eyes and erect ears.",
      "The puppy's overall body shape is rectangular, and it has a soft and dense fur texture."
   ],
   "Jack Russell Terrier": [
      "The photo shows a man holding a small, fluffy puppy with a white coat and black spots.",
      "The puppy has a snub nose, short legs, and a stubby tail that is tucked under.",
      "It has round brown eyes and erect ears.",
      "The puppy's overall body shape is rectangular, and it has a soft and dense fur texture."
   ]
}


Abyssinian_60
{
  "Bengal": [
    "The cat in the photo is small with a long body and a round head.",
    "It has a short neck and slender legs with thin paws.",
    "The cat has a short and fluffy brown and white spotted coat.",
    "Its eyes are round and blue, and it has a short snout with a snub nose.",
    "The cat has a stubby tail that points down."
  ],
  "Exotic Shorthair": [
    "The cat in the photo is small with a long body and a round head.",
    "It has a short neck and slender legs with thin paws.",
    "The cat has a short and fluffy brown and white spotted coat.",
    "Its eyes are round and blue, and it has a short snout with a snub nose.",
    "The cat has a stubby tail that points down."
  ],
  "British Shorthair": [
    "The cat in the photo is small with a long body and a round head.",
    "It has a short neck and slender legs with thin paws.",
    "The cat has a short and fluffy brown and white spotted coat.",
    "Its eyes are round and blue, and it has a short snout with a snub nose.",
    "The cat has a stubby tail that points down."
  ]
}


Abyssinian_61
{
    "British Shorthair, American Shorthair, Exotic Shorthair": [
        "The cat in the photo is medium-sized with a round body shape and small head.",
        "It has a short, round tail and its fur is short, fluffy, and tabby-patterned with brown and black colors.",
        "The cat has round blue eyes and a snub nose with a black color.",
        "Its ears are pointed forward and rounded in shape.",
        "The cat has a sleek overall appearance and a white nose."
    ]
}


Abyssinian_62
{
    "American Shorthair, British Shorthair, Russian Blue": [
        "The cat in the photo is small with a slender body and round head.",
        "It has a short neck, thin legs, and small paws with a rounded shape.",
        "The cat has a long, slender tail pointing upward.",
        "Its fur is gray with a spotted pattern and short, fluffy texture.",
        "The cat has round blue eyes and erect ears."
    ]
}


Beagle_63
{
   "Beagle, Dachshund, Boston Terrier": [
      "A young girl is holding a small dog in front of a mirror.",
      "The dog has a long body and a small, square-shaped head.",
      "Its coat is black and white, with a smooth texture and a pattern similar to that of a beagle.",
      "The dog has soft, short and dense fur.",
      "The overall appearance of the dog is fluffy, with black and white facial and body markings."
   ]
}


Beagle_64
{
   "Dachshund": [
      "The dog in the photo is a small breed with a long body and a square head.",
      "It has short legs and a thin build.",
      "The dog has round brown eyes and a short snout with a snub nose.",
      "Its ears are floppy and tucked.",
      "The coat is short, brown and white in color, with a smooth texture."
   ],
   "Basset Hound": [
      "The dog in the photo is a small breed with a long body and a square head.",
      "It has short legs and a thin build.",
      "The dog has round brown eyes and a short snout with a snub nose.",
      "Its ears are floppy and tucked.",
      "The coat is short, brown and white in color, with a smooth texture."
   ],
   "Boston Terrier": [
      "The dog in the photo is a small breed with a long body and a square head.",
      "It has short legs and a thin build.",
      "The dog has round brown eyes and a short snout with a snub nose.",
      "Its ears are floppy and tucked.",
      "The coat is short, brown and white in color, with a smooth texture."
   ]
}


Beagle_65
{
    "Beagle, Dachshund, Basset Hound": [
        "The dog in the photo has a small body and a hound-like head shape.",
        "It has short, thin legs with small round paws.",
        "The dog's coat is brown and white, with a smooth texture.",
        "It has round brown eyes, floppy ears, and a snub nose.",
        "The dog's tail is short and tucked under its body."
    ]
}


Bengal_66
{
    "Bengal, American Shorthair, Egyptian Mau": [
        "The cat in the photo is small with a long body and a round head.",
        "It has a snout with a short nose and round blue eyes.",
        "The cat has a short and dense coat that is striped and its fur texture is soft.",
        "It has a short tail that is stubby and pointing to the left.",
        "The cat has round paws with round toes and slender legs."
    ]
}


Bengal_67
{
    "Bengal, Tabby, Domestic Shorthair": [
        "The cat in the photo is a Bengal cat with a slender body, short tail, and snub nose.",
        "It has a squinty expression and a short, dense coat with a tabby pattern.",
        "The cat's overall appearance is sleek, and it has round blue eyes.",
        "It also has distinctive facial markings, including a white nose and a black mask.",
        "The cat is likely a mix of Bengal, Tabby, and Domestic Shorthair breeds."
    ]
}


Bengal_68
{
"Scottish Fold, Bengal, American Shorthair": [
"A cat is laying on a bed",
"The cat is small in size with a long body and a round head",
"It has a spotted tan and black coat that is short and fluffy",
"The cat has round blue eyes and erect ears with a snub nose",
"The legs are short and slender, with small paws and round toes"
]
}


American Pit Bull Terrier_69
{
    "Dachshund, American Bulldog, Boxer": [
        "The dog in the photo is a brown dog with a muscular body lying on the grass.",
        "It has a long body, short tail, and a snub nosed large head with a wrinkly face.",
        "The dog has a short neck, short legs with a slender shape and thick leg thickness.",
        "Its paws are medium-sized with a shape resembling that of a dachshund.",
        "The dog has a splayed toe and a stubby tail.",
    ]
}


Failed to decode JSON for key: American Pit Bull Terrier_69
American Pit Bull Terrier_70
{
  "Hound mix": [
    "The dog in the photo is a medium-sized dog with a long body and a short tail.",
    "It has a snub-nosed head and a large head size.",
    "The dog's facial wrinkles are in the form of a snout.",
    "It has a short neck and short legs with a slender leg shape and thick legs.",
    "The paw size of the dog is medium and the paw shape is typical of a dog."
  ],
  "Labrador Retriever": [
    "The dog in the photo is a medium-sized dog with a long body and a short tail.",
    "It has a snub-nosed head and a large head size.",
    "The dog's facial wrinkles are in the form of a snout.",
    "It has a short neck and short legs with a slender leg shape and thick legs.",
    "The paw size of the dog is medium and the paw shape is typical of a dog."
  ],
  "Boxer": [
    "The dog in the photo is a medium-sized dog with a long body and a short tail.",
    "It has a snub-nosed head and a large head size.",
    "The dog's facial wrinkles are in the form of a snout.",
    "It has a short neck and short legs with a slender leg shape and thick legs.",
    "The paw size of the dog is medium and the paw shape is typical of a dog."
  ]
}


American Pit Bull Terrier_71
{
    "Pit Bull Terrier, Boxer, Bulldog": [
        "The dog in the photo is a medium-sized dog with a square body shape and short, thick legs.",
        "It has a large head with a snub nose and wrinkled forehead.",
        "The dog has a short, stubby tail that is tucked under its body.",
        "Its coat is brown and white, with a tan and white pattern and a white chest.",
        "The dog is a white and brown pit bull terrier with a muscular appearance."
    ]
}


Siamese_72
{"Siamese, Exotic Shorthair, British Shorthair": [
  "The cat in the photo is small with a round body shape and a large round head.",
  "It has wrinkles on its face, short legs, and a slender tail.",
  "The cat has brown and white short and fluffy fur, with a striped pattern.",
  "Its eyes are round and blue, and its ears are pinned back.",
  "Overall, the cat has a long and slender body shape and a fluffy appearance."
]}


Siamese_73
{
    "Siamese, Oriental Shorthair, Colorpoint Shorthair": [
        "The cat in the photo is a Siamese cat with blue eyes.",
        "It has a medium-sized body, a large round head, and a short neck.",
        "The cat has a squinty look with facial wrinkles.",
        "Its legs are short and slender with thin paws.",
        "The tail is slender and short, pointing to the right."
    ]
}


Siamese_74
{
   "Siamese": [
      "The cat in the photo is small with a round body shape and a large head.",
      "It has wrinkles on its face and a short neck.",
      "Its legs are short and slender with thin paws.",
      "The cat has a short and fluffy coat with brown and white color.",
      "It has round blue eyes and round ears that are pinned back."
   ],
   "British Shorthair": [
      "The cat in the photo is small with a round body shape and a large head.",
      "It has wrinkles on its face and a short neck.",
      "Its legs are short and slender with thin paws.",
      "The cat has a short and fluffy coat with brown and white color.",
      "It has round blue eyes and round ears that are pinned back."
   ],
   "Scottish Fold": [
      "The cat in the photo is small with a round body shape and a large head.",
      "It has wrinkles on its face and a short neck.",
      "Its legs are short and slender with thin paws.",
      "The cat has a short and fluffy coat with brown and white color.",
      "It has round blue eyes and round ears that are pinned back."
   ]
}


Basset Hound_75
{
  "Basset Hound, Dachshund, Beagle": [
    "The dog in the photo is a medium-sized dog with a long body and short legs.",
    "It has a large head with a square muzzle and short snout.",
    "The dog has a muscular build and a smooth, short coat that is brown and white in color.",
    "It has round brown eyes and floppy ears that are pinned back.",
    "The dog also has facial wrinkles and a stub tail that is tucked under the chair."
  ]
}


Basset Hound_76
{
  "Basset Hound, Bloodhound, Beagle": [
    "The dog in the photo is a basset hound with a medium-sized body and a small head.",
    "It has a wrinkly nose and a short neck.",
    "The dog has short legs and slender, thin paws.",
    "Its coat is short, smooth, and brown and white in color.",
    "The dog has a stub tail that is tucked under its body."
  ]
}


Basset Hound_77
{
  "Beagle, Hound, Terrier": [
    "The dog in the photo is a beagle with a medium body size.",
    "It has a small head and facial wrinkles, along with a short neck and short legs.",
    "Its paw size is small with square paws and square toes.",
    "The dog has a stubby tail that is wagging.",
    "Its coat is short, smooth, and brown and white in color."
  ]
}


Miniature Pinscher_78
{
    "Pinscher, Miniature Pinscher, Doberman Pinscher": [
        "The dog in the photo is a small black and tan dog with a sleek and smooth coat.",
        "It has a short body, straight legs, and a long tail that is tucked.",
        "The dog has a snub-nosed muzzle and round brown eyes.",
        "It has a wrinkly nose and forehead, and its ears are erect with rounded tips.",
        "The dog has breed-specific markings of a black and tan pinscher, with a black nose and white chest."
    ]
}


Miniature Pinscher_79
{
    "Miniature Pinscher, Doberman Pinscher, Manchester Terrier": [
        "The dog in the photo is a small black and tan dog of the miniature pinscher breed.",
        "It has a snub-nosed head and small, round eyes.",
        "The dog has a short, smooth coat that is black and tan in color, and it has some white markings on its chest.",
        "Its legs are slender and it has thick legs and small paws.",
        "The dog is sitting on a chair with its tail tucked under its body."
    ]
}


Miniature Pinscher_80
{```json
{
  "Fox Terrier, Poodle, Dachshund": [
    "The dog in the photo is a small dog with a long body and short legs.",
    "It has a fox terrier head and a wrinkly face.",
    "The dog has a neck length of about 15 inches and short legs with a slender shape and thickness.",
    "Its paw size is small and shaped like a fox.",
    "The dog has a short, tan and white coat with a smooth texture."
  ]
}
```}


Failed to decode JSON for key: Miniature Pinscher_80
Pomeranian_81
{
   "Dachshund":[
      "The dog in the photo is a small breed with a long body and short legs.",
      "It has a snub nose and a small head with wrinkly facial features.",
      "The dog has a short and dense coat that is white and brown in color, with some wavy patterns.",
      "Its ears are erect and pinned back, and it has a stub tail that is wagging.",
      "The dog has a fluffy appearance, with white markings on its nose, chin, chest, paws, and the rest of its body."
   ],
   "French Bulldog":[
      "The dog in the photo is a small breed with a long body and short legs.",
      "It has a snub nose and a small head with wrinkly facial features.",
      "The dog has a short and dense coat that is white and brown in color, with some wavy patterns.",
      "Its ears are erect and pinned back, and it has a stub tail that is wagging.",
      "The dog has a fluffy appearance, with white markings on its nose, chin, chest, paws, and the rest of its body."
   ],
   "Basset Hound":[
      "The dog in the photo is a small breed with a long body and short legs.",
      "It has a snub nose and a small head with wrinkly facial features.",
      "The dog has a short and dense coat that is white and brown in color, with some wavy patterns.",
      "Its ears are erect and pinned back, and it has a stub tail that is wagging.",
      "The dog has a fluffy appearance, with white markings on its nose, chin, chest, paws, and the rest of its body."
   ]
}


Pomeranian_82
{
    "Bichon Frise": [
        "This photo shows a small dog with long, curly black and white fur.",
        "It has a snub nose and round brown eyes.",
        "The dog has a wrinkly face and floppy ears, with its ears pinned back.",
        "It has a medium-length, fluffy coat and a long, stub tail.",
        "The overall appearance of the dog is fluffy and it has a slender body with short legs."
    ],
    "Cocker Spaniel": [
        "This photo shows a small dog with long, curly black and white fur.",
        "It has a snub nose and round brown eyes.",
        "The dog has a wrinkly face and floppy ears, with its ears pinned back.",
        "It has a medium-length, fluffy coat and a long, stub tail.",
        "The overall appearance of the dog is fluffy and it has a slender body with short legs."
    ],
    "Shih Tzu": [
        "This photo shows a small dog with long, curly black and white fur.",
        "It has a snub nose and round brown eyes.",
        "The dog has a wrinkly face and floppy ears, with its ears pinned back.",
        "It has a medium-length, fluffy coat and a long, stub tail.",
        "The overall appearance of the dog is fluffy and it has a slender body with short legs."
    ]
}


Pomeranian_83
{
    "Pug, Boston Terrier, French Bulldog": [
        "The dog in the photo is a small dog with a short body and a long tail.",
        "It has a snub nose and small head, with facial wrinkles on its face.",
        "The dog has a fluffy coat with a wavy texture and is brown and white in color.",
        "It has round brown eyes and erect ears.",
        "The dog has a stubby tail that is wagging."
    ]
}


Russian Blue_84
{
    "British Shorthair, American Shorthair, Russian Blue": [
        "The cat in the photo is sitting in the grass.",
        "It has a long body, medium size, round head, large head size, and facial wrinkles from wearing a harness.",
        "The cat has a short neck, short legs, slender leg shape, thin leg thickness, and large round paws.",
        "It has a stubby tail, short tail length, and the tail is pointing to the left.",
        "The cat's coat is gray in color, short in length, and has a fluffy texture."
    ]
}


Russian Blue_85
{
    "Maine Coon, British Shorthair, Scottish Fold": [
        "The cat in the photo is medium-sized with a long body.",
        "It has a round head and a large head size.",
        "The cat also has facial wrinkles on its face.",
        "The cat is laying on a wooden desk.",
        "It seems to be a relaxed and comfortable cat."
    ]
}


Russian Blue_86
{
    "British Shorthair, Russian Blue, American Shorthair": [
        "The cat in the photo is a medium-sized gray cat with a round body shape.",
        "It has a large round head with a short snout and a snub nose.",
        "The cat has blue eyes and rounded ears that are pointing forward.",
        "It has short, dense, and fluffy gray fur with a solid gray color and a sleek overall appearance.",
        "The cat has a stubby tail pointing to the left and round paws."
    ]
}


Scottish Terrier_87
{
    "Scottish Terrier, Cairn Terrier, West Highland White Terrier": [
        "The dog in the photo is a black Scottish Terrier with a small and slender body.",
        "It has a short and squarish overall body shape, with a fluffy and rough coat.",
        "The dog has round brown eyes and a short snout with a snub nose.",
        "Its ears are up and have the shape of a Scottish Terrier.",
        "The dog has a short tail that is wagging."
    ]
}


Scottish Terrier_88
{
    "Scottish Terrier, Boston Terrier, Border Terrier": [
        "The dog in the photo is a small, black dog with a spherical body shape and short legs.",
        "It has a small head with a Scottish Terrier shape, round brown eyes, and a square muzzle.",
        "The dog has a short, smooth coat that is black in color and fluffy in texture.",
        "It has a short tail that is tucked under the body and a snub nose.",
        "The overall appearance of the dog is fluffy and it has black and white markings on its body and face."
    ]
}


Scottish Terrier_89
{
    "Scottish Terrier, West Highland White Terrier, Bichon Frise": [
        "The dog in the photo is a small and slender dog with a short and squarish body.",
        "It has a small head with scottish terrier features, including facial wrinkles and square-shaped ears.",
        "The dog has a short and fluffy white coat with black markings on its nose and body, and a short and curly coat pattern.",
        "It has round brown eyes and a snub nose.",
        "The dog has a short tail that is tucked under its body and square-shaped paws with square toes."
    ]
}


Samoyed_90
{
  "Samoyed, Bichon Frise, Jack Russell Terrier": [
    "The dog in the photo is small in size with a spherical body and head.",
    "It has short legs and a fluffy white coat with a sable pattern.",
    "The dog has a short tail that is tucked under the blanket.",
    "It has round brown eyes and erect ears.",
    "The overall appearance of the dog is fluffy, and it has facial and body markings of white with black spots."
  ]
}


Samoyed_91
{
"Samoyed, Eskimo Dog, Spitz": [
"The dog in the photo is a small, spitz type dog with a Samoyed head shape. It has a short, fluffy and dense white coat with black markings on its chest and legs.",
"The dog has a small body size, short legs, and a medium-sized paw. Its tail is long and tucked under its body.",
"The dog has a wrinkly nose and forehead, and its ears are pinned back. It has blue eyes and a snub black nose.",
"Overall, it has a fluffy appearance with a black collar.",
"The dog has a white coat with black markings on the chest and legs."
]
}


Samoyed_92
{
    "Bulldog, Samoyed, Bichon Frise": [
        "The dog in the photo is a large, spherical-headed dog with a lot of wrinkles.",
        "It has a short neck and legs, with thin and straight legs.",
        "The dog has large square paws and a stout, short tail that is tucked under.",
        "Its coat is white, short, and fluffy, with a dense fur texture.",
        "The dog has round brown eyes and an eskimo-shaped ear."
    ]
}


British Shorthair_93
{
  "British Shorthair, Bengal, American Bobtail": [
    "The cat in the photo is a large, long-bodied cat with a round head and a squinty face.",
    "It has a short neck, short legs, and slender, thin legs.",
    "The paws are large and round, with rounded toes.",
    "The cat has a short tail that points up, and a gray, short and fluffy coat with a spotted pattern.",
    "The fur is soft and short, and the eyes are round and yellow."
  ]
}


British Shorthair_94
{
    "British Blue, Russian Blue, Korat": [
        "The cat in the photo is large with a long body and a round head.",
        "It has a short neck and legs, with slender and thin proportions.",
        "The paw size is large, with round-shaped paws and splayed toes.",
        "The tail is slender and short, pointing upward.",
        "The coat is short, fluffy, and gray in color, with soft and dense fur."
    ]
}


British Shorthair_95
{
  "British Shorthair, Scottish Fold, American Wirehair": [
    "The photo shows a woman holding a small, gray cat with a long body and a round, large head.",
    "The cat has wrinkles on its face and a short neck.",
    "Its legs are short and slender, with thin paws that are round in shape.",
    "The cat has splayed toes and a stubby tail pointing upward.",
    "Its coat is short, fluffy, and of a solid gray color with a striped pattern."
  ]
}


Persian_96
{
    "Persian Cat, Exotic Shorthair, British Shorthair": [
        "The cat in the photo is large with a long body and round, large head. It has wrinkles on its face, short neck, and slender, thin legs.",
        "Its paws are large and round with rounded toes. The cat has a stubby tail that is pointing up.",
        "Its orange coat is short, fluffy, and has a persian cat pattern. The fur is long and dense, and the cat has round blue eyes.",
        "The ears are erect and pinned back, and it has a short snout with a black nose. The overall body shape is round, and the cat has facial markings and a white belly.",
        "The whiskers are short and tipped, and the claws are long and curved."
    ]
}


Persian_97
{
    "Persian Cat": [
        "This cat is large in size with a long body and a very large head.",
        "It has a snub nose and a squinty face with short legs and a slender leg shape.",
        "The paws are large with a rounded shape and the toes are splayed.",
        "The tail is stubby and tucked under the body.",
        "The cat has a short, fluffy coat with orange and white coloration."
    ],
    "Maine Coon": [
        "This cat is large in size with a long body and a very large head.",
        "It has a snub nose and a squinty face with short legs and a slender leg shape.",
        "The paws are large with a rounded shape and the toes are splayed.",
        "The tail is stubby and tucked under the body.",
        "The cat has a short, fluffy coat with orange and white coloration."
    ],
    "Ragdoll": [
        "This cat is large in size with a long body and a very large head.",
        "It has a snub nose and a squinty face with short legs and a slender leg shape.",
        "The paws are large with a rounded shape and the toes are splayed.",
        "The tail is stubby and tucked under the body.",
        "The cat has a short, fluffy coat with orange and white coloration."
    ]
}


Persian_98
{
  "Persian, Maine Coon, Siberian": [
    "The cat in the photo is large with a long and slender body.",
    "It has a large head with a slender snout and round blue eyes.",
    "The cat has short legs with thin and slender paws.",
    "Its fur is long, fluffy, and golden brown in color.",
    "The cat has a tan and white coat with a white tipped tail."
  ]
}


Havanese_99
{
  "Poodle, Bichon Frise, Maltese": [
    "The photo shows a woman holding a small dog with a poodle body shape and small head size.",
    "The dog has a short neck, short legs, and slender leg shape with small square paws and square toes.",
    "Its tail is short and tucked under the dog, and its coat is white, fluffy, and short in length.",
    "The dog has round brown eyes, floppy ears, and a square muzzle with a short snout.",
    "It has a snub nose with a black color and a short and stubby overall body shape and proportion. The dog has breed-specific markings with a white coat and black nose, and it has no facial markings but has white body markings with black spots."
  ]
}


Havanese_100
{
    "Bichon Frise, Pomeranian, Shih Tzu": [
        "The dog in the photo is small in size with a spherical body shape and a fluffy, short coat that is white and gray in color.",
        "It has a small, spherical head with a snout, round brown eyes, and floppy ears.",
        "The dog has a square muzzle, a short snout, and a snub nose.",
        "It has a rectangular body shape and proportion, and its tail is stubby and wagging.",
        "The dog has a soft, short and dense fur texture, and its overall appearance is fluffy with breed-specific markings of two dogs sitting on the grass."
    ]
}


Havanese_101
{
"Poodle, Bichon Frise, West Highland White Terrier": [
"The dog in the photo is small in size with a spherical body shape and a small spherical head.",
"It has a short neck and short legs that are slender and thin.",
"The paws are small and round with splayed toes.",
"The dog has a short, fluffy coat that is white and gray in color.",
"It has a stubby tail that is tucked under."
]
}


Chihuahua_102
{
  "Pug, French Bulldog, Bichon Frise": [
    "The dog in the photo is a small, white dog with a snub-nosed head and a lot of facial wrinkles.",
    "It has a short body with slender legs and thin paws.",
    "The dog has a short tail that is tucked under the chair.",
    "Its coat is white with a black nose and has a smooth texture.",
    "The dog has round brown eyes and erect ears."
  ]
}


Chihuahua_103
{
    "Chihuahua, Toy Fox Terrier, Pomeranian": [
        "The photo shows a small chihuahua dog wearing a colorful necklace.",
        "It has a short neck, short legs, and a tucked under tail.",
        "The dog has a brown coat with a smooth texture, and its fur is short and dense.",
        "It has round brown eyes and a snub nose.",
        "The ears are pinned back, and overall, the dog has a fluffy appearance."
    ]
}


Chihuahua_104
{"Chihuahua, Miniature Pinscher, Italian Greyhound": ["The photo shows a small gray Chihuahua puppy standing on a rug.", "The dog has a small body and head, with a slender leg shape and thick legs.", "Its coat is short and smooth, with a light gray color and a few white spots on the chest and belly.", "The dog has a snub nose, round eyes, and pinned back ears.", "Overall, the dog has a sleek and muscular appearance."]}


Staffordshire Bull Terrier_105
{
    "Boxer, Hound, Bulldog": [
        "The dog in the photo is a large boxer with a muscular body.",
        "It has a square head, short neck, and short legs.",
        "The dog has a stubby tail that is wagging.",
        "Its coat is black and brown, with a hound pattern, and it has a smooth texture.",
        "The dog has round brown eyes and a snub nose."
    ]
}


Staffordshire Bull Terrier_106
{
    "Boxer, Boston Terrier, Bulldog": [
        "The dog in the photo is a large dog with a square body shape, short legs, and a short tail.",
        "It has a snub nose, round eyes, and erect ears.",
        "The dog's coat is black with white markings, and it has a smooth and short fur texture.",
        "The overall appearance of the dog is muscular and it is standing in a green field."
    ]
}


Staffordshire Bull Terrier_107
{
    "Boston Terrier, French Bulldog, Boxer": [
        "The dog in the photo is small with a square body shape and a large snub nose.",
        "It has short, slender legs with thin, square paws and square toes.",
        "The dog has a short tail that is wagging and a smooth coat that is black and white.",
        "Its eyes are brown and round, and it has floppy ears and a short, square muzzle.",
        "Overall, the dog has a muscular appearance and is black and white in color."
    ]
}


Birman_108
{
    "Siamese, American Shorthair, Maine Coon": [
        "The cat in the photo is a medium-sized cat with a long body and a round head.",
        "It has blue eyes and a short neck.",
        "The cat has short, slender legs with large round paws.",
        "Its tail is slender and short, pointing to the left.",
        "The cat's coat is white and brown, short and fluffy, with a tuxedo pattern."
    ]
}


Birman_109
{
    "Maine Coon, Turkish Angora, British Longhair": [
        "The cat in the photo is long and slender with a medium-sized body.",
        "It has a round head and a small head size.",
        "The cat has long neck and short legs with a slender shape and thin thickness.",
        "Its paws are large and round in shape.",
        "The cat has a long and slender tail that points backwards."
    ]
}


Birman_110
{
    "Siamese, Maine Coon, Ragdoll": [
        "The cat in the photo is a medium-sized cat with a long and slender body, a large round head, and blue eyes.",
        "It has a short neck and short slender legs with thin paws.",
        "The cat has a short and fluffy coat with a tuxedo pattern of brown and white colors.",
        "It has a round snout with a short snub nose and black nose color.",
        "The cat's tail is short and slender, pointing to the right."
    ]
}


==============================
		 Finished Post-processing
==============================
		 ---> total discovered names = 288
['Labrador Retriever', 'Bulldog', 'Boxer', 'Dalmatian', 'Boston Terrier', 'French Bulldog', 'Boxer', 'Pug', 'French Bulldog', 'Bichon Frise', 'Bombay', 'British Shorthair', 'Russian Blue', 'Pug', 'Bulldog', 'Boxer', 'Pug Dog', 'Bulldog', 'Boxer', 'Samoyed', 'Pug', 'French Bulldog', 'Boston Terrier', 'Basset Hound', 'Siamese', 'Oriental Shorthair', 'Colorpoint Shorthair', 'Chihuahua', 'Toy Fox Terrier', 'Rat Terrier', 'Sphynx', 'Devon Rex', 'Bambino', 'Siamese', 'Dalmatian', 'Basset Hound', 'English Pointer', 'Small Pug', 'Miniature Pinscher', 'Doberman Pinscher', 'Manchester Terrier', 'American Shorthair', 'British Shorthair', 'Russian Blue', 'Bengal', 'American Shorthair', 'Egyptian Mau', 'Egyptian Mau', 'Exotic Shorthair', 'British Shorthair', 'Ragdoll', 'Boxer', 'Bullmastiff', 'Rottweiler', 'Siamese', 'Maine Coon', 'Ragdoll', 'Scottish Fold', 'Bengal', 'American Shorthair', 'Boston Terrier', 'Labrador Retriever', 'Boxer', 'Saint Bernard', 'Yorkshire Terrier', 'Yorkie', 'Small Terrier', 'Maine Coon', 'Turkish Angora', 'British Longhair', 'Mastiff', 'St. Bernard', 'Newfoundland', 'Bernese Mountain Dog', 'Pinscher', 'Miniature Pinscher', 'Doberman Pinscher', 'Scottish Terrier', 'Cairn Terrier', 'West Highland White Terrier', 'Chow Chow', 'Shiba Inu', 'Asian Samoyed', 'Labrador Retriever', 'Shiba Inu', 'Shih Tzu', 'Bulldog', 'Persian Cat', 'Poodle', 'Dalmatian', 'Bulldog', 'Bengal', 'Shiba Inu', 'Shih Tzu', 'Pekingese', 'Bichon Frise', 'Jack Russell Terrier', 'Siamese', 'American Shorthair', 'Maine Coon', 'Poodle', 'Bichon Frise', 'West Highland White Terrier', 'Sphynx', 'Devon Rex', 'Peterbald', 'Boxer', 'Bulldog', 'Boston Terrier', 'Scottish Fold', 'Golden Retriever', 'Labrador Retriever', 'Bernese Mountain Dog', 'British Shorthair', 'Bengal', 'American Bobtail', 'Siamese', 'Exotic Shorthair', 'British Shorthair', 'Pug', 'Bulldog', 'Boston Terrier', 'Pointer', 'Dalmatian', 'Boston Terrier', 'Scottish Terrier', 'Boston Terrier', 'Border Terrier', 'Yorkshire Terrier', 'Shih Tzu', 'Maltese', 'Pug', 'Boston Terrier', 'French Bulldog', 'Bulldog', 'Boxer', 'Boston Terrier', 'Chihuahua', 'Toy Fox Terrier', 'Pomeranian', 'Maine Coon', 'British Shorthair', 'Scottish Fold', 'Dalmatian', 'Basset Hound', 'Bloodhound', 'Beagle', 'Boxer', 'Boston Terrier', 'Bulldog', 'Basset Hound', 'Dachshund', 'Beagle', 'St. Bernard', 'Mastiff', 'Boxer', 'Beagle', 'Hound', 'Terrier', 'Bengal', 'Abyssinian', 'Egyptian Mau', 'Yorkshire Terrier', 'Yorkie', 'Silky Terrier', 'Chihuahua', 'Bichon Frise', 'Pomeranian', 'Shih Tzu', 'St. Bernard', 'Bernese Mountain Dog', 'Greater Swiss Mountain Dog', 'Bulldog', 'Maine Coon', 'Bengal', 'Tabby', 'Domestic Shorthair', 'Hound mix', 'Ragdoll', 'Poodle', 'Bichon Frise', 'Maltese', 'Samoyed', 'Eskimo Dog', 'Spitz', 'Bichon Frise', 'Samoyed', 'Bichon Frise', 'Jack Russell Terrier', 'Beagle', 'Dachshund', 'Boston Terrier', 'English Cocker Spaniel', 'Beagle', 'Dachshund', 'Basset Hound', 'Tibetan Mastiff', 'Newfoundland', 'Leonberger', 'Dalmatian', 'Boston Terrier', 'French Bulldog', 'Pomeranian', 'Maine Coon', 'Norwegian Forest Cat', 'Siberian Cat', 'British Shorthair', 'British Shorthair', 'Russian Blue', 'American Shorthair', 'Bulldog', 'Samoyed', 'Bichon Frise', 'Possible Cat Breeds', 'Shih Tzu', 'Russian Blue', 'Boxer', 'Bulldog', 'Pitbull', 'Siberian', 'British Shorthair', 'Scottish Fold', 'American Wirehair', 'Boxer', 'Hound', 'Bulldog', 'Sphynx', 'Devon Rex', 'Cornish Rex', 'Siamese', 'Scottish Fold', 'British Shorthair', 'British Shorthair', 'American Shorthair', 'Exotic Shorthair', 'Hound', 'Boxer', 'Dalmatian', 'Chihuahua', 'Miniature Pinscher', 'Italian Greyhound', 'Pointer', 'Dalmatian', 'Beagle', 'Exotic Shorthair', 'Boxer', 'American Cocker Spaniel', 'Cairn Terrier', 'Cocker Spaniel', 'Dachshund', 'Basset Hound', 'Pit Bull Terrier', 'Boxer', 'Bulldog', 'Persian Cat', 'Exotic Shorthair', 'British Shorthair', 'Dalmatian', 'Boxer', 'Pointer', 'Siamese', 'Bengal', 'Abyssinian', 'Basset Hound', 'Bulldog', 'Boston Terrier', 'Pug', 'Dachshund', 'British Blue', 'Russian Blue', 'Korat', 'British Shorthair', 'American Shorthair', 'Russian Blue', 'Dalmatian', 'English Setter', 'Bull Terrier', 'Persian', 'Maine Coon', 'Siberian', 'Cocker Spaniel', 'Chihuahua', 'Jack Russell Terrier', 'Pomeranian', 'Scottish Terrier', 'West Highland White Terrier', 'Bichon Frise', 'French Bulldog']

		 ---> total discovered names = 288
		 ---> number of failure entries = 4
END==============================

Namespace(config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', alpha=0.7, N_tta=10, num_per_category='3', num_runs=10)
Number of GPUs: 1
Device ID: 0 Device Name: NVIDIA RTX A6000
['Labrador Retriever', 'Bulldog', 'Boxer', 'Dalmatian', 'Boston Terrier', 'French Bulldog', 'Boxer', 'Pug', 'French Bulldog', 'Bichon Frise', 'Bombay', 'British Shorthair', 'Russian Blue', 'Pug', 'Bulldog', 'Boxer', 'Pug Dog', 'Bulldog', 'Boxer', 'Samoyed', 'Pug', 'French Bulldog', 'Boston Terrier', 'Basset Hound', 'Siamese', 'Oriental Shorthair', 'Colorpoint Shorthair', 'Chihuahua', 'Toy Fox Terrier', 'Rat Terrier', 'Sphynx', 'Devon Rex', 'Bambino', 'Siamese', 'Dalmatian', 'Basset Hound', 'English Pointer', 'Small Pug', 'Miniature Pinscher', 'Doberman Pinscher', 'Manchester Terrier', 'American Shorthair', 'British Shorthair', 'Russian Blue', 'Bengal', 'American Shorthair', 'Egyptian Mau', 'Egyptian Mau', 'Exotic Shorthair', 'British Shorthair', 'Ragdoll', 'Boxer', 'Bullmastiff', 'Rottweiler', 'Siamese', 'Maine Coon', 'Ragdoll', 'Scottish Fold', 'Bengal', 'American Shorthair', 'Boston Terrier', 'Labrador Retriever', 'Boxer', 'Saint Bernard', 'Yorkshire Terrier', 'Yorkie', 'Small Terrier', 'Maine Coon', 'Turkish Angora', 'British Longhair', 'Mastiff', 'St. Bernard', 'Newfoundland', 'Bernese Mountain Dog', 'Pinscher', 'Miniature Pinscher', 'Doberman Pinscher', 'Scottish Terrier', 'Cairn Terrier', 'West Highland White Terrier', 'Chow Chow', 'Shiba Inu', 'Asian Samoyed', 'Labrador Retriever', 'Shiba Inu', 'Shih Tzu', 'Bulldog', 'Persian Cat', 'Poodle', 'Dalmatian', 'Bulldog', 'Bengal', 'Shiba Inu', 'Shih Tzu', 'Pekingese', 'Bichon Frise', 'Jack Russell Terrier', 'Siamese', 'American Shorthair', 'Maine Coon', 'Poodle', 'Bichon Frise', 'West Highland White Terrier', 'Sphynx', 'Devon Rex', 'Peterbald', 'Boxer', 'Bulldog', 'Boston Terrier', 'Scottish Fold', 'Golden Retriever', 'Labrador Retriever', 'Bernese Mountain Dog', 'British Shorthair', 'Bengal', 'American Bobtail', 'Siamese', 'Exotic Shorthair', 'British Shorthair', 'Pug', 'Bulldog', 'Boston Terrier', 'Pointer', 'Dalmatian', 'Boston Terrier', 'Scottish Terrier', 'Boston Terrier', 'Border Terrier', 'Yorkshire Terrier', 'Shih Tzu', 'Maltese', 'Pug', 'Boston Terrier', 'French Bulldog', 'Bulldog', 'Boxer', 'Boston Terrier', 'Chihuahua', 'Toy Fox Terrier', 'Pomeranian', 'Maine Coon', 'British Shorthair', 'Scottish Fold', 'Dalmatian', 'Basset Hound', 'Bloodhound', 'Beagle', 'Boxer', 'Boston Terrier', 'Bulldog', 'Basset Hound', 'Dachshund', 'Beagle', 'St. Bernard', 'Mastiff', 'Boxer', 'Beagle', 'Hound', 'Terrier', 'Bengal', 'Abyssinian', 'Egyptian Mau', 'Yorkshire Terrier', 'Yorkie', 'Silky Terrier', 'Chihuahua', 'Bichon Frise', 'Pomeranian', 'Shih Tzu', 'St. Bernard', 'Bernese Mountain Dog', 'Greater Swiss Mountain Dog', 'Bulldog', 'Maine Coon', 'Bengal', 'Tabby', 'Domestic Shorthair', 'Hound mix', 'Ragdoll', 'Poodle', 'Bichon Frise', 'Maltese', 'Samoyed', 'Eskimo Dog', 'Spitz', 'Bichon Frise', 'Samoyed', 'Bichon Frise', 'Jack Russell Terrier', 'Beagle', 'Dachshund', 'Boston Terrier', 'English Cocker Spaniel', 'Beagle', 'Dachshund', 'Basset Hound', 'Tibetan Mastiff', 'Newfoundland', 'Leonberger', 'Dalmatian', 'Boston Terrier', 'French Bulldog', 'Pomeranian', 'Maine Coon', 'Norwegian Forest Cat', 'Siberian Cat', 'British Shorthair', 'British Shorthair', 'Russian Blue', 'American Shorthair', 'Bulldog', 'Samoyed', 'Bichon Frise', 'Possible Cat Breeds', 'Shih Tzu', 'Russian Blue', 'Boxer', 'Bulldog', 'Pitbull', 'Siberian', 'British Shorthair', 'Scottish Fold', 'American Wirehair', 'Boxer', 'Hound', 'Bulldog', 'Sphynx', 'Devon Rex', 'Cornish Rex', 'Siamese', 'Scottish Fold', 'British Shorthair', 'British Shorthair', 'American Shorthair', 'Exotic Shorthair', 'Hound', 'Boxer', 'Dalmatian', 'Chihuahua', 'Miniature Pinscher', 'Italian Greyhound', 'Pointer', 'Dalmatian', 'Beagle', 'Exotic Shorthair', 'Boxer', 'American Cocker Spaniel', 'Cairn Terrier', 'Cocker Spaniel', 'Dachshund', 'Basset Hound', 'Pit Bull Terrier', 'Boxer', 'Bulldog', 'Persian Cat', 'Exotic Shorthair', 'British Shorthair', 'Dalmatian', 'Boxer', 'Pointer', 'Siamese', 'Bengal', 'Abyssinian', 'Basset Hound', 'Bulldog', 'Boston Terrier', 'Pug', 'Dachshund', 'British Blue', 'Russian Blue', 'Korat', 'British Shorthair', 'American Shorthair', 'Russian Blue', 'Dalmatian', 'English Setter', 'Bull Terrier', 'Persian', 'Maine Coon', 'Siberian', 'Cocker Spaniel', 'Chihuahua', 'Jack Russell Terrier', 'Pomeranian', 'Scottish Terrier', 'West Highland White Terrier', 'Bichon Frise', 'French Bulldog']
0it [00:00, ?it/s]1it [00:02,  2.27s/it]2it [00:03,  1.46s/it]3it [00:03,  1.14s/it]4it [00:04,  1.07s/it]5it [00:05,  1.01s/it]6it [00:07,  1.09s/it]7it [00:08,  1.21s/it]8it [00:09,  1.12s/it]9it [00:10,  1.05s/it]10it [00:11,  1.01it/s]11it [00:12,  1.00it/s]12it [00:13,  1.07s/it]13it [00:15,  1.42s/it]14it [00:17,  1.50s/it]15it [00:18,  1.51s/it]16it [00:20,  1.44s/it]17it [00:21,  1.51s/it]18it [00:23,  1.54s/it]19it [00:24,  1.54s/it]20it [00:26,  1.55s/it]21it [00:27,  1.47s/it]22it [00:29,  1.49s/it]23it [00:31,  1.65s/it]24it [00:33,  1.68s/it]25it [00:34,  1.71s/it]26it [00:36,  1.69s/it]27it [00:38,  1.64s/it]28it [00:39,  1.69s/it]29it [00:42,  1.85s/it]30it [00:44,  1.97s/it]31it [00:46,  2.13s/it]32it [00:49,  2.20s/it]33it [00:51,  2.24s/it]34it [00:53,  2.29s/it]35it [00:56,  2.31s/it]36it [00:58,  2.37s/it]37it [01:01,  2.34s/it]38it [01:03,  2.27s/it]39it [01:05,  2.34s/it]40it [01:08,  2.36s/it]41it [01:10,  2.36s/it]42it [01:12,  2.40s/it]43it [01:15,  2.40s/it]44it [01:17,  2.40s/it]45it [01:20,  2.39s/it]46it [01:21,  2.17s/it]47it [01:23,  2.00s/it]48it [01:24,  1.84s/it]49it [01:26,  1.87s/it]50it [01:28,  1.91s/it]51it [01:30,  1.81s/it]52it [01:31,  1.68s/it]53it [01:32,  1.54s/it]54it [01:33,  1.32s/it]55it [01:35,  1.37s/it]56it [01:36,  1.25s/it]57it [01:37,  1.22s/it]58it [01:38,  1.24s/it]59it [01:40,  1.29s/it]60it [01:40,  1.16s/it]61it [01:41,  1.06s/it]62it [01:42,  1.02it/s]63it [01:43,  1.07it/s]64it [01:44,  1.07it/s]65it [01:45,  1.01s/it]66it [01:47,  1.24s/it]67it [01:49,  1.37s/it]68it [01:50,  1.45s/it]69it [01:52,  1.55s/it]70it [01:53,  1.48s/it]71it [01:55,  1.43s/it]72it [01:56,  1.36s/it]73it [01:57,  1.42s/it]74it [01:59,  1.39s/it]75it [02:01,  1.55s/it]76it [02:03,  1.81s/it]77it [02:05,  1.98s/it]78it [02:08,  2.11s/it]79it [02:10,  2.08s/it]80it [02:12,  2.26s/it]81it [02:15,  2.26s/it]82it [02:17,  2.24s/it]83it [02:20,  2.35s/it]84it [02:22,  2.36s/it]85it [02:24,  2.20s/it]86it [02:26,  2.20s/it]87it [02:28,  2.20s/it]88it [02:30,  2.08s/it]89it [02:32,  2.00s/it]90it [02:33,  1.89s/it]91it [02:35,  1.88s/it]92it [02:37,  1.85s/it]93it [02:39,  1.81s/it]94it [02:40,  1.76s/it]95it [02:42,  1.60s/it]96it [02:43,  1.50s/it]97it [02:44,  1.48s/it]98it [02:46,  1.45s/it]99it [02:47,  1.39s/it]100it [02:48,  1.22s/it]101it [02:49,  1.17s/it]102it [02:50,  1.14s/it]103it [02:51,  1.15s/it]104it [02:52,  1.08s/it]105it [02:53,  1.20s/it]106it [02:55,  1.18s/it]107it [02:56,  1.11s/it]108it [02:56,  1.07s/it]109it [02:57,  1.28it/s]110it [02:57,  1.36it/s]111it [02:58,  1.41it/s]111it [02:58,  1.61s/it]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:01<02:41,  1.41s/it]  2%|▏         | 2/115 [00:01<01:15,  1.50it/s]  4%|▍         | 5/115 [00:01<00:23,  4.61it/s]  7%|▋         | 8/115 [00:01<00:13,  7.84it/s] 10%|▉         | 11/115 [00:01<00:09, 11.14it/s] 13%|█▎        | 15/115 [00:02<00:06, 15.53it/s] 16%|█▌        | 18/115 [00:02<00:05, 18.03it/s] 18%|█▊        | 21/115 [00:02<00:04, 20.07it/s] 21%|██        | 24/115 [00:02<00:04, 20.49it/s] 23%|██▎       | 27/115 [00:02<00:03, 22.19it/s] 26%|██▌       | 30/115 [00:02<00:03, 23.36it/s] 30%|██▉       | 34/115 [00:02<00:03, 25.89it/s] 33%|███▎      | 38/115 [00:02<00:02, 28.54it/s] 37%|███▋      | 42/115 [00:02<00:02, 30.42it/s] 40%|████      | 46/115 [00:03<00:02, 31.91it/s] 43%|████▎     | 50/115 [00:03<00:01, 32.94it/s] 47%|████▋     | 54/115 [00:03<00:01, 33.60it/s] 50%|█████     | 58/115 [00:03<00:01, 34.15it/s] 54%|█████▍    | 62/115 [00:03<00:01, 34.54it/s] 57%|█████▋    | 66/115 [00:03<00:01, 34.80it/s] 61%|██████    | 70/115 [00:03<00:01, 34.96it/s] 64%|██████▍   | 74/115 [00:03<00:01, 35.12it/s] 68%|██████▊   | 78/115 [00:03<00:01, 35.23it/s] 71%|███████▏  | 82/115 [00:04<00:00, 34.87it/s] 75%|███████▍  | 86/115 [00:04<00:00, 35.04it/s] 78%|███████▊  | 90/115 [00:04<00:00, 35.19it/s] 82%|████████▏ | 94/115 [00:04<00:00, 35.36it/s] 85%|████████▌ | 98/115 [00:04<00:00, 35.47it/s] 89%|████████▊ | 102/115 [00:04<00:00, 35.53it/s] 92%|█████████▏| 106/115 [00:04<00:00, 31.56it/s] 96%|█████████▌| 110/115 [00:05<00:00, 28.17it/s] 99%|█████████▉| 114/115 [00:05<00:00, 30.04it/s]100%|██████████| 115/115 [00:05<00:00, 21.87it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<02:56,  1.55s/it]  3%|▎         | 4/115 [00:01<00:38,  2.90it/s]  7%|▋         | 8/115 [00:01<00:16,  6.47it/s] 10%|▉         | 11/115 [00:01<00:11,  9.34it/s] 13%|█▎        | 15/115 [00:02<00:07, 13.57it/s] 17%|█▋        | 19/115 [00:02<00:05, 17.35it/s] 20%|██        | 23/115 [00:02<00:04, 20.96it/s] 23%|██▎       | 27/115 [00:02<00:03, 23.88it/s] 27%|██▋       | 31/115 [00:02<00:03, 26.47it/s] 30%|███       | 35/115 [00:02<00:02, 28.13it/s] 34%|███▍      | 39/115 [00:02<00:02, 29.09it/s] 37%|███▋      | 43/115 [00:02<00:02, 29.98it/s] 41%|████      | 47/115 [00:03<00:02, 30.41it/s] 44%|████▍     | 51/115 [00:03<00:02, 30.81it/s] 48%|████▊     | 55/115 [00:03<00:01, 30.90it/s] 51%|█████▏    | 59/115 [00:03<00:01, 31.75it/s] 55%|█████▍    | 63/115 [00:03<00:01, 31.44it/s] 58%|█████▊    | 67/115 [00:03<00:01, 31.66it/s] 62%|██████▏   | 71/115 [00:03<00:01, 31.82it/s] 65%|██████▌   | 75/115 [00:03<00:01, 32.31it/s] 69%|██████▊   | 79/115 [00:04<00:01, 32.41it/s] 72%|███████▏  | 83/115 [00:04<00:00, 32.49it/s] 76%|███████▌  | 87/115 [00:04<00:00, 32.14it/s] 79%|███████▉  | 91/115 [00:04<00:00, 32.34it/s] 83%|████████▎ | 95/115 [00:04<00:00, 31.90it/s] 86%|████████▌ | 99/115 [00:04<00:00, 32.05it/s] 90%|████████▉ | 103/115 [00:04<00:00, 28.25it/s] 92%|█████████▏| 106/115 [00:05<00:00, 24.16it/s] 95%|█████████▍| 109/115 [00:05<00:00, 21.66it/s] 97%|█████████▋| 112/115 [00:05<00:00, 21.22it/s]100%|██████████| 115/115 [00:05<00:00, 20.75it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7338225245475769


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 72.96266012537475
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.46727084561853
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.07239401094768


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.38225555419922
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  2.66it/s]2it [00:00,  3.35it/s]3it [00:00,  3.70it/s]4it [00:01,  3.95it/s]5it [00:01,  4.05it/s]6it [00:01,  3.66it/s]7it [00:01,  3.58it/s]8it [00:02,  3.47it/s]9it [00:02,  3.05it/s]10it [00:02,  3.69it/s]11it [00:03,  3.66it/s]12it [00:03,  3.20it/s]13it [00:04,  1.68it/s]14it [00:06,  1.17it/s]15it [00:07,  1.05it/s]16it [00:08,  1.01it/s]17it [00:09,  1.08it/s]18it [00:10,  1.04it/s]19it [00:11,  1.07it/s]20it [00:12,  1.07it/s]21it [00:13,  1.04it/s]22it [00:14,  1.03s/it]23it [00:15,  1.10s/it]24it [00:16,  1.11s/it]25it [00:18,  1.18s/it]26it [00:19,  1.31s/it]27it [00:20,  1.24s/it]28it [00:21,  1.16s/it]29it [00:22,  1.04it/s]30it [00:22,  1.20it/s]31it [00:23,  1.16it/s]32it [00:24,  1.01it/s]33it [00:25,  1.12it/s]34it [00:26,  1.02s/it]35it [00:28,  1.08s/it]36it [00:29,  1.13s/it]37it [00:30,  1.12s/it]38it [00:32,  1.25s/it]39it [00:33,  1.25s/it]40it [00:34,  1.24s/it]41it [00:35,  1.21s/it]42it [00:36,  1.13s/it]43it [00:37,  1.14s/it]44it [00:38,  1.10s/it]45it [00:39,  1.10s/it]46it [00:40,  1.10it/s]47it [00:40,  1.40it/s]48it [00:40,  1.74it/s]49it [00:41,  1.84it/s]50it [00:41,  2.06it/s]51it [00:41,  2.29it/s]52it [00:42,  2.47it/s]53it [00:42,  2.40it/s]54it [00:43,  2.52it/s]56it [00:43,  3.95it/s]58it [00:43,  5.46it/s]60it [00:43,  6.86it/s]62it [00:43,  8.10it/s]64it [00:43,  9.19it/s]66it [00:44, 10.28it/s]68it [00:44, 11.21it/s]70it [00:44, 11.35it/s]72it [00:44, 11.75it/s]74it [00:44, 12.45it/s]76it [00:44, 12.66it/s]78it [00:45, 11.74it/s]80it [00:45,  9.37it/s]82it [00:45, 10.39it/s]84it [00:45,  9.55it/s]86it [00:45, 10.28it/s]88it [00:46,  7.26it/s]89it [00:46,  5.26it/s]91it [00:46,  6.49it/s]93it [00:47,  7.63it/s]94it [00:47,  4.98it/s]95it [00:48,  3.32it/s]96it [00:48,  2.89it/s]98it [00:49,  3.31it/s]99it [00:49,  3.59it/s]100it [00:50,  2.49it/s]101it [00:50,  2.41it/s]102it [00:51,  2.12it/s]103it [00:51,  2.08it/s]104it [00:52,  1.99it/s]105it [00:53,  1.81it/s]106it [00:54,  1.38it/s]107it [00:54,  1.45it/s]108it [00:55,  1.49it/s]109it [00:55,  1.57it/s]110it [00:56,  1.75it/s]111it [00:56,  1.78it/s]111it [00:56,  1.95it/s]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<03:14,  1.71s/it]  3%|▎         | 3/115 [00:01<00:54,  2.05it/s]  6%|▌         | 7/115 [00:01<00:18,  5.69it/s] 10%|▉         | 11/115 [00:02<00:10,  9.67it/s] 13%|█▎        | 15/115 [00:02<00:07, 13.79it/s] 17%|█▋        | 19/115 [00:02<00:05, 17.57it/s] 20%|██        | 23/115 [00:02<00:04, 21.07it/s] 23%|██▎       | 27/115 [00:02<00:03, 24.23it/s] 27%|██▋       | 31/115 [00:02<00:03, 26.92it/s] 30%|███       | 35/115 [00:02<00:02, 28.43it/s] 34%|███▍      | 39/115 [00:02<00:02, 29.74it/s] 37%|███▋      | 43/115 [00:02<00:02, 31.22it/s] 41%|████      | 47/115 [00:03<00:02, 32.32it/s] 44%|████▍     | 51/115 [00:03<00:01, 32.78it/s] 48%|████▊     | 55/115 [00:03<00:01, 33.22it/s] 51%|█████▏    | 59/115 [00:03<00:01, 33.82it/s] 55%|█████▍    | 63/115 [00:03<00:01, 34.20it/s] 58%|█████▊    | 67/115 [00:03<00:01, 34.15it/s] 62%|██████▏   | 71/115 [00:03<00:01, 33.72it/s] 65%|██████▌   | 75/115 [00:03<00:01, 33.90it/s] 69%|██████▊   | 79/115 [00:04<00:01, 33.02it/s] 72%|███████▏  | 83/115 [00:04<00:01, 31.82it/s] 76%|███████▌  | 87/115 [00:04<00:00, 32.85it/s] 79%|███████▉  | 91/115 [00:04<00:00, 33.54it/s] 83%|████████▎ | 95/115 [00:04<00:00, 34.15it/s] 86%|████████▌ | 99/115 [00:04<00:00, 34.59it/s] 90%|████████▉ | 103/115 [00:04<00:00, 34.90it/s] 93%|█████████▎| 107/115 [00:04<00:00, 35.12it/s] 97%|█████████▋| 111/115 [00:04<00:00, 35.29it/s]100%|██████████| 115/115 [00:05<00:00, 36.20it/s]100%|██████████| 115/115 [00:05<00:00, 21.88it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<04:50,  2.55s/it]  3%|▎         | 4/115 [00:02<00:56,  1.96it/s]  7%|▋         | 8/115 [00:02<00:23,  4.57it/s] 10%|▉         | 11/115 [00:02<00:15,  6.86it/s] 13%|█▎        | 15/115 [00:02<00:09, 10.38it/s] 16%|█▌        | 18/115 [00:03<00:07, 13.02it/s] 19%|█▉        | 22/115 [00:03<00:05, 16.72it/s] 23%|██▎       | 26/115 [00:03<00:04, 19.88it/s] 26%|██▌       | 30/115 [00:03<00:03, 22.71it/s] 30%|██▉       | 34/115 [00:03<00:03, 24.81it/s] 33%|███▎      | 38/115 [00:03<00:02, 26.64it/s] 37%|███▋      | 42/115 [00:03<00:02, 28.59it/s] 40%|████      | 46/115 [00:03<00:02, 29.65it/s] 43%|████▎     | 50/115 [00:04<00:02, 29.49it/s] 47%|████▋     | 54/115 [00:04<00:02, 30.47it/s] 50%|█████     | 58/115 [00:04<00:01, 31.31it/s] 54%|█████▍    | 62/115 [00:04<00:01, 31.19it/s] 57%|█████▋    | 66/115 [00:04<00:01, 31.06it/s] 61%|██████    | 70/115 [00:04<00:01, 31.63it/s] 64%|██████▍   | 74/115 [00:04<00:01, 31.85it/s] 68%|██████▊   | 78/115 [00:04<00:01, 32.28it/s] 71%|███████▏  | 82/115 [00:05<00:01, 31.95it/s] 75%|███████▍  | 86/115 [00:05<00:00, 31.69it/s] 78%|███████▊  | 90/115 [00:05<00:00, 31.44it/s] 82%|████████▏ | 94/115 [00:05<00:00, 32.26it/s] 85%|████████▌ | 98/115 [00:05<00:00, 33.21it/s] 89%|████████▊ | 102/115 [00:05<00:00, 33.16it/s] 92%|█████████▏| 106/115 [00:05<00:00, 33.65it/s] 96%|█████████▌| 110/115 [00:05<00:00, 33.72it/s] 99%|█████████▉| 114/115 [00:06<00:00, 34.24it/s]100%|██████████| 115/115 [00:06<00:00, 18.10it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7394368052482605


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 73.15344780594167
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.99892790945758
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.83530648137427


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.94367980957031
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.00s/it]2it [00:01,  1.05it/s]3it [00:02,  1.14it/s]4it [00:03,  1.01it/s]5it [00:05,  1.13s/it]6it [00:06,  1.07s/it]7it [00:07,  1.02s/it]8it [00:08,  1.01s/it]9it [00:08,  1.04it/s]10it [00:09,  1.09it/s]11it [00:10,  1.11it/s]12it [00:11,  1.09it/s]13it [00:12,  1.09it/s]14it [00:13,  1.12it/s]15it [00:14,  1.18it/s]16it [00:15,  1.15it/s]17it [00:16,  1.04it/s]18it [00:17,  1.20s/it]19it [00:19,  1.31s/it]20it [00:21,  1.41s/it]21it [00:22,  1.43s/it]22it [00:24,  1.51s/it]23it [00:25,  1.49s/it]24it [00:27,  1.52s/it]25it [00:28,  1.53s/it]26it [00:30,  1.59s/it]27it [00:32,  1.61s/it]28it [00:33,  1.63s/it]29it [00:35,  1.63s/it]30it [00:37,  1.60s/it]31it [00:38,  1.62s/it]32it [00:40,  1.64s/it]33it [00:42,  1.60s/it]34it [00:43,  1.53s/it]35it [00:44,  1.44s/it]36it [00:45,  1.35s/it]37it [00:46,  1.30s/it]38it [00:48,  1.25s/it]39it [00:49,  1.29s/it]40it [00:50,  1.26s/it]41it [00:51,  1.24s/it]42it [00:53,  1.29s/it]43it [00:54,  1.30s/it]44it [00:55,  1.26s/it]45it [00:56,  1.13s/it]46it [00:57,  1.04s/it]47it [00:58,  1.00s/it]48it [00:59,  1.03it/s]49it [01:00,  1.09it/s]50it [01:00,  1.24it/s]51it [01:00,  1.49it/s]52it [01:01,  1.73it/s]53it [01:01,  1.84it/s]54it [01:02,  2.13it/s]55it [01:02,  2.71it/s]56it [01:02,  3.39it/s]57it [01:02,  4.18it/s]58it [01:02,  4.38it/s]59it [01:03,  3.30it/s]60it [01:03,  2.77it/s]61it [01:04,  2.55it/s]62it [01:05,  1.76it/s]63it [01:05,  1.55it/s]64it [01:06,  1.94it/s]65it [01:06,  2.28it/s]66it [01:06,  2.46it/s]67it [01:07,  2.31it/s]68it [01:07,  2.65it/s]69it [01:07,  2.50it/s]70it [01:08,  2.65it/s]71it [01:08,  3.13it/s]72it [01:08,  3.61it/s]73it [01:08,  3.40it/s]74it [01:09,  3.00it/s]75it [01:09,  2.42it/s]76it [01:10,  2.83it/s]77it [01:10,  2.28it/s]78it [01:11,  1.94it/s]79it [01:11,  1.92it/s]80it [01:12,  1.63it/s]81it [01:13,  1.61it/s]82it [01:13,  1.68it/s]83it [01:14,  1.61it/s]84it [01:15,  1.81it/s]85it [01:15,  2.11it/s]86it [01:15,  2.47it/s]87it [01:15,  2.47it/s]88it [01:16,  3.11it/s]89it [01:16,  2.54it/s]90it [01:17,  2.12it/s]91it [01:17,  1.97it/s]92it [01:18,  1.68it/s]93it [01:18,  2.00it/s]94it [01:19,  1.74it/s]95it [01:20,  2.00it/s]96it [01:20,  2.37it/s]97it [01:20,  2.92it/s]98it [01:20,  2.76it/s]99it [01:21,  3.02it/s]100it [01:22,  1.86it/s]101it [01:23,  1.41it/s]102it [01:24,  1.30it/s]103it [01:25,  1.04s/it]104it [01:27,  1.18s/it]105it [01:28,  1.14s/it]106it [01:29,  1.09s/it]107it [01:30,  1.01it/s]108it [01:30,  1.06it/s]109it [01:31,  1.10it/s]110it [01:32,  1.11it/s]111it [01:33,  1.09it/s]111it [01:33,  1.19it/s]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:27,  2.87s/it]  3%|▎         | 4/115 [00:02<01:03,  1.75it/s]  6%|▌         | 7/115 [00:03<00:30,  3.54it/s] 10%|▉         | 11/115 [00:03<00:16,  6.42it/s] 13%|█▎        | 15/115 [00:03<00:10,  9.55it/s] 17%|█▋        | 19/115 [00:03<00:07, 12.82it/s] 19%|█▉        | 22/115 [00:03<00:06, 15.04it/s] 22%|██▏       | 25/115 [00:03<00:05, 16.86it/s] 24%|██▍       | 28/115 [00:03<00:04, 19.07it/s] 27%|██▋       | 31/115 [00:03<00:04, 20.82it/s] 30%|██▉       | 34/115 [00:04<00:03, 21.87it/s] 32%|███▏      | 37/115 [00:04<00:03, 22.96it/s] 35%|███▍      | 40/115 [00:04<00:03, 21.78it/s] 37%|███▋      | 43/115 [00:04<00:03, 22.53it/s] 40%|████      | 46/115 [00:04<00:02, 23.54it/s] 43%|████▎     | 49/115 [00:04<00:02, 24.96it/s] 45%|████▌     | 52/115 [00:04<00:02, 25.07it/s] 48%|████▊     | 55/115 [00:04<00:02, 25.64it/s] 51%|█████▏    | 59/115 [00:05<00:02, 27.52it/s] 54%|█████▍    | 62/115 [00:05<00:01, 26.81it/s] 57%|█████▋    | 65/115 [00:05<00:01, 26.90it/s] 59%|█████▉    | 68/115 [00:05<00:01, 26.66it/s] 62%|██████▏   | 71/115 [00:05<00:01, 26.71it/s] 64%|██████▍   | 74/115 [00:05<00:01, 26.67it/s] 68%|██████▊   | 78/115 [00:05<00:01, 27.80it/s] 70%|███████   | 81/115 [00:05<00:01, 28.15it/s] 73%|███████▎  | 84/115 [00:05<00:01, 27.66it/s] 77%|███████▋  | 88/115 [00:06<00:00, 28.91it/s] 80%|████████  | 92/115 [00:06<00:00, 30.07it/s] 83%|████████▎ | 96/115 [00:06<00:00, 30.40it/s] 87%|████████▋ | 100/115 [00:06<00:00, 31.56it/s] 90%|█████████ | 104/115 [00:06<00:00, 32.36it/s] 94%|█████████▍| 108/115 [00:06<00:00, 32.81it/s] 97%|█████████▋| 112/115 [00:06<00:00, 33.63it/s]100%|██████████| 115/115 [00:07<00:00, 16.06it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<05:48,  3.06s/it]  3%|▎         | 3/115 [00:03<01:37,  1.15it/s]  5%|▌         | 6/115 [00:03<00:39,  2.78it/s]  8%|▊         | 9/115 [00:03<00:22,  4.81it/s] 11%|█▏        | 13/115 [00:03<00:12,  7.93it/s] 14%|█▍        | 16/115 [00:03<00:09, 10.21it/s] 17%|█▋        | 19/115 [00:03<00:07, 12.96it/s] 19%|█▉        | 22/115 [00:03<00:05, 15.78it/s] 22%|██▏       | 25/115 [00:04<00:05, 17.75it/s] 25%|██▌       | 29/115 [00:04<00:03, 21.65it/s] 29%|██▊       | 33/115 [00:04<00:03, 24.23it/s] 31%|███▏      | 36/115 [00:04<00:03, 25.28it/s] 35%|███▍      | 40/115 [00:04<00:02, 27.53it/s] 38%|███▊      | 44/115 [00:04<00:02, 27.25it/s] 41%|████      | 47/115 [00:04<00:02, 27.52it/s] 43%|████▎     | 50/115 [00:04<00:02, 25.89it/s] 46%|████▌     | 53/115 [00:05<00:02, 25.90it/s] 50%|████▉     | 57/115 [00:05<00:02, 27.48it/s] 52%|█████▏    | 60/115 [00:05<00:01, 27.98it/s] 55%|█████▍    | 63/115 [00:05<00:01, 27.49it/s] 57%|█████▋    | 66/115 [00:05<00:01, 27.13it/s] 61%|██████    | 70/115 [00:05<00:01, 28.32it/s] 63%|██████▎   | 73/115 [00:05<00:01, 27.82it/s] 66%|██████▌   | 76/115 [00:05<00:01, 27.06it/s] 69%|██████▊   | 79/115 [00:05<00:01, 27.47it/s] 72%|███████▏  | 83/115 [00:06<00:01, 28.45it/s] 76%|███████▌  | 87/115 [00:06<00:00, 30.07it/s] 79%|███████▉  | 91/115 [00:06<00:00, 31.36it/s] 83%|████████▎ | 95/115 [00:06<00:00, 32.28it/s] 86%|████████▌ | 99/115 [00:06<00:00, 31.74it/s] 90%|████████▉ | 103/115 [00:06<00:00, 32.14it/s] 93%|█████████▎| 107/115 [00:06<00:00, 31.88it/s] 97%|█████████▋| 111/115 [00:06<00:00, 32.94it/s]100%|██████████| 115/115 [00:07<00:00, 32.90it/s]100%|██████████| 115/115 [00:07<00:00, 15.52it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.74102383852005


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 73.56227855001363
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.85149644575272
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.72482624482399


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 74.10238647460938
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.58s/it]2it [00:03,  2.00s/it]3it [00:05,  1.87s/it]4it [00:07,  1.83s/it]5it [00:08,  1.69s/it]6it [00:10,  1.72s/it]7it [00:12,  1.86s/it]8it [00:14,  1.79s/it]9it [00:15,  1.72s/it]10it [00:17,  1.68s/it]11it [00:18,  1.62s/it]12it [00:20,  1.62s/it]13it [00:21,  1.53s/it]14it [00:23,  1.43s/it]15it [00:24,  1.34s/it]16it [00:26,  1.62s/it]17it [00:29,  1.88s/it]18it [00:31,  2.00s/it]19it [00:33,  2.10s/it]20it [00:35,  2.10s/it]21it [00:37,  2.13s/it]22it [00:40,  2.19s/it]23it [00:41,  2.02s/it]24it [00:43,  1.85s/it]25it [00:44,  1.76s/it]26it [00:46,  1.64s/it]27it [00:48,  1.69s/it]28it [00:49,  1.73s/it]29it [00:51,  1.70s/it]30it [00:53,  1.67s/it]31it [00:54,  1.70s/it]32it [00:56,  1.64s/it]33it [00:57,  1.63s/it]34it [00:59,  1.73s/it]35it [01:01,  1.68s/it]36it [01:02,  1.49s/it]37it [01:03,  1.38s/it]38it [01:04,  1.29s/it]39it [01:05,  1.20s/it]40it [01:06,  1.15s/it]41it [01:08,  1.23s/it]42it [01:09,  1.31s/it]43it [01:10,  1.24s/it]44it [01:11,  1.17s/it]45it [01:12,  1.09s/it]46it [01:13,  1.03s/it]47it [01:14,  1.05s/it]48it [01:16,  1.32s/it]49it [01:17,  1.13s/it]50it [01:17,  1.06it/s]51it [01:18,  1.25it/s]52it [01:18,  1.52it/s]53it [01:19,  1.71it/s]54it [01:19,  2.11it/s]55it [01:19,  2.62it/s]56it [01:19,  3.00it/s]57it [01:19,  3.53it/s]58it [01:20,  3.54it/s]59it [01:20,  3.26it/s]60it [01:20,  3.89it/s]61it [01:20,  3.83it/s]62it [01:21,  4.34it/s]64it [01:21,  6.31it/s]66it [01:21,  8.18it/s]67it [01:21,  8.08it/s]68it [01:21,  8.25it/s]70it [01:21, 10.07it/s]72it [01:21, 11.10it/s]74it [01:21, 12.62it/s]76it [01:22, 13.83it/s]78it [01:22, 14.77it/s]80it [01:22, 10.72it/s]82it [01:22, 12.19it/s]84it [01:22, 13.52it/s]86it [01:22, 13.63it/s]88it [01:22, 14.79it/s]90it [01:23, 15.18it/s]92it [01:23, 15.61it/s]94it [01:23, 10.99it/s]96it [01:23, 11.78it/s]98it [01:23, 12.91it/s]100it [01:23, 13.71it/s]102it [01:24, 13.86it/s]104it [01:24, 14.24it/s]106it [01:24, 14.31it/s]108it [01:24, 14.81it/s]110it [01:24, 14.63it/s]111it [01:24,  1.31it/s]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<03:48,  2.00s/it]  4%|▍         | 5/115 [00:02<00:35,  3.10it/s]  8%|▊         | 9/115 [00:02<00:17,  6.20it/s] 11%|█▏        | 13/115 [00:02<00:10,  9.73it/s] 15%|█▍        | 17/115 [00:02<00:07, 13.47it/s] 18%|█▊        | 21/115 [00:02<00:05, 17.25it/s] 22%|██▏       | 25/115 [00:02<00:04, 20.83it/s] 25%|██▌       | 29/115 [00:02<00:03, 24.05it/s] 29%|██▊       | 33/115 [00:02<00:03, 26.75it/s] 32%|███▏      | 37/115 [00:03<00:02, 28.91it/s] 36%|███▌      | 41/115 [00:03<00:02, 30.52it/s] 39%|███▉      | 45/115 [00:03<00:02, 31.67it/s] 43%|████▎     | 49/115 [00:03<00:02, 32.57it/s] 46%|████▌     | 53/115 [00:03<00:01, 33.26it/s] 50%|████▉     | 57/115 [00:03<00:01, 33.75it/s] 53%|█████▎    | 61/115 [00:03<00:01, 34.14it/s] 57%|█████▋    | 65/115 [00:03<00:01, 34.34it/s] 60%|██████    | 69/115 [00:03<00:01, 34.58it/s] 63%|██████▎   | 73/115 [00:04<00:01, 34.82it/s] 67%|██████▋   | 77/115 [00:04<00:01, 34.86it/s] 70%|███████   | 81/115 [00:04<00:00, 34.92it/s] 74%|███████▍  | 85/115 [00:04<00:00, 35.06it/s] 77%|███████▋  | 89/115 [00:04<00:00, 35.24it/s] 81%|████████  | 93/115 [00:04<00:00, 35.28it/s] 84%|████████▍ | 97/115 [00:04<00:00, 35.34it/s] 88%|████████▊ | 101/115 [00:04<00:00, 35.40it/s] 91%|█████████▏| 105/115 [00:04<00:00, 35.40it/s] 95%|█████████▍| 109/115 [00:05<00:00, 35.43it/s] 98%|█████████▊| 113/115 [00:05<00:00, 35.45it/s]100%|██████████| 115/115 [00:05<00:00, 21.18it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<03:57,  2.08s/it]  4%|▍         | 5/115 [00:02<00:36,  2.99it/s]  8%|▊         | 9/115 [00:02<00:17,  6.01it/s] 11%|█▏        | 13/115 [00:02<00:10,  9.45it/s] 15%|█▍        | 17/115 [00:02<00:07, 13.17it/s] 18%|█▊        | 21/115 [00:02<00:05, 16.95it/s] 22%|██▏       | 25/115 [00:02<00:04, 20.53it/s] 25%|██▌       | 29/115 [00:02<00:03, 23.78it/s] 29%|██▊       | 33/115 [00:02<00:03, 26.53it/s] 32%|███▏      | 37/115 [00:03<00:02, 28.75it/s] 36%|███▌      | 41/115 [00:03<00:02, 30.52it/s] 39%|███▉      | 45/115 [00:03<00:02, 31.85it/s] 43%|████▎     | 49/115 [00:03<00:02, 32.80it/s] 46%|████▌     | 53/115 [00:03<00:01, 33.42it/s] 50%|████▉     | 57/115 [00:03<00:01, 34.00it/s] 53%|█████▎    | 61/115 [00:03<00:01, 34.30it/s] 57%|█████▋    | 65/115 [00:03<00:01, 34.52it/s] 60%|██████    | 69/115 [00:04<00:01, 34.37it/s] 63%|██████▎   | 73/115 [00:04<00:01, 25.56it/s] 67%|██████▋   | 77/115 [00:04<00:01, 27.07it/s] 70%|███████   | 81/115 [00:04<00:01, 28.81it/s] 74%|███████▍  | 85/115 [00:04<00:01, 29.64it/s] 77%|███████▋  | 89/115 [00:04<00:00, 31.03it/s] 81%|████████  | 93/115 [00:04<00:00, 32.30it/s] 84%|████████▍ | 97/115 [00:04<00:00, 33.27it/s] 88%|████████▊ | 101/115 [00:05<00:00, 33.96it/s] 91%|█████████▏| 105/115 [00:05<00:00, 33.83it/s] 95%|█████████▍| 109/115 [00:05<00:00, 33.25it/s] 98%|█████████▊| 113/115 [00:05<00:00, 31.77it/s]100%|██████████| 115/115 [00:05<00:00, 20.27it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.735502302646637


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 72.60834014717906
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.82326044680963
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.78370258391101


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.55023193359375
=========================          END          =========================
0it [00:00, ?it/s]1it [00:02,  2.33s/it]2it [00:04,  2.39s/it]3it [00:07,  2.47s/it]4it [00:09,  2.43s/it]5it [00:12,  2.55s/it]6it [00:15,  2.57s/it]7it [00:17,  2.54s/it]8it [00:20,  2.52s/it]9it [00:22,  2.59s/it]10it [00:25,  2.59s/it]11it [00:27,  2.53s/it]12it [00:30,  2.48s/it]13it [00:32,  2.47s/it]14it [00:34,  2.32s/it]15it [00:36,  2.15s/it]16it [00:37,  1.99s/it]17it [00:39,  1.88s/it]18it [00:41,  2.01s/it]19it [00:43,  1.96s/it]20it [00:45,  1.89s/it]21it [00:47,  1.81s/it]22it [00:49,  1.87s/it]23it [00:51,  1.91s/it]24it [00:52,  1.89s/it]25it [00:54,  1.71s/it]26it [00:55,  1.57s/it]27it [00:56,  1.45s/it]28it [00:57,  1.40s/it]29it [00:58,  1.29s/it]30it [00:59,  1.18s/it]31it [01:00,  1.16s/it]32it [01:02,  1.35s/it]33it [01:04,  1.43s/it]34it [01:06,  1.61s/it]35it [01:08,  1.78s/it]36it [01:09,  1.64s/it]37it [01:11,  1.59s/it]38it [01:13,  1.63s/it]39it [01:14,  1.70s/it]40it [01:16,  1.61s/it]41it [01:17,  1.62s/it]42it [01:19,  1.57s/it]43it [01:20,  1.44s/it]44it [01:21,  1.38s/it]45it [01:23,  1.46s/it]46it [01:25,  1.54s/it]47it [01:27,  1.62s/it]48it [01:29,  1.79s/it]49it [01:31,  2.02s/it]50it [01:34,  2.16s/it]51it [01:36,  2.31s/it]52it [01:39,  2.38s/it]53it [01:41,  2.41s/it]54it [01:44,  2.43s/it]55it [01:47,  2.49s/it]56it [01:49,  2.43s/it]57it [01:51,  2.40s/it]58it [01:54,  2.41s/it]59it [01:56,  2.41s/it]60it [01:58,  2.39s/it]61it [02:01,  2.36s/it]62it [02:03,  2.27s/it]63it [02:05,  2.26s/it]64it [02:07,  2.13s/it]65it [02:08,  1.99s/it]66it [02:10,  1.78s/it]67it [02:11,  1.63s/it]68it [02:12,  1.50s/it]69it [02:13,  1.39s/it]70it [02:15,  1.47s/it]71it [02:16,  1.42s/it]72it [02:18,  1.38s/it]73it [02:19,  1.41s/it]74it [02:21,  1.49s/it]75it [02:22,  1.54s/it]76it [02:24,  1.44s/it]77it [02:25,  1.40s/it]78it [02:26,  1.39s/it]79it [02:28,  1.37s/it]80it [02:29,  1.51s/it]81it [02:31,  1.63s/it]82it [02:33,  1.67s/it]83it [02:35,  1.70s/it]84it [02:37,  1.80s/it]85it [02:39,  1.91s/it]86it [02:41,  1.90s/it]87it [02:43,  1.88s/it]88it [02:45,  2.02s/it]89it [02:47,  2.08s/it]90it [02:49,  2.02s/it]91it [02:51,  2.02s/it]92it [02:53,  1.97s/it]93it [02:55,  1.91s/it]94it [02:57,  1.95s/it]95it [02:59,  1.96s/it]96it [03:01,  2.01s/it]97it [03:04,  2.26s/it]98it [03:06,  2.37s/it]99it [03:09,  2.50s/it]100it [03:11,  2.33s/it]101it [03:13,  2.18s/it]102it [03:15,  2.06s/it]103it [03:17,  2.02s/it]104it [03:19,  1.94s/it]105it [03:20,  1.92s/it]106it [03:23,  2.07s/it]107it [03:25,  2.02s/it]108it [03:26,  1.91s/it]109it [03:28,  1.88s/it]110it [03:30,  1.82s/it]111it [03:32,  1.79s/it]111it [03:32,  1.91s/it]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:28,  2.88s/it]  3%|▎         | 4/115 [00:02<01:03,  1.75it/s]  7%|▋         | 8/115 [00:03<00:25,  4.12it/s] 10%|▉         | 11/115 [00:03<00:16,  6.20it/s] 13%|█▎        | 15/115 [00:03<00:10,  9.48it/s] 17%|█▋        | 19/115 [00:03<00:07, 12.98it/s] 20%|██        | 23/115 [00:03<00:05, 16.36it/s] 23%|██▎       | 27/115 [00:03<00:04, 19.45it/s] 27%|██▋       | 31/115 [00:03<00:03, 22.54it/s] 30%|███       | 35/115 [00:03<00:03, 25.26it/s] 34%|███▍      | 39/115 [00:04<00:03, 24.92it/s] 37%|███▋      | 42/115 [00:04<00:03, 23.02it/s] 40%|████      | 46/115 [00:04<00:02, 25.89it/s] 43%|████▎     | 50/115 [00:04<00:02, 27.55it/s] 46%|████▌     | 53/115 [00:04<00:02, 27.77it/s] 50%|████▉     | 57/115 [00:04<00:01, 29.03it/s] 53%|█████▎    | 61/115 [00:04<00:01, 29.39it/s] 57%|█████▋    | 65/115 [00:04<00:01, 30.60it/s] 60%|██████    | 69/115 [00:05<00:01, 30.16it/s] 63%|██████▎   | 73/115 [00:05<00:01, 31.05it/s] 67%|██████▋   | 77/115 [00:05<00:01, 31.76it/s] 70%|███████   | 81/115 [00:05<00:01, 32.00it/s] 74%|███████▍  | 85/115 [00:05<00:00, 31.71it/s] 77%|███████▋  | 89/115 [00:05<00:00, 30.99it/s] 81%|████████  | 93/115 [00:05<00:00, 31.53it/s] 84%|████████▍ | 97/115 [00:05<00:00, 32.68it/s] 88%|████████▊ | 101/115 [00:06<00:00, 32.56it/s] 91%|█████████▏| 105/115 [00:06<00:00, 33.00it/s] 95%|█████████▍| 109/115 [00:06<00:00, 33.52it/s] 98%|█████████▊| 113/115 [00:06<00:00, 32.41it/s]100%|██████████| 115/115 [00:06<00:00, 16.76it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<03:40,  1.94s/it]  4%|▍         | 5/115 [00:02<00:34,  3.20it/s]  8%|▊         | 9/115 [00:02<00:16,  6.39it/s] 11%|█▏        | 13/115 [00:02<00:10,  9.98it/s] 15%|█▍        | 17/115 [00:02<00:07, 13.80it/s] 18%|█▊        | 21/115 [00:02<00:05, 17.24it/s] 22%|██▏       | 25/115 [00:02<00:04, 20.85it/s] 25%|██▌       | 29/115 [00:02<00:03, 24.05it/s] 29%|██▊       | 33/115 [00:02<00:03, 26.76it/s] 32%|███▏      | 37/115 [00:02<00:02, 28.94it/s] 36%|███▌      | 41/115 [00:03<00:02, 30.66it/s] 39%|███▉      | 45/115 [00:03<00:02, 31.94it/s] 43%|████▎     | 49/115 [00:03<00:02, 32.90it/s] 46%|████▌     | 53/115 [00:03<00:01, 33.60it/s] 50%|████▉     | 57/115 [00:03<00:01, 32.82it/s] 53%|█████▎    | 61/115 [00:03<00:02, 26.96it/s] 57%|█████▋    | 65/115 [00:03<00:01, 28.95it/s] 60%|██████    | 69/115 [00:03<00:01, 30.54it/s] 63%|██████▎   | 73/115 [00:04<00:01, 30.55it/s] 67%|██████▋   | 77/115 [00:04<00:01, 31.79it/s] 70%|███████   | 81/115 [00:04<00:01, 32.54it/s] 74%|███████▍  | 85/115 [00:04<00:00, 33.32it/s] 77%|███████▋  | 89/115 [00:04<00:00, 33.87it/s] 81%|████████  | 93/115 [00:04<00:00, 33.47it/s] 84%|████████▍ | 97/115 [00:04<00:00, 33.06it/s] 88%|████████▊ | 101/115 [00:04<00:00, 31.19it/s] 91%|█████████▏| 105/115 [00:05<00:00, 31.35it/s] 95%|█████████▍| 109/115 [00:05<00:00, 32.54it/s] 98%|█████████▊| 113/115 [00:05<00:00, 33.46it/s]100%|██████████| 115/115 [00:05<00:00, 20.79it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7331259846687317


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 72.03597710547834
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.08033145593575
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 63.48576557792478


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.3125991821289
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.36s/it]2it [00:03,  1.62s/it]3it [00:04,  1.36s/it]4it [00:05,  1.24s/it]5it [00:06,  1.25s/it]6it [00:07,  1.29s/it]7it [00:09,  1.28s/it]8it [00:10,  1.35s/it]9it [00:11,  1.23s/it]10it [00:12,  1.09s/it]11it [00:13,  1.06s/it]12it [00:14,  1.10s/it]13it [00:15,  1.07s/it]14it [00:16,  1.07s/it]15it [00:17,  1.13s/it]16it [00:19,  1.16s/it]17it [00:20,  1.11s/it]18it [00:21,  1.14s/it]19it [00:23,  1.33s/it]20it [00:24,  1.48s/it]21it [00:26,  1.65s/it]22it [00:28,  1.70s/it]23it [00:30,  1.71s/it]24it [00:32,  1.70s/it]25it [00:33,  1.53s/it]26it [00:34,  1.51s/it]27it [00:36,  1.51s/it]28it [00:37,  1.34s/it]29it [00:38,  1.30s/it]30it [00:39,  1.28s/it]31it [00:41,  1.43s/it]32it [00:43,  1.47s/it]33it [00:44,  1.59s/it]34it [00:46,  1.70s/it]35it [00:48,  1.65s/it]36it [00:50,  1.66s/it]37it [00:51,  1.63s/it]38it [00:53,  1.60s/it]39it [00:54,  1.51s/it]40it [00:56,  1.53s/it]41it [00:58,  1.88s/it]42it [01:00,  1.97s/it]43it [01:03,  2.05s/it]44it [01:05,  2.04s/it]45it [01:07,  1.97s/it]46it [01:08,  1.96s/it]47it [01:10,  1.91s/it]48it [01:12,  1.98s/it]49it [01:14,  1.97s/it]50it [01:17,  2.09s/it]51it [01:19,  2.01s/it]52it [01:21,  2.03s/it]53it [01:22,  1.90s/it]54it [01:23,  1.72s/it]55it [01:25,  1.65s/it]56it [01:27,  1.66s/it]57it [01:28,  1.67s/it]58it [01:30,  1.64s/it]59it [01:32,  1.70s/it]60it [01:33,  1.65s/it]61it [01:35,  1.57s/it]62it [01:36,  1.58s/it]63it [01:38,  1.53s/it]64it [01:40,  1.68s/it]65it [01:41,  1.51s/it]66it [01:42,  1.54s/it]67it [01:45,  1.74s/it]68it [01:46,  1.71s/it]69it [01:48,  1.62s/it]70it [01:49,  1.65s/it]71it [01:51,  1.62s/it]72it [01:52,  1.52s/it]73it [01:54,  1.52s/it]74it [01:56,  1.60s/it]75it [01:57,  1.54s/it]76it [01:58,  1.48s/it]77it [02:00,  1.49s/it]78it [02:01,  1.37s/it]79it [02:02,  1.24s/it]80it [02:03,  1.25s/it]81it [02:04,  1.17s/it]82it [02:06,  1.27s/it]83it [02:08,  1.49s/it]84it [02:09,  1.56s/it]85it [02:11,  1.69s/it]86it [02:13,  1.63s/it]87it [02:15,  1.70s/it]88it [02:17,  1.73s/it]89it [02:18,  1.71s/it]90it [02:20,  1.67s/it]91it [02:21,  1.67s/it]92it [02:23,  1.75s/it]93it [02:25,  1.71s/it]94it [02:27,  1.87s/it]95it [02:29,  1.94s/it]96it [02:30,  1.64s/it]97it [02:31,  1.43s/it]98it [02:32,  1.32s/it]99it [02:33,  1.21s/it]100it [02:34,  1.16s/it]101it [02:36,  1.29s/it]102it [02:37,  1.20s/it]103it [02:38,  1.10s/it]104it [02:38,  1.00s/it]105it [02:39,  1.02it/s]106it [02:40,  1.02it/s]107it [02:42,  1.05s/it]108it [02:43,  1.06s/it]109it [02:44,  1.02s/it]110it [02:45,  1.01s/it]111it [02:46,  1.21s/it]111it [02:46,  1.50s/it]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<06:16,  3.30s/it]  3%|▎         | 4/115 [00:03<01:12,  1.53it/s]  7%|▋         | 8/115 [00:03<00:29,  3.63it/s] 10%|█         | 12/115 [00:03<00:16,  6.18it/s] 14%|█▍        | 16/115 [00:03<00:10,  9.13it/s] 17%|█▋        | 20/115 [00:03<00:07, 12.48it/s] 21%|██        | 24/115 [00:04<00:05, 15.79it/s] 24%|██▍       | 28/115 [00:04<00:04, 19.06it/s] 28%|██▊       | 32/115 [00:04<00:03, 22.23it/s] 31%|███▏      | 36/115 [00:04<00:03, 24.61it/s] 35%|███▍      | 40/115 [00:04<00:02, 26.78it/s] 38%|███▊      | 44/115 [00:04<00:02, 28.09it/s] 42%|████▏     | 48/115 [00:04<00:02, 29.34it/s] 45%|████▌     | 52/115 [00:04<00:02, 29.78it/s] 49%|████▊     | 56/115 [00:04<00:01, 30.28it/s] 52%|█████▏    | 60/115 [00:05<00:01, 30.77it/s] 56%|█████▌    | 64/115 [00:05<00:01, 30.01it/s] 59%|█████▉    | 68/115 [00:05<00:01, 30.70it/s] 63%|██████▎   | 72/115 [00:05<00:01, 31.74it/s] 66%|██████▌   | 76/115 [00:05<00:01, 31.31it/s] 70%|██████▉   | 80/115 [00:05<00:01, 30.87it/s] 73%|███████▎  | 84/115 [00:05<00:00, 31.41it/s] 77%|███████▋  | 88/115 [00:06<00:00, 32.48it/s] 80%|████████  | 92/115 [00:06<00:00, 33.33it/s] 83%|████████▎ | 96/115 [00:06<00:00, 33.38it/s] 87%|████████▋ | 100/115 [00:06<00:00, 32.64it/s] 90%|█████████ | 104/115 [00:06<00:00, 32.59it/s] 94%|█████████▍| 108/115 [00:06<00:00, 31.67it/s] 97%|█████████▋| 112/115 [00:06<00:00, 31.38it/s]100%|██████████| 115/115 [00:07<00:00, 16.18it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:25,  2.86s/it]  2%|▏         | 2/115 [00:02<02:20,  1.24s/it]  4%|▍         | 5/115 [00:03<00:41,  2.66it/s]  8%|▊         | 9/115 [00:03<00:18,  5.65it/s] 11%|█▏        | 13/115 [00:03<00:11,  8.90it/s] 15%|█▍        | 17/115 [00:03<00:07, 12.49it/s] 18%|█▊        | 21/115 [00:03<00:05, 16.08it/s] 22%|██▏       | 25/115 [00:03<00:04, 19.39it/s] 25%|██▌       | 29/115 [00:03<00:03, 21.71it/s] 28%|██▊       | 32/115 [00:03<00:03, 22.61it/s] 30%|███       | 35/115 [00:04<00:03, 23.02it/s] 33%|███▎      | 38/115 [00:04<00:03, 24.50it/s] 36%|███▌      | 41/115 [00:04<00:02, 25.66it/s] 39%|███▉      | 45/115 [00:04<00:02, 27.46it/s] 42%|████▏     | 48/115 [00:04<00:02, 27.28it/s] 45%|████▌     | 52/115 [00:04<00:02, 28.36it/s] 49%|████▊     | 56/115 [00:04<00:02, 28.65it/s] 52%|█████▏    | 60/115 [00:04<00:01, 29.61it/s] 56%|█████▌    | 64/115 [00:05<00:01, 29.80it/s] 59%|█████▉    | 68/115 [00:05<00:01, 29.08it/s] 62%|██████▏   | 71/115 [00:05<00:01, 28.71it/s] 65%|██████▌   | 75/115 [00:05<00:01, 30.03it/s] 69%|██████▊   | 79/115 [00:05<00:01, 29.82it/s] 71%|███████▏  | 82/115 [00:05<00:01, 29.03it/s] 75%|███████▍  | 86/115 [00:05<00:00, 30.22it/s] 78%|███████▊  | 90/115 [00:05<00:00, 31.06it/s] 82%|████████▏ | 94/115 [00:06<00:00, 31.57it/s] 85%|████████▌ | 98/115 [00:06<00:00, 32.74it/s] 89%|████████▊ | 102/115 [00:06<00:00, 33.60it/s] 92%|█████████▏| 106/115 [00:06<00:00, 34.18it/s] 96%|█████████▌| 110/115 [00:06<00:00, 34.62it/s] 99%|█████████▉| 114/115 [00:06<00:00, 34.44it/s]100%|██████████| 115/115 [00:06<00:00, 16.77it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7339720129966736


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 72.88089397656037
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.4888459494279
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.137113527702


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.39720153808594
=========================          END          =========================
0it [00:00, ?it/s]1it [00:01,  1.78s/it]2it [00:03,  1.88s/it]3it [00:05,  2.04s/it]4it [00:07,  1.87s/it]5it [00:09,  1.73s/it]6it [00:10,  1.60s/it]7it [00:12,  1.62s/it]8it [00:13,  1.52s/it]9it [00:14,  1.49s/it]10it [00:16,  1.49s/it]11it [00:17,  1.44s/it]12it [00:18,  1.35s/it]13it [00:20,  1.34s/it]14it [00:21,  1.45s/it]15it [00:23,  1.61s/it]16it [00:25,  1.66s/it]17it [00:27,  1.69s/it]18it [00:29,  1.74s/it]19it [00:30,  1.76s/it]20it [00:32,  1.60s/it]21it [00:33,  1.43s/it]22it [00:34,  1.38s/it]23it [00:35,  1.33s/it]24it [00:37,  1.37s/it]25it [00:38,  1.30s/it]26it [00:39,  1.22s/it]27it [00:40,  1.17s/it]28it [00:41,  1.17s/it]29it [00:43,  1.29s/it]30it [00:44,  1.25s/it]31it [00:45,  1.23s/it]32it [00:46,  1.19s/it]33it [00:47,  1.23s/it]34it [00:49,  1.25s/it]35it [00:50,  1.36s/it]36it [00:52,  1.47s/it]37it [00:54,  1.60s/it]38it [00:56,  1.63s/it]39it [00:57,  1.54s/it]40it [00:59,  1.56s/it]41it [01:00,  1.53s/it]42it [01:02,  1.55s/it]43it [01:03,  1.48s/it]44it [01:04,  1.49s/it]45it [01:06,  1.52s/it]46it [01:07,  1.46s/it]47it [01:09,  1.38s/it]48it [01:10,  1.35s/it]49it [01:11,  1.42s/it]50it [01:13,  1.47s/it]51it [01:15,  1.49s/it]52it [01:16,  1.37s/it]53it [01:17,  1.25s/it]54it [01:18,  1.18s/it]55it [01:19,  1.23s/it]56it [01:20,  1.28s/it]57it [01:22,  1.39s/it]58it [01:23,  1.31s/it]59it [01:24,  1.28s/it]60it [01:25,  1.20s/it]61it [01:26,  1.01it/s]62it [01:26,  1.15it/s]63it [01:27,  1.41it/s]64it [01:27,  1.48it/s]65it [01:28,  1.65it/s]66it [01:28,  1.80it/s]67it [01:28,  2.23it/s]68it [01:29,  2.12it/s]69it [01:29,  2.18it/s]70it [01:30,  1.78it/s]71it [01:31,  1.62it/s]72it [01:32,  1.51it/s]73it [01:32,  1.74it/s]74it [01:33,  1.30it/s]75it [01:34,  1.14it/s]76it [01:36,  1.13s/it]77it [01:37,  1.14s/it]78it [01:38,  1.07s/it]79it [01:39,  1.07s/it]80it [01:41,  1.12s/it]81it [01:42,  1.11s/it]82it [01:43,  1.13s/it]83it [01:44,  1.09s/it]84it [01:45,  1.02s/it]85it [01:46,  1.10s/it]86it [01:47,  1.09s/it]87it [01:48,  1.10s/it]88it [01:49,  1.07s/it]89it [01:50,  1.02s/it]90it [01:51,  1.00s/it]91it [01:53,  1.22s/it]92it [01:54,  1.16s/it]93it [01:55,  1.15s/it]94it [01:56,  1.19s/it]95it [01:57,  1.14s/it]96it [01:58,  1.08s/it]97it [01:59,  1.08s/it]98it [02:00,  1.04s/it]99it [02:01,  1.06s/it]100it [02:02,  1.01s/it]101it [02:03,  1.00it/s]102it [02:04,  1.00s/it]103it [02:05,  1.01s/it]104it [02:06,  1.03it/s]106it [02:07,  1.45it/s]107it [02:07,  1.60it/s]108it [02:07,  1.90it/s]109it [02:08,  1.76it/s]110it [02:09,  1.72it/s]111it [02:09,  1.64it/s]111it [02:09,  1.17s/it]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:16,  2.78s/it]  2%|▏         | 2/115 [00:02<02:17,  1.22s/it]  3%|▎         | 4/115 [00:03<00:56,  1.96it/s]  5%|▌         | 6/115 [00:03<00:32,  3.38it/s]  7%|▋         | 8/115 [00:03<00:21,  5.03it/s]  9%|▊         | 10/115 [00:03<00:15,  6.80it/s] 10%|█         | 12/115 [00:03<00:11,  8.60it/s] 12%|█▏        | 14/115 [00:03<00:09, 10.42it/s] 14%|█▍        | 16/115 [00:03<00:08, 12.04it/s] 16%|█▌        | 18/115 [00:03<00:07, 13.29it/s] 17%|█▋        | 20/115 [00:03<00:06, 14.35it/s] 19%|█▉        | 22/115 [00:04<00:06, 14.48it/s] 21%|██        | 24/115 [00:04<00:06, 13.16it/s] 23%|██▎       | 26/115 [00:04<00:06, 14.22it/s] 24%|██▍       | 28/115 [00:04<00:05, 14.94it/s] 26%|██▌       | 30/115 [00:04<00:05, 15.85it/s] 28%|██▊       | 32/115 [00:04<00:05, 16.55it/s] 30%|███       | 35/115 [00:04<00:04, 19.95it/s] 33%|███▎      | 38/115 [00:05<00:04, 19.14it/s] 35%|███▍      | 40/115 [00:05<00:04, 18.52it/s] 37%|███▋      | 43/115 [00:05<00:03, 20.12it/s] 40%|████      | 46/115 [00:05<00:03, 19.45it/s] 42%|████▏     | 48/115 [00:05<00:03, 19.05it/s] 43%|████▎     | 50/115 [00:05<00:03, 18.82it/s] 45%|████▌     | 52/115 [00:05<00:03, 18.52it/s] 47%|████▋     | 54/115 [00:05<00:03, 17.98it/s] 50%|████▉     | 57/115 [00:05<00:02, 20.74it/s] 52%|█████▏    | 60/115 [00:06<00:02, 20.07it/s] 55%|█████▍    | 63/115 [00:06<00:02, 20.44it/s] 57%|█████▋    | 66/115 [00:06<00:02, 19.44it/s] 59%|█████▉    | 68/115 [00:06<00:02, 18.79it/s] 61%|██████    | 70/115 [00:06<00:02, 18.34it/s] 63%|██████▎   | 72/115 [00:06<00:02, 18.23it/s] 64%|██████▍   | 74/115 [00:06<00:02, 18.02it/s] 66%|██████▌   | 76/115 [00:07<00:02, 17.68it/s] 69%|██████▊   | 79/115 [00:07<00:01, 18.67it/s] 70%|███████   | 81/115 [00:07<00:01, 17.57it/s] 72%|███████▏  | 83/115 [00:07<00:01, 17.10it/s] 74%|███████▍  | 85/115 [00:07<00:01, 17.26it/s] 76%|███████▌  | 87/115 [00:07<00:01, 17.40it/s] 77%|███████▋  | 89/115 [00:07<00:01, 17.61it/s] 80%|████████  | 92/115 [00:07<00:01, 20.26it/s] 83%|████████▎ | 95/115 [00:08<00:00, 21.33it/s] 85%|████████▌ | 98/115 [00:08<00:00, 20.63it/s] 88%|████████▊ | 101/115 [00:08<00:00, 20.72it/s] 90%|█████████ | 104/115 [00:08<00:00, 21.27it/s] 93%|█████████▎| 107/115 [00:08<00:00, 20.77it/s] 96%|█████████▌| 110/115 [00:08<00:00, 20.04it/s] 98%|█████████▊| 113/115 [00:08<00:00, 19.66it/s]100%|██████████| 115/115 [00:09<00:00, 12.43it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:04<07:40,  4.04s/it]  3%|▎         | 3/115 [00:04<02:01,  1.09s/it]  4%|▍         | 5/115 [00:04<01:01,  1.79it/s]  7%|▋         | 8/115 [00:04<00:30,  3.49it/s]  9%|▊         | 10/115 [00:04<00:22,  4.73it/s] 10%|█         | 12/115 [00:04<00:16,  6.24it/s] 12%|█▏        | 14/115 [00:04<00:12,  7.85it/s] 14%|█▍        | 16/115 [00:04<00:10,  9.41it/s] 16%|█▌        | 18/115 [00:04<00:08, 11.21it/s] 17%|█▋        | 20/115 [00:05<00:07, 12.67it/s] 19%|█▉        | 22/115 [00:05<00:06, 13.78it/s] 22%|██▏       | 25/115 [00:05<00:05, 16.68it/s] 23%|██▎       | 27/115 [00:05<00:05, 16.65it/s] 26%|██▌       | 30/115 [00:05<00:04, 18.73it/s] 29%|██▊       | 33/115 [00:05<00:04, 18.26it/s] 30%|███       | 35/115 [00:05<00:04, 18.37it/s] 32%|███▏      | 37/115 [00:05<00:04, 18.71it/s] 34%|███▍      | 39/115 [00:06<00:04, 18.46it/s] 37%|███▋      | 43/115 [00:06<00:03, 20.84it/s] 40%|████      | 46/115 [00:06<00:03, 20.67it/s] 43%|████▎     | 49/115 [00:06<00:03, 21.95it/s] 45%|████▌     | 52/115 [00:06<00:03, 20.01it/s] 48%|████▊     | 55/115 [00:06<00:03, 19.52it/s] 50%|█████     | 58/115 [00:06<00:02, 20.53it/s] 53%|█████▎    | 61/115 [00:07<00:02, 19.34it/s] 55%|█████▍    | 63/115 [00:07<00:02, 18.69it/s] 57%|█████▋    | 65/115 [00:07<00:02, 18.21it/s] 59%|█████▉    | 68/115 [00:07<00:02, 19.38it/s] 61%|██████    | 70/115 [00:07<00:02, 19.08it/s] 63%|██████▎   | 73/115 [00:07<00:02, 20.54it/s] 66%|██████▌   | 76/115 [00:07<00:01, 20.31it/s] 69%|██████▊   | 79/115 [00:07<00:01, 21.19it/s] 71%|███████▏  | 82/115 [00:08<00:01, 21.30it/s] 74%|███████▍  | 85/115 [00:08<00:01, 21.54it/s] 77%|███████▋  | 88/115 [00:08<00:01, 23.24it/s] 79%|███████▉  | 91/115 [00:08<00:01, 21.64it/s] 82%|████████▏ | 94/115 [00:08<00:01, 20.45it/s] 84%|████████▍ | 97/115 [00:08<00:00, 19.85it/s] 87%|████████▋ | 100/115 [00:09<00:00, 19.49it/s] 89%|████████▊ | 102/115 [00:09<00:00, 19.30it/s] 90%|█████████ | 104/115 [00:09<00:00, 18.92it/s] 92%|█████████▏| 106/115 [00:09<00:00, 18.82it/s] 95%|█████████▍| 109/115 [00:09<00:00, 19.87it/s] 97%|█████████▋| 112/115 [00:09<00:00, 20.47it/s]100%|██████████| 115/115 [00:09<00:00, 20.07it/s]100%|██████████| 115/115 [00:10<00:00, 11.47it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7395657300949097


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 73.01717089125103
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.72997376327056
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.52119990456325


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.95657348632812
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  9.72it/s]3it [00:00, 13.82it/s]5it [00:00, 12.42it/s]7it [00:00, 11.52it/s]9it [00:00, 12.20it/s]11it [00:00, 11.97it/s]13it [00:01, 10.84it/s]15it [00:01,  9.04it/s]16it [00:01,  9.09it/s]17it [00:01,  9.26it/s]18it [00:01,  8.18it/s]19it [00:02,  5.75it/s]20it [00:02,  4.87it/s]21it [00:02,  5.50it/s]23it [00:02,  7.30it/s]24it [00:02,  5.98it/s]26it [00:03,  7.50it/s]28it [00:03,  9.23it/s]30it [00:03, 11.12it/s]32it [00:03, 11.78it/s]34it [00:03, 11.06it/s]36it [00:03, 10.70it/s]38it [00:04,  9.14it/s]40it [00:04,  8.10it/s]41it [00:04,  8.16it/s]42it [00:05,  5.84it/s]43it [00:05,  6.21it/s]44it [00:05,  4.47it/s]45it [00:06,  2.99it/s]46it [00:06,  2.99it/s]48it [00:06,  4.58it/s]50it [00:06,  6.16it/s]52it [00:06,  7.57it/s]54it [00:07,  7.85it/s]56it [00:07,  8.60it/s]58it [00:07,  8.77it/s]59it [00:07,  8.43it/s]60it [00:08,  6.45it/s]61it [00:08,  6.39it/s]62it [00:08,  6.95it/s]63it [00:08,  7.37it/s]65it [00:08,  8.53it/s]66it [00:08,  8.45it/s]68it [00:08,  8.84it/s]70it [00:09, 10.05it/s]72it [00:09, 11.11it/s]74it [00:09, 12.26it/s]76it [00:09, 12.61it/s]78it [00:09, 10.60it/s]80it [00:10,  5.53it/s]81it [00:10,  4.87it/s]82it [00:10,  5.14it/s]84it [00:11,  4.71it/s]86it [00:11,  6.03it/s]88it [00:11,  7.28it/s]90it [00:11,  8.55it/s]92it [00:12,  9.23it/s]94it [00:12,  8.56it/s]96it [00:12,  9.85it/s]98it [00:12, 11.03it/s]100it [00:12, 11.96it/s]102it [00:12, 11.94it/s]104it [00:13, 12.33it/s]106it [00:13, 11.33it/s]108it [00:13,  9.92it/s]110it [00:13,  9.19it/s]111it [00:13,  8.91it/s]111it [00:13,  7.95it/s]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<03:57,  2.08s/it]  3%|▎         | 3/115 [00:02<01:04,  1.73it/s]  4%|▍         | 5/115 [00:02<00:33,  3.24it/s]  7%|▋         | 8/115 [00:02<00:18,  5.74it/s]  9%|▊         | 10/115 [00:02<00:14,  7.39it/s] 10%|█         | 12/115 [00:02<00:11,  9.08it/s] 12%|█▏        | 14/115 [00:02<00:09, 10.82it/s] 14%|█▍        | 16/115 [00:02<00:07, 12.44it/s] 16%|█▌        | 18/115 [00:03<00:07, 13.85it/s] 18%|█▊        | 21/115 [00:03<00:06, 15.62it/s] 20%|██        | 23/115 [00:03<00:05, 16.44it/s] 22%|██▏       | 25/115 [00:03<00:05, 16.81it/s] 23%|██▎       | 27/115 [00:03<00:05, 16.97it/s] 25%|██▌       | 29/115 [00:03<00:04, 17.42it/s] 27%|██▋       | 31/115 [00:03<00:04, 17.75it/s] 30%|██▉       | 34/115 [00:03<00:04, 18.43it/s] 31%|███▏      | 36/115 [00:03<00:04, 18.62it/s] 34%|███▍      | 39/115 [00:04<00:03, 19.17it/s] 36%|███▌      | 41/115 [00:04<00:03, 18.85it/s] 37%|███▋      | 43/115 [00:04<00:03, 18.79it/s] 40%|████      | 46/115 [00:04<00:03, 19.09it/s] 42%|████▏     | 48/115 [00:04<00:03, 18.70it/s] 43%|████▎     | 50/115 [00:04<00:03, 18.46it/s] 45%|████▌     | 52/115 [00:04<00:03, 18.48it/s] 47%|████▋     | 54/115 [00:04<00:03, 18.78it/s] 49%|████▊     | 56/115 [00:05<00:03, 18.40it/s] 50%|█████     | 58/115 [00:05<00:03, 18.52it/s] 52%|█████▏    | 60/115 [00:05<00:03, 18.21it/s] 54%|█████▍    | 62/115 [00:05<00:02, 18.49it/s] 56%|█████▌    | 64/115 [00:05<00:02, 18.16it/s] 57%|█████▋    | 66/115 [00:05<00:02, 18.04it/s] 59%|█████▉    | 68/115 [00:05<00:02, 18.52it/s] 61%|██████    | 70/115 [00:05<00:02, 18.16it/s] 63%|██████▎   | 72/115 [00:05<00:02, 17.93it/s] 64%|██████▍   | 74/115 [00:06<00:02, 17.96it/s] 66%|██████▌   | 76/115 [00:06<00:02, 18.12it/s] 68%|██████▊   | 78/115 [00:06<00:02, 18.27it/s] 70%|██████▉   | 80/115 [00:06<00:01, 18.34it/s] 72%|███████▏  | 83/115 [00:06<00:01, 18.61it/s] 74%|███████▍  | 85/115 [00:06<00:01, 18.35it/s] 76%|███████▌  | 87/115 [00:06<00:01, 18.24it/s] 77%|███████▋  | 89/115 [00:06<00:01, 18.19it/s] 80%|████████  | 92/115 [00:06<00:01, 18.60it/s] 82%|████████▏ | 94/115 [00:07<00:01, 18.63it/s] 83%|████████▎ | 96/115 [00:07<00:01, 18.48it/s] 85%|████████▌ | 98/115 [00:07<00:00, 18.40it/s] 87%|████████▋ | 100/115 [00:07<00:00, 18.76it/s] 89%|████████▊ | 102/115 [00:07<00:00, 18.83it/s] 90%|█████████ | 104/115 [00:07<00:00, 18.51it/s] 92%|█████████▏| 106/115 [00:07<00:00, 18.26it/s] 94%|█████████▍| 108/115 [00:07<00:00, 18.31it/s] 96%|█████████▌| 110/115 [00:07<00:00, 18.45it/s] 97%|█████████▋| 112/115 [00:08<00:00, 18.56it/s] 99%|█████████▉| 114/115 [00:08<00:00, 18.89it/s]100%|██████████| 115/115 [00:08<00:00, 13.75it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<03:56,  2.07s/it]  3%|▎         | 3/115 [00:02<01:04,  1.73it/s]  4%|▍         | 5/115 [00:02<00:33,  3.24it/s]  7%|▋         | 8/115 [00:02<00:18,  5.80it/s]  9%|▊         | 10/115 [00:02<00:14,  7.48it/s] 11%|█▏        | 13/115 [00:02<00:10, 10.15it/s] 13%|█▎        | 15/115 [00:02<00:08, 11.61it/s] 15%|█▍        | 17/115 [00:02<00:07, 13.02it/s] 17%|█▋        | 19/115 [00:03<00:06, 14.20it/s] 18%|█▊        | 21/115 [00:03<00:06, 15.31it/s] 20%|██        | 23/115 [00:03<00:05, 16.06it/s] 22%|██▏       | 25/115 [00:03<00:05, 16.43it/s] 23%|██▎       | 27/115 [00:03<00:05, 16.96it/s] 25%|██▌       | 29/115 [00:03<00:04, 17.43it/s] 27%|██▋       | 31/115 [00:03<00:04, 17.77it/s] 29%|██▊       | 33/115 [00:03<00:04, 18.01it/s] 31%|███▏      | 36/115 [00:03<00:04, 19.08it/s] 33%|███▎      | 38/115 [00:04<00:04, 18.58it/s] 36%|███▌      | 41/115 [00:04<00:03, 19.27it/s] 37%|███▋      | 43/115 [00:04<00:03, 18.87it/s] 39%|███▉      | 45/115 [00:04<00:03, 18.80it/s] 41%|████      | 47/115 [00:04<00:03, 18.74it/s] 43%|████▎     | 49/115 [00:04<00:03, 18.68it/s] 45%|████▌     | 52/115 [00:04<00:03, 19.35it/s] 48%|████▊     | 55/115 [00:04<00:03, 19.42it/s] 50%|████▉     | 57/115 [00:05<00:03, 19.04it/s] 52%|█████▏    | 60/115 [00:05<00:02, 19.11it/s] 55%|█████▍    | 63/115 [00:05<00:02, 19.32it/s] 57%|█████▋    | 65/115 [00:05<00:02, 19.37it/s] 58%|█████▊    | 67/115 [00:05<00:02, 19.28it/s] 60%|██████    | 69/115 [00:05<00:02, 18.82it/s] 62%|██████▏   | 71/115 [00:05<00:02, 18.41it/s] 64%|██████▍   | 74/115 [00:05<00:02, 18.94it/s] 66%|██████▌   | 76/115 [00:06<00:02, 18.77it/s] 69%|██████▊   | 79/115 [00:06<00:01, 19.35it/s] 70%|███████   | 81/115 [00:06<00:01, 19.02it/s] 73%|███████▎  | 84/115 [00:06<00:01, 19.44it/s] 75%|███████▍  | 86/115 [00:06<00:01, 19.15it/s] 77%|███████▋  | 89/115 [00:06<00:01, 19.71it/s] 79%|███████▉  | 91/115 [00:06<00:01, 19.29it/s] 81%|████████  | 93/115 [00:06<00:01, 19.08it/s] 83%|████████▎ | 95/115 [00:07<00:01, 18.99it/s] 84%|████████▍ | 97/115 [00:07<00:00, 18.94it/s] 86%|████████▌ | 99/115 [00:07<00:00, 18.91it/s] 88%|████████▊ | 101/115 [00:07<00:00, 18.86it/s] 90%|████████▉ | 103/115 [00:07<00:00, 18.83it/s] 92%|█████████▏| 106/115 [00:07<00:00, 19.48it/s] 95%|█████████▍| 109/115 [00:07<00:00, 19.84it/s] 97%|█████████▋| 111/115 [00:07<00:00, 19.36it/s] 98%|█████████▊| 113/115 [00:07<00:00, 19.11it/s]100%|██████████| 115/115 [00:08<00:00, 14.04it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7419168949127197


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 73.07168165712729
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.74140293518558
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.25463115986153


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 74.19168853759766
=========================          END          =========================
0it [00:00, ?it/s]1it [00:00,  2.60it/s]2it [00:01,  1.64it/s]3it [00:01,  1.49it/s]4it [00:02,  1.65it/s]5it [00:02,  2.00it/s]6it [00:02,  2.49it/s]7it [00:03,  2.11it/s]8it [00:04,  1.89it/s]9it [00:04,  1.74it/s]10it [00:05,  2.16it/s]11it [00:05,  2.40it/s]12it [00:06,  2.07it/s]13it [00:06,  1.91it/s]14it [00:07,  1.83it/s]15it [00:07,  1.66it/s]16it [00:08,  1.50it/s]17it [00:09,  1.36it/s]18it [00:10,  1.30it/s]19it [00:11,  1.41it/s]20it [00:11,  1.41it/s]21it [00:12,  1.20it/s]22it [00:14,  1.09it/s]23it [00:15,  1.04it/s]24it [00:16,  1.02s/it]25it [00:17,  1.02s/it]26it [00:18,  1.09s/it]27it [00:19,  1.10s/it]28it [00:20,  1.12s/it]29it [00:21,  1.06s/it]30it [00:22,  1.05s/it]31it [00:23,  1.06s/it]32it [00:24,  1.07s/it]33it [00:26,  1.13s/it]34it [00:27,  1.27s/it]35it [00:29,  1.43s/it]36it [00:30,  1.40s/it]37it [00:32,  1.31s/it]38it [00:33,  1.40s/it]39it [00:34,  1.34s/it]40it [00:36,  1.28s/it]41it [00:37,  1.30s/it]42it [00:38,  1.25s/it]43it [00:39,  1.16s/it]44it [00:40,  1.14s/it]45it [00:41,  1.12s/it]46it [00:42,  1.10s/it]47it [00:43,  1.08s/it]48it [00:44,  1.10s/it]49it [00:45,  1.11s/it]50it [00:47,  1.13s/it]51it [00:48,  1.05s/it]52it [00:48,  1.02s/it]53it [00:50,  1.02s/it]54it [00:50,  1.01it/s]55it [00:51,  1.13it/s]56it [00:51,  1.38it/s]57it [00:52,  1.48it/s]58it [00:53,  1.49it/s]59it [00:53,  1.68it/s]60it [00:54,  1.64it/s]61it [00:54,  1.58it/s]62it [00:55,  1.56it/s]63it [00:56,  1.35it/s]64it [00:57,  1.39it/s]65it [00:57,  1.55it/s]66it [00:58,  1.59it/s]67it [00:58,  1.74it/s]68it [00:59,  1.77it/s]69it [00:59,  1.93it/s]70it [00:59,  2.38it/s]71it [01:00,  2.10it/s]72it [01:01,  1.99it/s]73it [01:01,  1.82it/s]74it [01:02,  1.49it/s]75it [01:03,  1.71it/s]76it [01:03,  1.78it/s]77it [01:04,  1.73it/s]78it [01:04,  1.68it/s]79it [01:05,  1.96it/s]80it [01:05,  1.70it/s]81it [01:06,  2.11it/s]82it [01:06,  2.34it/s]83it [01:06,  2.41it/s]84it [01:07,  2.46it/s]85it [01:07,  2.72it/s]86it [01:07,  3.04it/s]87it [01:07,  3.58it/s]88it [01:08,  3.80it/s]89it [01:08,  3.21it/s]90it [01:08,  2.74it/s]91it [01:09,  3.02it/s]92it [01:09,  2.30it/s]93it [01:10,  2.03it/s]94it [01:11,  1.78it/s]95it [01:12,  1.52it/s]96it [01:13,  1.26it/s]97it [01:14,  1.15it/s]98it [01:15,  1.10it/s]99it [01:15,  1.19it/s]100it [01:16,  1.58it/s]102it [01:16,  2.65it/s]104it [01:16,  3.95it/s]105it [01:16,  4.35it/s]106it [01:16,  4.90it/s]107it [01:16,  5.23it/s]109it [01:17,  6.81it/s]110it [01:17,  6.12it/s]111it [01:17,  6.12it/s]111it [01:17,  1.43it/s]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<03:39,  1.93s/it]  3%|▎         | 3/115 [00:02<01:03,  1.77it/s]  4%|▍         | 5/115 [00:02<00:33,  3.25it/s]  6%|▌         | 7/115 [00:02<00:21,  4.99it/s]  8%|▊         | 9/115 [00:02<00:15,  6.95it/s] 10%|▉         | 11/115 [00:02<00:11,  8.81it/s] 11%|█▏        | 13/115 [00:02<00:09, 10.54it/s] 13%|█▎        | 15/115 [00:02<00:08, 12.19it/s] 15%|█▍        | 17/115 [00:02<00:07, 13.68it/s] 17%|█▋        | 19/115 [00:02<00:06, 15.14it/s] 18%|█▊        | 21/115 [00:03<00:05, 15.86it/s] 20%|██        | 23/115 [00:03<00:05, 16.30it/s] 22%|██▏       | 25/115 [00:03<00:05, 16.87it/s] 23%|██▎       | 27/115 [00:03<00:05, 17.01it/s] 25%|██▌       | 29/115 [00:03<00:05, 17.02it/s] 27%|██▋       | 31/115 [00:03<00:04, 17.16it/s] 29%|██▊       | 33/115 [00:03<00:04, 17.05it/s] 30%|███       | 35/115 [00:03<00:04, 16.70it/s] 32%|███▏      | 37/115 [00:04<00:04, 17.05it/s] 34%|███▍      | 39/115 [00:04<00:04, 17.54it/s] 36%|███▌      | 41/115 [00:04<00:04, 17.60it/s] 37%|███▋      | 43/115 [00:04<00:04, 17.81it/s] 39%|███▉      | 45/115 [00:04<00:03, 17.89it/s] 41%|████      | 47/115 [00:04<00:03, 18.38it/s] 43%|████▎     | 49/115 [00:04<00:03, 18.07it/s] 44%|████▍     | 51/115 [00:04<00:03, 18.20it/s] 46%|████▌     | 53/115 [00:04<00:03, 17.96it/s] 48%|████▊     | 55/115 [00:05<00:03, 18.07it/s] 50%|████▉     | 57/115 [00:05<00:03, 18.10it/s] 51%|█████▏    | 59/115 [00:05<00:03, 18.24it/s] 53%|█████▎    | 61/115 [00:05<00:02, 18.64it/s] 55%|█████▍    | 63/115 [00:05<00:02, 18.21it/s] 57%|█████▋    | 65/115 [00:05<00:02, 17.92it/s] 58%|█████▊    | 67/115 [00:05<00:02, 18.11it/s] 60%|██████    | 69/115 [00:05<00:02, 18.27it/s] 62%|██████▏   | 71/115 [00:05<00:02, 18.34it/s] 63%|██████▎   | 73/115 [00:05<00:02, 18.40it/s] 65%|██████▌   | 75/115 [00:06<00:02, 18.84it/s] 67%|██████▋   | 77/115 [00:06<00:02, 17.47it/s] 69%|██████▊   | 79/115 [00:06<00:02, 15.10it/s] 70%|███████   | 81/115 [00:06<00:02, 14.84it/s] 72%|███████▏  | 83/115 [00:06<00:02, 15.67it/s] 74%|███████▍  | 85/115 [00:06<00:01, 16.48it/s] 76%|███████▌  | 87/115 [00:06<00:01, 17.11it/s] 77%|███████▋  | 89/115 [00:06<00:01, 17.58it/s] 79%|███████▉  | 91/115 [00:07<00:01, 17.92it/s] 81%|████████  | 93/115 [00:07<00:01, 18.17it/s] 83%|████████▎ | 96/115 [00:07<00:01, 18.68it/s] 85%|████████▌ | 98/115 [00:07<00:00, 18.42it/s] 87%|████████▋ | 100/115 [00:07<00:00, 18.24it/s] 89%|████████▊ | 102/115 [00:07<00:00, 18.10it/s] 90%|█████████ | 104/115 [00:07<00:00, 18.19it/s] 92%|█████████▏| 106/115 [00:07<00:00, 18.05it/s] 94%|█████████▍| 108/115 [00:08<00:00, 17.47it/s] 96%|█████████▌| 110/115 [00:08<00:00, 17.29it/s] 97%|█████████▋| 112/115 [00:08<00:00, 17.46it/s] 99%|█████████▉| 114/115 [00:08<00:00, 17.62it/s]100%|██████████| 115/115 [00:08<00:00, 13.44it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<04:09,  2.19s/it]  3%|▎         | 3/115 [00:02<01:08,  1.64it/s]  4%|▍         | 5/115 [00:02<00:35,  3.09it/s]  6%|▌         | 7/115 [00:02<00:22,  4.74it/s]  8%|▊         | 9/115 [00:02<00:16,  6.60it/s] 10%|▉         | 11/115 [00:02<00:12,  8.47it/s] 11%|█▏        | 13/115 [00:02<00:09, 10.32it/s] 13%|█▎        | 15/115 [00:02<00:08, 12.04it/s] 15%|█▍        | 17/115 [00:03<00:07, 13.51it/s] 17%|█▋        | 19/115 [00:03<00:06, 14.66it/s] 18%|█▊        | 21/115 [00:03<00:06, 15.62it/s] 20%|██        | 23/115 [00:03<00:05, 16.12it/s] 22%|██▏       | 25/115 [00:03<00:05, 16.58it/s] 23%|██▎       | 27/115 [00:03<00:05, 16.95it/s] 25%|██▌       | 29/115 [00:03<00:04, 17.45it/s] 27%|██▋       | 31/115 [00:03<00:04, 17.62it/s] 29%|██▊       | 33/115 [00:03<00:04, 17.65it/s] 30%|███       | 35/115 [00:04<00:04, 17.82it/s] 32%|███▏      | 37/115 [00:04<00:04, 17.56it/s] 34%|███▍      | 39/115 [00:04<00:04, 17.64it/s] 36%|███▌      | 41/115 [00:04<00:04, 17.58it/s] 37%|███▋      | 43/115 [00:04<00:04, 17.67it/s] 39%|███▉      | 45/115 [00:04<00:04, 17.49it/s] 41%|████      | 47/115 [00:04<00:03, 17.60it/s] 43%|████▎     | 49/115 [00:04<00:03, 18.05it/s] 44%|████▍     | 51/115 [00:04<00:03, 17.74it/s] 46%|████▌     | 53/115 [00:05<00:03, 16.75it/s] 48%|████▊     | 55/115 [00:05<00:03, 16.83it/s] 50%|████▉     | 57/115 [00:05<00:03, 17.05it/s] 51%|█████▏    | 59/115 [00:05<00:03, 17.23it/s] 53%|█████▎    | 61/115 [00:05<00:03, 17.41it/s] 55%|█████▍    | 63/115 [00:05<00:03, 17.23it/s] 57%|█████▋    | 65/115 [00:05<00:02, 17.13it/s] 58%|█████▊    | 67/115 [00:05<00:02, 17.30it/s] 60%|██████    | 69/115 [00:06<00:02, 18.00it/s] 62%|██████▏   | 71/115 [00:06<00:02, 17.98it/s] 63%|██████▎   | 73/115 [00:06<00:02, 17.41it/s] 65%|██████▌   | 75/115 [00:06<00:02, 17.26it/s] 67%|██████▋   | 77/115 [00:06<00:02, 17.14it/s] 69%|██████▊   | 79/115 [00:06<00:02, 17.02it/s] 71%|███████▏  | 82/115 [00:06<00:01, 17.70it/s] 73%|███████▎  | 84/115 [00:06<00:01, 17.65it/s] 75%|███████▍  | 86/115 [00:07<00:01, 17.25it/s] 77%|███████▋  | 88/115 [00:07<00:01, 17.69it/s] 78%|███████▊  | 90/115 [00:07<00:01, 17.78it/s] 80%|████████  | 92/115 [00:07<00:01, 16.59it/s] 82%|████████▏ | 94/115 [00:07<00:01, 14.66it/s] 83%|████████▎ | 96/115 [00:07<00:01, 13.54it/s] 85%|████████▌ | 98/115 [00:07<00:01, 12.96it/s] 87%|████████▋ | 100/115 [00:08<00:01, 12.37it/s] 89%|████████▊ | 102/115 [00:08<00:01, 12.60it/s] 90%|█████████ | 104/115 [00:08<00:00, 13.85it/s] 92%|█████████▏| 106/115 [00:08<00:00, 15.02it/s] 94%|█████████▍| 108/115 [00:08<00:00, 15.96it/s] 96%|█████████▌| 110/115 [00:08<00:00, 16.68it/s] 98%|█████████▊| 113/115 [00:08<00:00, 17.69it/s]100%|██████████| 115/115 [00:09<00:00, 12.67it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7380269169807434


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 73.09893704006541
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.70474205222004
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.55467519027563


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.80268859863281
=========================          END          =========================
0it [00:00, ?it/s]2it [00:00, 18.08it/s]4it [00:00, 18.14it/s]6it [00:00, 18.16it/s]8it [00:00, 17.39it/s]11it [00:00, 17.68it/s]13it [00:00, 17.43it/s]15it [00:00, 16.66it/s]17it [00:00, 16.67it/s]20it [00:01, 18.41it/s]22it [00:01, 18.21it/s]24it [00:01, 18.23it/s]26it [00:01, 18.50it/s]28it [00:01, 18.31it/s]30it [00:01, 18.15it/s]32it [00:01, 16.32it/s]34it [00:01, 15.11it/s]36it [00:02, 14.87it/s]38it [00:02,  7.72it/s]40it [00:02,  8.96it/s]42it [00:03,  9.30it/s]44it [00:03,  8.45it/s]46it [00:04,  3.17it/s]47it [00:05,  2.29it/s]48it [00:06,  1.73it/s]49it [00:08,  1.48it/s]50it [00:09,  1.25it/s]51it [00:10,  1.07it/s]52it [00:11,  1.01it/s]53it [00:12,  1.01it/s]54it [00:14,  1.23s/it]55it [00:16,  1.37s/it]56it [00:17,  1.49s/it]57it [00:19,  1.52s/it]58it [00:21,  1.56s/it]59it [00:23,  1.63s/it]60it [00:24,  1.67s/it]61it [00:27,  1.87s/it]62it [00:29,  1.95s/it]63it [00:31,  1.93s/it]64it [00:32,  1.87s/it]65it [00:34,  1.80s/it]66it [00:36,  1.77s/it]67it [00:37,  1.75s/it]68it [00:39,  1.76s/it]69it [00:41,  1.89s/it]70it [00:44,  2.08s/it]71it [00:45,  1.91s/it]72it [00:47,  1.77s/it]73it [00:49,  1.77s/it]74it [00:51,  1.90s/it]75it [00:53,  1.85s/it]76it [00:54,  1.80s/it]77it [00:56,  1.79s/it]78it [00:58,  1.82s/it]79it [01:00,  1.88s/it]80it [01:02,  1.97s/it]81it [01:04,  1.90s/it]82it [01:05,  1.79s/it]83it [01:07,  1.77s/it]84it [01:09,  1.74s/it]85it [01:11,  1.76s/it]86it [01:12,  1.79s/it]87it [01:15,  1.94s/it]88it [01:17,  2.04s/it]89it [01:19,  2.15s/it]90it [01:22,  2.21s/it]91it [01:24,  2.14s/it]92it [01:26,  2.14s/it]93it [01:28,  2.15s/it]94it [01:30,  2.18s/it]95it [01:32,  2.17s/it]96it [01:35,  2.26s/it]97it [01:37,  2.28s/it]98it [01:39,  2.23s/it]99it [01:41,  2.05s/it]100it [01:43,  1.92s/it]101it [01:44,  1.88s/it]102it [01:46,  1.93s/it]103it [01:48,  1.94s/it]104it [01:50,  1.93s/it]105it [01:52,  1.82s/it]106it [01:54,  1.88s/it]107it [01:56,  1.83s/it]108it [01:57,  1.79s/it]109it [01:59,  1.75s/it]110it [02:01,  1.74s/it]111it [02:02,  1.73s/it]111it [02:02,  1.11s/it]
Number of selected candidates = 50
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 50
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:14,  2.76s/it]  3%|▎         | 4/115 [00:02<01:02,  1.77it/s]  6%|▌         | 7/115 [00:03<00:30,  3.57it/s]  9%|▊         | 10/115 [00:03<00:18,  5.77it/s] 12%|█▏        | 14/115 [00:03<00:11,  9.18it/s] 16%|█▌        | 18/115 [00:03<00:07, 12.82it/s] 18%|█▊        | 21/115 [00:03<00:06, 15.34it/s] 22%|██▏       | 25/115 [00:03<00:04, 18.97it/s] 25%|██▌       | 29/115 [00:03<00:04, 21.26it/s] 29%|██▊       | 33/115 [00:03<00:03, 23.70it/s] 31%|███▏      | 36/115 [00:03<00:03, 23.89it/s] 34%|███▍      | 39/115 [00:04<00:03, 24.73it/s] 37%|███▋      | 43/115 [00:04<00:02, 26.39it/s] 41%|████      | 47/115 [00:04<00:02, 26.26it/s] 43%|████▎     | 50/115 [00:04<00:02, 27.12it/s] 46%|████▌     | 53/115 [00:04<00:02, 27.67it/s] 49%|████▊     | 56/115 [00:04<00:02, 27.83it/s] 51%|█████▏    | 59/115 [00:04<00:02, 26.82it/s] 54%|█████▍    | 62/115 [00:04<00:01, 27.67it/s] 57%|█████▋    | 65/115 [00:05<00:01, 27.36it/s] 60%|██████    | 69/115 [00:05<00:01, 28.48it/s] 63%|██████▎   | 72/115 [00:05<00:01, 28.48it/s] 65%|██████▌   | 75/115 [00:05<00:01, 28.38it/s] 68%|██████▊   | 78/115 [00:05<00:01, 28.55it/s] 70%|███████   | 81/115 [00:05<00:01, 28.13it/s] 73%|███████▎  | 84/115 [00:05<00:01, 28.64it/s] 77%|███████▋  | 88/115 [00:05<00:00, 30.62it/s] 80%|████████  | 92/115 [00:05<00:00, 30.68it/s] 83%|████████▎ | 96/115 [00:06<00:00, 31.16it/s] 87%|████████▋ | 100/115 [00:06<00:00, 31.09it/s] 90%|█████████ | 104/115 [00:06<00:00, 32.10it/s] 94%|█████████▍| 108/115 [00:06<00:00, 32.05it/s] 97%|█████████▋| 112/115 [00:06<00:00, 32.05it/s]100%|██████████| 115/115 [00:06<00:00, 16.70it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<05:53,  3.10s/it]  3%|▎         | 3/115 [00:03<01:35,  1.17it/s]  5%|▌         | 6/115 [00:03<00:38,  2.83it/s]  9%|▊         | 10/115 [00:03<00:18,  5.57it/s] 12%|█▏        | 14/115 [00:03<00:11,  8.69it/s] 16%|█▌        | 18/115 [00:03<00:08, 12.00it/s] 19%|█▉        | 22/115 [00:03<00:05, 15.63it/s] 23%|██▎       | 26/115 [00:03<00:04, 19.09it/s] 26%|██▌       | 30/115 [00:04<00:03, 22.05it/s] 30%|██▉       | 34/115 [00:04<00:03, 25.00it/s] 33%|███▎      | 38/115 [00:04<00:02, 26.75it/s] 37%|███▋      | 42/115 [00:04<00:02, 27.08it/s] 40%|████      | 46/115 [00:04<00:02, 28.97it/s] 43%|████▎     | 50/115 [00:04<00:02, 30.21it/s] 47%|████▋     | 54/115 [00:04<00:01, 31.14it/s] 50%|█████     | 58/115 [00:04<00:01, 31.48it/s] 54%|█████▍    | 62/115 [00:05<00:01, 32.28it/s] 57%|█████▋    | 66/115 [00:05<00:01, 32.43it/s] 61%|██████    | 70/115 [00:05<00:01, 32.85it/s] 64%|██████▍   | 74/115 [00:05<00:01, 32.80it/s] 68%|██████▊   | 78/115 [00:05<00:01, 33.14it/s] 71%|███████▏  | 82/115 [00:05<00:01, 32.55it/s] 75%|███████▍  | 86/115 [00:05<00:00, 33.28it/s] 78%|███████▊  | 90/115 [00:05<00:00, 33.36it/s] 82%|████████▏ | 94/115 [00:06<00:00, 33.44it/s] 85%|████████▌ | 98/115 [00:06<00:00, 34.06it/s] 89%|████████▊ | 102/115 [00:06<00:00, 33.90it/s] 92%|█████████▏| 106/115 [00:06<00:00, 34.36it/s] 96%|█████████▌| 110/115 [00:06<00:00, 34.27it/s] 99%|█████████▉| 114/115 [00:06<00:00, 34.68it/s]100%|██████████| 115/115 [00:06<00:00, 16.73it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.7347964644432068


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 72.41755246661215
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 81.62620086983091
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 64.18915588771512


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 73.47964477539062
=========================          END          =========================


========================= ViLang Final Results of 10 runs, w/ 3 imgs per class=========================


[Clustering]
Clustering ACC: 72.88089397656037
Semantic ACC:   73.71189880371094
=========================          END          =========================
