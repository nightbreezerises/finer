Namespace(config_file_env='./configs/env_machine.yml', config_file_expt='./configs/expts/pet37_all.yml', alpha=0.7, N_tta=10, num_per_category='random', num_runs=10)
Number of GPUs: 1
Device ID: 0 Device Name: NVIDIA RTX A6000
['Bombay', 'Oriental Shorthair', 'Siamese', 'Tabby', 'British Shorthair', 'American Shorthair', 'Bulldog', 'Boxer', 'Pitbull', 'Boxer', 'Bulldog', 'Boston Terrier', 'Ragdoll', 'Bengal', 'Egyptian Mau', 'Ocicat', 'Yorkshire Terrier', 'Yorkie', 'Toy Terrier', 'Bombay', 'European Shorthair', 'American Shorthair', 'Maine Coon', 'Ragdoll', 'Siberian', 'Maine Coon', 'Norwegian Forest Cat', 'Ragdoll', 'English Foxhound', 'Boston Terrier', 'Boxer', 'Bullmastiff', 'American Bulldog', 'Scottie dog', 'Siamese', 'American Shorthair', 'British Shorthair', 'English Bulldog', 'Dalmatian', 'Maine Coon', 'British Shorthair', 'Ragdoll', 'Pit Bull', 'British Shorthair', 'Russian Blue', 'Korat', 'Cocker Spaniel', 'Cockapoo', 'English Springer Spaniel', 'Bombay', 'Oriental Shorthair', 'Japanese Bobtail', 'Basset Hound', 'Dachshund', 'English Bulldog', 'Bombay', 'Oriental Shorthair', 'Devon Rex', 'Boxer', 'Basset Hound', 'Beagle', 'Bloodhound', 'Ocicat', 'Bengal', 'Ocicat', 'Egyptian Mau', 'Basset Hound', 'Dachshund', 'Bloodhound', 'Tabby cat', 'American Shorthair', 'Bengal cat', 'Pointer', 'Pit Bull', 'American Staffordshire Terrier', 'Boxer', 'Samoyed', 'Eskimo Dog', 'White Shepherd', 'possible dog breeds', 'Abyssinian cat', 'Tabby', 'Bulldog', 'Pit Bull', 'American Staffordshire Terrier', 'Bull Terrier', 'Boxer', 'American Bulldog', 'Boston Terrier', 'Siamese', 'Maine Coon', 'British Shorthair', 'Bengal', 'Abyssinian', 'American Shorthair', 'Pug', 'French Bulldog', 'Boston Terrier', 'Rat Terrier', 'Jack Russell Terrier', 'American Eskimo Dog', 'Maine Coon', 'English Setter', 'Norwegian Elkhound', 'American Eskimo Dog', 'Egyptian Mau', 'Bulldog', 'Boxer', 'Shar Pei', 'Cocker Spaniel', 'Poodle', 'Bichon Frise', 'American Staffordshire Terrier', 'Savannah', 'Bengal', 'Tabby', 'Domestic Shorthair', 'Bengal', 'Egyptian Mau', 'Abyssinian', 'American Bobtail', 'Bengal', 'Toyger', 'Pug', 'Scottish Terrier', 'Tabby', 'Bengal', 'Abyssinian', 'British Shorthair', 'Maine Coon', 'Ragdoll', 'Bichon Frise', 'Smooth-coated Chihuahua', 'Boxer', 'Bulldog', 'Staffordshire Bull Terrier', 'Beagle', 'Dachshund', 'Basset Hound', 'Bombay', 'British Shorthair', 'Oriental Shorthair', 'Basset Hound', 'Bloodhound', 'Beagle', 'Short-haired Chihuahua', 'Beagle', 'Basset Hound', 'Harrier', 'British Shorthair', 'American Shorthair', 'Bengal', 'Basset Hound', 'Bloodhound', 'Dachshund', 'Pug', 'Bichon Frise', 'Boston Terrier', 'French Bulldog', 'Staffordshire Bull Terrier', 'Domestic Shorthair', 'Boxer', 'Great Dane', 'Boston Terrier', 'Tabby', 'American Shorthair', 'British Shorthair', 'Rottweiler', 'Bulldog', 'Boxer', 'Maine Coon', 'American Shorthair', 'Bengal', 'Scottie', 'Dachshund', 'Pug', 'Bichon Frise', 'Siamese', 'Bombay', 'Burmese', 'Beagle', 'Basset Hound', 'Dachshund', 'Bengal cat', 'Bulldog', 'Bullmastiff', 'Boxer', 'Boxer', 'Bulldog', 'Dalmatian', 'Boxer Mix', 'Basset Hound', 'Basset Hound', 'Dachshund', 'Beagle', 'Boxer', 'Dalmatian', 'Boston Terrier', 'British Blue', 'Russian Blue', 'Korat', 'Chihuahua', 'Pointer', 'Boxer', 'English Bulldog', 'Bulldog', 'Hound', 'Terrier', 'Bulldog', 'American Bulldog', 'French Bulldog', 'Bengal', 'Abyssinian', 'Egyptian Mau', 'Bengal', 'Mackerel Tabby', 'Abyssinian', 'Basset Hound', 'English Bulldog', 'Dalmatian', 'Harrier', 'Chihuahua', 'Poodle', 'Bichon Frise', 'Bengal', 'Border Collie', 'Boston Terrier', 'Boxer', 'Basset Hound', 'English Bulldog', 'Boston Terrier', 'St. Bernard', 'Bernese Mountain Dog', 'Newfoundland', 'Beagle', 'Maine Coon', 'Siberian', 'Norwegian Forest', 'Boston Terrier', 'Boxer', 'French Bulldog', 'Shih Tzu', 'Bichon Frise', 'Cairn Terrier', 'Siamese', 'American Shorthair', 'Shiba Inu', 'Shih Tzu', 'Poodle', 'Boxer', 'Bulldog', 'Great Dane', 'Abyssinian', 'Bengal', 'Oriental Shorthair', 'Boston Terrier', 'French Bulldog', 'Pug', 'Calico', 'British Shorthair', 'Maine Coon', 'Siamese cat', 'Maine Coon', 'British Shorthair', 'Scottish Fold', 'chihuahua', 'boston terrier', 'shih tzu', 'American Bulldog', 'Dachshund']
0it [00:00, ?it/s]1it [00:02,  2.41s/it]2it [00:04,  2.07s/it]3it [00:05,  1.88s/it]4it [00:08,  2.10s/it]5it [00:10,  2.23s/it]6it [00:12,  2.18s/it]7it [00:14,  2.12s/it]8it [00:17,  2.15s/it]9it [00:19,  2.12s/it]10it [00:21,  2.09s/it]11it [00:23,  2.08s/it]12it [00:24,  1.97s/it]13it [00:26,  1.92s/it]14it [00:28,  1.95s/it]15it [00:30,  1.92s/it]16it [00:32,  1.98s/it]17it [00:34,  2.06s/it]18it [00:37,  2.08s/it]19it [00:38,  2.01s/it]20it [00:40,  1.96s/it]21it [00:42,  1.93s/it]22it [00:44,  1.91s/it]23it [00:46,  1.93s/it]24it [00:48,  1.92s/it]25it [00:50,  2.06s/it]26it [00:52,  2.03s/it]27it [00:54,  2.02s/it]28it [00:56,  1.90s/it]29it [00:58,  1.86s/it]30it [01:00,  1.93s/it]31it [01:02,  2.01s/it]32it [01:04,  2.03s/it]33it [01:06,  1.99s/it]34it [01:08,  1.90s/it]35it [01:10,  2.08s/it]36it [01:12,  2.04s/it]37it [01:14,  2.05s/it]38it [01:16,  1.97s/it]39it [01:18,  1.95s/it]40it [01:20,  2.01s/it]41it [01:22,  2.05s/it]42it [01:24,  2.03s/it]43it [01:26,  2.05s/it]44it [01:28,  2.03s/it]45it [01:30,  1.97s/it]46it [01:32,  1.99s/it]47it [01:34,  1.95s/it]48it [01:36,  1.89s/it]49it [01:37,  1.83s/it]50it [01:39,  1.82s/it]51it [01:41,  1.91s/it]52it [01:43,  2.00s/it]53it [01:45,  1.90s/it]54it [01:47,  1.83s/it]55it [01:49,  1.83s/it]56it [01:51,  1.92s/it]57it [01:53,  1.92s/it]58it [01:55,  1.99s/it]59it [01:57,  1.99s/it]60it [01:59,  2.01s/it]61it [02:01,  2.04s/it]62it [02:03,  2.07s/it]63it [02:05,  2.03s/it]64it [02:07,  2.06s/it]65it [02:09,  2.06s/it]66it [02:11,  1.96s/it]67it [02:13,  2.03s/it]68it [02:15,  2.08s/it]69it [02:17,  1.99s/it]70it [02:19,  2.03s/it]71it [02:21,  2.02s/it]72it [02:23,  1.98s/it]73it [02:25,  1.84s/it]74it [02:26,  1.68s/it]75it [02:28,  1.64s/it]76it [02:31,  2.07s/it]77it [02:33,  2.29s/it]78it [02:36,  2.49s/it]79it [02:39,  2.55s/it]80it [02:42,  2.59s/it]81it [02:45,  2.65s/it]82it [02:47,  2.67s/it]83it [02:50,  2.74s/it]84it [02:53,  2.72s/it]85it [02:56,  2.86s/it]86it [02:59,  2.85s/it]87it [03:02,  2.88s/it]88it [03:05,  2.94s/it]89it [03:08,  3.01s/it]90it [03:11,  3.01s/it]91it [03:14,  2.89s/it]92it [03:16,  2.86s/it]93it [03:19,  2.88s/it]94it [03:22,  2.84s/it]95it [03:25,  2.81s/it]96it [03:28,  2.91s/it]97it [03:31,  2.87s/it]98it [03:34,  2.90s/it]99it [03:36,  2.84s/it]100it [03:39,  2.75s/it]101it [03:42,  2.69s/it]102it [03:44,  2.72s/it]103it [03:47,  2.76s/it]104it [03:49,  2.58s/it]105it [03:51,  2.41s/it]106it [03:53,  2.28s/it]107it [03:55,  2.19s/it]108it [03:57,  2.19s/it]109it [04:00,  2.24s/it]110it [04:02,  2.23s/it]111it [04:04,  2.16s/it]112it [04:06,  2.13s/it]113it [04:08,  2.16s/it]114it [04:11,  2.26s/it]115it [04:13,  2.30s/it]115it [04:13,  2.21s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:02<04:33,  2.40s/it]  2%|▏         | 2/115 [00:02<02:00,  1.06s/it]  5%|▌         | 6/115 [00:02<00:31,  3.41it/s]  9%|▊         | 10/115 [00:02<00:16,  6.42it/s] 12%|█▏        | 14/115 [00:03<00:10,  9.79it/s] 15%|█▍        | 17/115 [00:03<00:07, 12.40it/s] 17%|█▋        | 20/115 [00:04<00:17,  5.38it/s] 20%|██        | 23/115 [00:04<00:13,  7.08it/s] 23%|██▎       | 27/115 [00:04<00:08,  9.97it/s] 27%|██▋       | 31/115 [00:04<00:06, 13.06it/s] 30%|██▉       | 34/115 [00:05<00:06, 12.23it/s] 33%|███▎      | 38/115 [00:05<00:04, 15.63it/s] 37%|███▋      | 42/115 [00:05<00:03, 19.09it/s] 40%|████      | 46/115 [00:05<00:03, 22.04it/s] 43%|████▎     | 49/115 [00:05<00:03, 21.61it/s] 45%|████▌     | 52/115 [00:06<00:04, 13.02it/s] 49%|████▊     | 56/115 [00:06<00:03, 16.25it/s] 52%|█████▏    | 60/115 [00:06<00:02, 19.62it/s] 56%|█████▌    | 64/115 [00:06<00:02, 22.16it/s] 58%|█████▊    | 67/115 [00:06<00:02, 19.35it/s] 62%|██████▏   | 71/115 [00:06<00:01, 22.56it/s] 65%|██████▌   | 75/115 [00:07<00:02, 14.42it/s] 68%|██████▊   | 78/115 [00:07<00:02, 14.31it/s] 70%|███████   | 81/115 [00:07<00:03, 10.10it/s] 74%|███████▍  | 85/115 [00:08<00:02, 13.24it/s] 77%|███████▋  | 89/115 [00:08<00:01, 16.64it/s] 80%|████████  | 92/115 [00:08<00:02, 10.31it/s] 82%|████████▏ | 94/115 [00:09<00:02,  7.24it/s] 85%|████████▌ | 98/115 [00:09<00:01, 10.11it/s] 88%|████████▊ | 101/115 [00:09<00:01, 10.48it/s] 91%|█████████▏| 105/115 [00:09<00:00, 13.79it/s] 95%|█████████▍| 109/115 [00:10<00:00, 17.31it/s] 97%|█████████▋| 112/115 [00:10<00:00,  8.76it/s]100%|██████████| 115/115 [00:10<00:00, 10.77it/s]100%|██████████| 115/115 [00:11<00:00, 10.39it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<02:05,  1.10s/it]  3%|▎         | 3/115 [00:01<00:37,  2.98it/s]  6%|▌         | 7/115 [00:01<00:14,  7.70it/s] 10%|▉         | 11/115 [00:01<00:08, 12.01it/s] 12%|█▏        | 14/115 [00:01<00:06, 15.14it/s] 16%|█▌        | 18/115 [00:01<00:05, 19.05it/s] 19%|█▉        | 22/115 [00:01<00:04, 22.04it/s] 23%|██▎       | 26/115 [00:01<00:03, 24.47it/s] 26%|██▌       | 30/115 [00:02<00:03, 26.68it/s] 30%|██▉       | 34/115 [00:02<00:02, 28.84it/s] 33%|███▎      | 38/115 [00:02<00:02, 29.98it/s] 37%|███▋      | 42/115 [00:02<00:02, 31.41it/s] 40%|████      | 46/115 [00:02<00:02, 30.26it/s] 43%|████▎     | 50/115 [00:02<00:02, 30.50it/s] 47%|████▋     | 54/115 [00:02<00:01, 30.65it/s] 50%|█████     | 58/115 [00:02<00:01, 30.87it/s] 54%|█████▍    | 62/115 [00:03<00:01, 29.07it/s] 57%|█████▋    | 66/115 [00:03<00:01, 29.69it/s] 61%|██████    | 70/115 [00:03<00:01, 30.84it/s] 64%|██████▍   | 74/115 [00:03<00:01, 30.81it/s] 68%|██████▊   | 78/115 [00:03<00:01, 29.92it/s] 71%|███████▏  | 82/115 [00:03<00:01, 30.68it/s] 75%|███████▍  | 86/115 [00:03<00:00, 31.08it/s] 78%|███████▊  | 90/115 [00:04<00:00, 31.27it/s] 82%|████████▏ | 94/115 [00:04<00:00, 32.49it/s] 85%|████████▌ | 98/115 [00:04<00:00, 33.25it/s] 89%|████████▊ | 102/115 [00:04<00:00, 33.91it/s] 92%|█████████▏| 106/115 [00:04<00:00, 34.44it/s] 96%|█████████▌| 110/115 [00:04<00:00, 34.81it/s] 99%|█████████▉| 114/115 [00:04<00:00, 33.98it/s]100%|██████████| 115/115 [00:04<00:00, 23.61it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.670640766620636


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 64.45898064867811
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.59761273944594
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 52.99717295669407


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 67.06407928466797
=========================          END          =========================
0it [00:00, ?it/s]1it [00:02,  2.20s/it]2it [00:04,  2.53s/it]3it [00:07,  2.32s/it]4it [00:09,  2.37s/it]5it [00:12,  2.60s/it]6it [00:16,  2.94s/it]7it [00:18,  2.83s/it]8it [00:21,  2.78s/it]9it [00:24,  2.74s/it]10it [00:26,  2.78s/it]11it [00:30,  2.98s/it]12it [00:33,  3.08s/it]13it [00:36,  3.08s/it]14it [00:39,  3.13s/it]15it [00:43,  3.35s/it]16it [00:47,  3.36s/it]17it [00:50,  3.40s/it]18it [00:54,  3.47s/it]19it [00:58,  3.55s/it]20it [01:01,  3.63s/it]21it [01:05,  3.65s/it]22it [01:09,  3.62s/it]23it [01:13,  3.71s/it]24it [01:16,  3.60s/it]25it [01:20,  3.67s/it]26it [01:24,  3.77s/it]27it [01:28,  3.99s/it]28it [01:32,  3.96s/it]29it [01:36,  4.00s/it]30it [01:41,  4.09s/it]31it [01:45,  4.13s/it]32it [01:49,  4.19s/it]33it [01:53,  3.99s/it]34it [01:57,  4.04s/it]35it [02:01,  4.10s/it]36it [02:05,  4.22s/it]37it [02:10,  4.18s/it]38it [02:13,  3.97s/it]39it [02:17,  3.86s/it]40it [02:21,  3.86s/it]41it [02:24,  3.89s/it]42it [02:29,  3.93s/it]43it [02:32,  3.92s/it]44it [02:36,  3.95s/it]45it [02:40,  3.92s/it]46it [02:44,  3.97s/it]47it [02:49,  4.12s/it]48it [02:53,  4.19s/it]49it [02:57,  4.07s/it]50it [03:01,  4.01s/it]51it [03:05,  4.02s/it]52it [03:09,  4.02s/it]53it [03:13,  3.96s/it]54it [03:16,  3.88s/it]55it [03:21,  4.06s/it]56it [03:26,  4.24s/it]57it [03:30,  4.17s/it]58it [03:33,  4.04s/it]59it [03:37,  3.89s/it]60it [03:41,  3.84s/it]61it [03:44,  3.72s/it]62it [03:47,  3.54s/it]63it [03:50,  3.28s/it]64it [03:53,  3.19s/it]65it [03:56,  3.23s/it]66it [04:00,  3.33s/it]67it [04:03,  3.37s/it]68it [04:07,  3.47s/it]69it [04:11,  3.53s/it]70it [04:14,  3.50s/it]71it [04:18,  3.54s/it]72it [04:22,  3.70s/it]73it [04:25,  3.68s/it]74it [04:29,  3.56s/it]75it [04:31,  3.29s/it]76it [04:34,  3.24s/it]77it [04:37,  3.19s/it]78it [04:41,  3.30s/it]79it [04:45,  3.51s/it]80it [04:48,  3.41s/it]81it [04:52,  3.55s/it]82it [04:56,  3.58s/it]83it [04:59,  3.57s/it]84it [05:03,  3.54s/it]85it [05:06,  3.55s/it]86it [05:10,  3.49s/it]87it [05:13,  3.44s/it]88it [05:16,  3.42s/it]89it [05:20,  3.59s/it]90it [05:24,  3.76s/it]91it [05:28,  3.80s/it]92it [05:33,  3.91s/it]93it [05:37,  4.05s/it]94it [05:41,  3.97s/it]95it [05:45,  4.07s/it]96it [05:49,  4.12s/it]97it [05:53,  4.14s/it]98it [05:57,  4.09s/it]99it [06:01,  4.08s/it]100it [06:06,  4.15s/it]101it [06:10,  4.22s/it]102it [06:15,  4.42s/it]103it [06:19,  4.32s/it]104it [06:23,  4.21s/it]105it [06:27,  4.10s/it]106it [06:31,  4.14s/it]107it [06:36,  4.29s/it]108it [06:40,  4.27s/it]109it [06:44,  4.32s/it]110it [06:49,  4.42s/it]111it [06:53,  4.24s/it]112it [06:57,  4.15s/it]113it [07:01,  4.09s/it]114it [07:05,  4.12s/it]115it [07:09,  4.09s/it]115it [07:09,  3.74s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<03:52,  2.04s/it]  2%|▏         | 2/115 [00:02<01:43,  1.09it/s]  4%|▍         | 5/115 [00:02<00:31,  3.47it/s]  7%|▋         | 8/115 [00:02<00:17,  6.27it/s] 10%|▉         | 11/115 [00:02<00:11,  8.96it/s] 12%|█▏        | 14/115 [00:02<00:08, 12.10it/s] 15%|█▍        | 17/115 [00:02<00:06, 15.26it/s] 17%|█▋        | 20/115 [00:02<00:05, 17.40it/s] 20%|██        | 23/115 [00:02<00:04, 18.89it/s] 23%|██▎       | 26/115 [00:03<00:04, 19.29it/s] 25%|██▌       | 29/115 [00:03<00:04, 20.97it/s] 28%|██▊       | 32/115 [00:03<00:04, 18.69it/s] 30%|███       | 35/115 [00:03<00:03, 20.20it/s] 33%|███▎      | 38/115 [00:03<00:03, 20.97it/s] 36%|███▌      | 41/115 [00:03<00:03, 22.24it/s] 38%|███▊      | 44/115 [00:03<00:03, 23.00it/s] 41%|████      | 47/115 [00:04<00:02, 23.12it/s] 44%|████▍     | 51/115 [00:04<00:02, 25.01it/s] 47%|████▋     | 54/115 [00:04<00:02, 25.41it/s] 50%|████▉     | 57/115 [00:04<00:02, 24.62it/s] 53%|█████▎    | 61/115 [00:04<00:02, 25.47it/s] 56%|█████▌    | 64/115 [00:04<00:02, 25.06it/s] 59%|█████▉    | 68/115 [00:04<00:01, 27.37it/s] 62%|██████▏   | 71/115 [00:04<00:01, 27.83it/s] 64%|██████▍   | 74/115 [00:05<00:01, 26.66it/s] 67%|██████▋   | 77/115 [00:05<00:01, 26.14it/s] 70%|██████▉   | 80/115 [00:05<00:01, 27.11it/s] 72%|███████▏  | 83/115 [00:05<00:01, 27.65it/s] 76%|███████▌  | 87/115 [00:05<00:00, 29.28it/s] 79%|███████▉  | 91/115 [00:05<00:00, 30.64it/s] 83%|████████▎ | 95/115 [00:05<00:00, 32.08it/s] 86%|████████▌ | 99/115 [00:05<00:00, 33.12it/s] 90%|████████▉ | 103/115 [00:05<00:00, 33.53it/s] 93%|█████████▎| 107/115 [00:06<00:00, 34.11it/s] 97%|█████████▋| 111/115 [00:06<00:00, 33.24it/s]100%|██████████| 115/115 [00:06<00:00, 32.96it/s]100%|██████████| 115/115 [00:06<00:00, 17.30it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<03:21,  1.77s/it]  3%|▎         | 4/115 [00:01<00:40,  2.75it/s]  6%|▌         | 7/115 [00:01<00:20,  5.33it/s]  9%|▊         | 10/115 [00:02<00:12,  8.25it/s] 11%|█▏        | 13/115 [00:02<00:09, 11.00it/s] 14%|█▍        | 16/115 [00:02<00:07, 13.99it/s] 17%|█▋        | 19/115 [00:02<00:05, 16.76it/s] 19%|█▉        | 22/115 [00:02<00:04, 19.16it/s] 22%|██▏       | 25/115 [00:02<00:04, 20.31it/s] 25%|██▌       | 29/115 [00:02<00:03, 23.41it/s] 29%|██▊       | 33/115 [00:02<00:03, 24.72it/s] 31%|███▏      | 36/115 [00:03<00:03, 25.13it/s] 35%|███▍      | 40/115 [00:03<00:02, 27.60it/s] 37%|███▋      | 43/115 [00:03<00:02, 27.22it/s] 41%|████      | 47/115 [00:03<00:02, 28.21it/s] 43%|████▎     | 50/115 [00:03<00:02, 26.32it/s] 46%|████▌     | 53/115 [00:03<00:02, 27.13it/s] 49%|████▊     | 56/115 [00:03<00:02, 27.66it/s] 51%|█████▏    | 59/115 [00:03<00:02, 27.28it/s] 54%|█████▍    | 62/115 [00:03<00:01, 26.95it/s] 57%|█████▋    | 65/115 [00:04<00:02, 24.64it/s] 60%|██████    | 69/115 [00:04<00:01, 27.23it/s] 63%|██████▎   | 73/115 [00:04<00:01, 27.62it/s] 67%|██████▋   | 77/115 [00:04<00:01, 28.02it/s] 70%|███████   | 81/115 [00:04<00:01, 28.81it/s] 74%|███████▍  | 85/115 [00:04<00:01, 29.95it/s] 77%|███████▋  | 89/115 [00:04<00:00, 29.88it/s] 81%|████████  | 93/115 [00:05<00:00, 31.12it/s] 84%|████████▍ | 97/115 [00:05<00:00, 32.28it/s] 88%|████████▊ | 101/115 [00:05<00:00, 32.93it/s] 91%|█████████▏| 105/115 [00:05<00:00, 33.48it/s] 95%|█████████▍| 109/115 [00:05<00:00, 34.11it/s] 98%|█████████▊| 113/115 [00:05<00:00, 34.56it/s]100%|██████████| 115/115 [00:05<00:00, 19.47it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6698163747787476


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 63.88661760697738
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.70538180194698
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 52.85033921691944


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.98163604736328
=========================          END          =========================
0it [00:00, ?it/s]1it [00:04,  4.04s/it]2it [00:08,  4.11s/it]3it [00:12,  4.14s/it]4it [00:16,  3.95s/it]5it [00:19,  3.69s/it]6it [00:23,  3.80s/it]7it [00:27,  3.84s/it]8it [00:31,  3.83s/it]9it [00:34,  3.82s/it]10it [00:38,  3.83s/it]11it [00:42,  3.73s/it]12it [00:45,  3.60s/it]13it [00:49,  3.64s/it]14it [00:53,  3.83s/it]15it [00:57,  3.82s/it]16it [01:01,  3.94s/it]17it [01:04,  3.81s/it]18it [01:08,  3.75s/it]19it [01:12,  3.80s/it]20it [01:16,  3.74s/it]21it [01:20,  4.02s/it]22it [01:24,  3.95s/it]23it [01:28,  3.82s/it]24it [01:32,  3.88s/it]25it [01:36,  4.05s/it]26it [01:41,  4.23s/it]27it [01:45,  4.30s/it]28it [01:50,  4.33s/it]29it [01:54,  4.27s/it]30it [01:58,  4.22s/it]31it [02:02,  4.09s/it]32it [02:06,  4.06s/it]33it [02:10,  4.07s/it]34it [02:14,  4.15s/it]35it [02:18,  4.18s/it]36it [02:22,  4.14s/it]37it [02:26,  4.12s/it]38it [02:30,  3.87s/it]39it [02:33,  3.68s/it]40it [02:37,  3.70s/it]41it [02:40,  3.68s/it]42it [02:43,  3.52s/it]43it [02:47,  3.48s/it]44it [02:50,  3.36s/it]45it [02:53,  3.31s/it]46it [02:57,  3.39s/it]47it [03:01,  3.65s/it]48it [03:05,  3.65s/it]49it [03:08,  3.64s/it]50it [03:12,  3.58s/it]51it [03:15,  3.53s/it]52it [03:18,  3.46s/it]53it [03:22,  3.38s/it]54it [03:25,  3.35s/it]55it [03:29,  3.62s/it]56it [03:33,  3.64s/it]57it [03:37,  3.75s/it]58it [03:41,  3.81s/it]59it [03:45,  4.00s/it]60it [03:50,  4.23s/it]61it [03:54,  4.25s/it]62it [03:58,  4.14s/it]63it [04:02,  4.07s/it]64it [04:06,  4.07s/it]65it [04:11,  4.23s/it]66it [04:15,  4.19s/it]67it [04:19,  4.11s/it]68it [04:23,  4.19s/it]69it [04:28,  4.27s/it]70it [04:31,  4.11s/it]71it [04:37,  4.51s/it]72it [04:42,  4.67s/it]73it [04:47,  4.70s/it]74it [04:51,  4.70s/it]75it [04:56,  4.81s/it]76it [05:01,  4.76s/it]77it [05:05,  4.67s/it]78it [05:09,  4.49s/it]79it [05:14,  4.58s/it]80it [05:19,  4.52s/it]81it [05:24,  4.66s/it]82it [05:29,  4.84s/it]83it [05:34,  4.87s/it]84it [05:39,  4.95s/it]85it [05:44,  4.92s/it]86it [05:48,  4.78s/it]87it [05:53,  4.89s/it]88it [05:58,  4.71s/it]89it [06:03,  4.81s/it]90it [06:07,  4.69s/it]91it [06:12,  4.69s/it]92it [06:16,  4.58s/it]93it [06:20,  4.38s/it]94it [06:24,  4.35s/it]95it [06:28,  4.14s/it]96it [06:32,  4.02s/it]97it [06:36,  4.04s/it]98it [06:40,  3.95s/it]99it [06:45,  4.25s/it]100it [06:49,  4.24s/it]101it [06:52,  4.04s/it]102it [06:56,  4.00s/it]103it [07:00,  3.93s/it]104it [07:04,  4.04s/it]105it [07:08,  3.96s/it]106it [07:12,  3.88s/it]107it [07:15,  3.83s/it]108it [07:19,  3.74s/it]109it [07:23,  3.96s/it]110it [07:28,  4.03s/it]111it [07:32,  4.18s/it]112it [07:36,  4.20s/it]113it [07:41,  4.23s/it]114it [07:45,  4.14s/it]115it [07:49,  4.09s/it]115it [07:49,  4.08s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<04:46,  2.51s/it]  3%|▎         | 4/115 [00:02<00:55,  1.99it/s]  6%|▌         | 7/115 [00:02<00:27,  3.92it/s]  9%|▊         | 10/115 [00:02<00:16,  6.29it/s] 11%|█▏        | 13/115 [00:02<00:11,  8.95it/s] 15%|█▍        | 17/115 [00:03<00:07, 12.78it/s] 18%|█▊        | 21/115 [00:03<00:05, 16.55it/s] 22%|██▏       | 25/115 [00:03<00:04, 19.12it/s] 25%|██▌       | 29/115 [00:03<00:03, 21.88it/s] 29%|██▊       | 33/115 [00:03<00:03, 24.20it/s] 32%|███▏      | 37/115 [00:03<00:02, 26.10it/s] 36%|███▌      | 41/115 [00:03<00:02, 27.36it/s] 39%|███▉      | 45/115 [00:04<00:02, 27.55it/s] 42%|████▏     | 48/115 [00:04<00:02, 27.85it/s] 45%|████▌     | 52/115 [00:04<00:02, 29.48it/s] 49%|████▊     | 56/115 [00:04<00:02, 29.00it/s] 51%|█████▏    | 59/115 [00:04<00:01, 28.47it/s] 54%|█████▍    | 62/115 [00:04<00:02, 23.29it/s] 57%|█████▋    | 66/115 [00:04<00:01, 25.86it/s] 60%|██████    | 69/115 [00:04<00:01, 25.73it/s] 63%|██████▎   | 72/115 [00:05<00:01, 26.07it/s] 66%|██████▌   | 76/115 [00:05<00:01, 28.46it/s] 69%|██████▊   | 79/115 [00:05<00:01, 27.99it/s] 71%|███████▏  | 82/115 [00:05<00:01, 28.06it/s] 74%|███████▍  | 85/115 [00:05<00:01, 27.57it/s] 77%|███████▋  | 89/115 [00:05<00:00, 29.21it/s] 81%|████████  | 93/115 [00:05<00:00, 30.85it/s] 84%|████████▍ | 97/115 [00:05<00:00, 31.81it/s] 88%|████████▊ | 101/115 [00:05<00:00, 32.77it/s] 91%|█████████▏| 105/115 [00:06<00:00, 33.58it/s] 95%|█████████▍| 109/115 [00:06<00:00, 34.21it/s] 98%|█████████▊| 113/115 [00:06<00:00, 33.97it/s]100%|██████████| 115/115 [00:06<00:00, 17.60it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:02,  2.65s/it]  3%|▎         | 3/115 [00:02<01:25,  1.32it/s]  4%|▍         | 5/115 [00:02<00:43,  2.51it/s]  7%|▋         | 8/115 [00:03<00:22,  4.75it/s] 10%|▉         | 11/115 [00:03<00:14,  7.42it/s] 13%|█▎        | 15/115 [00:03<00:08, 11.26it/s] 16%|█▌        | 18/115 [00:03<00:06, 14.11it/s] 18%|█▊        | 21/115 [00:03<00:05, 16.63it/s] 21%|██        | 24/115 [00:03<00:04, 18.48it/s] 24%|██▍       | 28/115 [00:03<00:03, 22.05it/s] 27%|██▋       | 31/115 [00:03<00:03, 22.91it/s] 30%|██▉       | 34/115 [00:04<00:03, 23.43it/s] 32%|███▏      | 37/115 [00:04<00:03, 24.42it/s] 35%|███▍      | 40/115 [00:04<00:02, 25.76it/s] 37%|███▋      | 43/115 [00:04<00:02, 26.62it/s] 40%|████      | 46/115 [00:04<00:02, 26.27it/s] 43%|████▎     | 49/115 [00:04<00:02, 23.53it/s] 46%|████▌     | 53/115 [00:04<00:02, 26.33it/s] 50%|████▉     | 57/115 [00:04<00:02, 27.65it/s] 53%|█████▎    | 61/115 [00:04<00:01, 28.29it/s] 56%|█████▌    | 64/115 [00:05<00:01, 28.24it/s] 58%|█████▊    | 67/115 [00:05<00:01, 28.12it/s] 61%|██████    | 70/115 [00:05<00:01, 27.54it/s] 63%|██████▎   | 73/115 [00:05<00:01, 27.79it/s] 66%|██████▌   | 76/115 [00:05<00:01, 26.44it/s] 69%|██████▊   | 79/115 [00:05<00:01, 24.34it/s] 71%|███████▏  | 82/115 [00:05<00:01, 21.19it/s] 74%|███████▍  | 85/115 [00:06<00:01, 21.69it/s] 77%|███████▋  | 89/115 [00:06<00:01, 24.50it/s] 81%|████████  | 93/115 [00:06<00:00, 26.92it/s] 84%|████████▍ | 97/115 [00:06<00:00, 29.27it/s] 88%|████████▊ | 101/115 [00:06<00:00, 30.28it/s] 91%|█████████▏| 105/115 [00:06<00:00, 31.04it/s] 95%|█████████▍| 109/115 [00:06<00:00, 31.13it/s] 98%|█████████▊| 113/115 [00:06<00:00, 32.22it/s]100%|██████████| 115/115 [00:07<00:00, 16.25it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6672695875167847


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 63.25974379940038
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.43568549378142
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 52.25876490283032


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.72695922851562
=========================          END          =========================
0it [00:00, ?it/s]1it [00:04,  4.85s/it]2it [00:10,  5.03s/it]3it [00:15,  5.06s/it]4it [00:20,  5.34s/it]5it [00:25,  5.23s/it]6it [00:30,  5.02s/it]7it [00:34,  4.79s/it]8it [00:39,  4.69s/it]9it [00:43,  4.69s/it]10it [00:49,  4.83s/it]11it [00:53,  4.76s/it]12it [00:59,  5.10s/it]13it [01:04,  5.12s/it]14it [01:10,  5.17s/it]15it [01:14,  4.96s/it]16it [01:19,  4.96s/it]17it [01:23,  4.74s/it]18it [01:28,  4.73s/it]19it [01:33,  4.71s/it]20it [01:37,  4.63s/it]21it [01:41,  4.57s/it]22it [01:47,  4.81s/it]23it [01:51,  4.76s/it]24it [01:56,  4.58s/it]25it [02:00,  4.47s/it]26it [02:05,  4.52s/it]27it [02:09,  4.59s/it]28it [02:13,  4.41s/it]29it [02:18,  4.40s/it]30it [02:22,  4.52s/it]31it [02:27,  4.57s/it]32it [02:32,  4.60s/it]33it [02:37,  4.70s/it]34it [02:41,  4.67s/it]35it [02:46,  4.53s/it]36it [02:51,  4.69s/it]37it [02:55,  4.69s/it]38it [03:00,  4.73s/it]39it [03:04,  4.61s/it]40it [03:09,  4.53s/it]41it [03:13,  4.55s/it]42it [03:18,  4.70s/it]43it [03:23,  4.65s/it]44it [03:28,  4.62s/it]45it [03:32,  4.57s/it]46it [03:37,  4.61s/it]47it [03:41,  4.61s/it]48it [03:46,  4.60s/it]49it [03:50,  4.58s/it]50it [03:55,  4.51s/it]51it [03:59,  4.57s/it]52it [04:04,  4.48s/it]53it [04:09,  4.65s/it]54it [04:14,  4.76s/it]55it [04:18,  4.56s/it]56it [04:23,  4.61s/it]57it [04:27,  4.44s/it]58it [04:31,  4.42s/it]59it [04:36,  4.54s/it]60it [04:40,  4.55s/it]61it [04:45,  4.62s/it]62it [04:49,  4.52s/it]63it [04:54,  4.60s/it]64it [04:58,  4.48s/it]65it [05:02,  4.34s/it]66it [05:07,  4.44s/it]67it [05:12,  4.53s/it]68it [05:16,  4.50s/it]69it [05:21,  4.42s/it]70it [05:25,  4.33s/it]71it [05:29,  4.26s/it]72it [05:34,  4.51s/it]73it [05:38,  4.33s/it]74it [05:42,  4.40s/it]75it [05:46,  4.24s/it]76it [05:50,  4.11s/it]77it [05:54,  4.14s/it]78it [05:59,  4.28s/it]79it [06:04,  4.58s/it]80it [06:08,  4.51s/it]81it [06:13,  4.59s/it]82it [06:17,  4.39s/it]83it [06:22,  4.44s/it]84it [06:26,  4.43s/it]85it [06:30,  4.35s/it]86it [06:35,  4.41s/it]87it [06:40,  4.55s/it]88it [06:44,  4.53s/it]89it [06:49,  4.68s/it]90it [06:54,  4.79s/it]91it [06:59,  4.74s/it]92it [07:03,  4.54s/it]93it [07:08,  4.80s/it]94it [07:13,  4.75s/it]95it [07:18,  4.82s/it]96it [07:23,  4.84s/it]97it [07:27,  4.76s/it]98it [07:32,  4.68s/it]99it [07:37,  4.70s/it]100it [07:41,  4.55s/it]101it [07:45,  4.39s/it]102it [07:49,  4.34s/it]103it [07:53,  4.21s/it]104it [07:57,  4.16s/it]105it [08:02,  4.25s/it]106it [08:06,  4.18s/it]107it [08:10,  4.15s/it]108it [08:14,  4.11s/it]109it [08:18,  4.11s/it]110it [08:21,  3.96s/it]111it [08:26,  4.04s/it]112it [08:30,  4.19s/it]113it [08:34,  4.04s/it]114it [08:38,  4.19s/it]115it [08:43,  4.19s/it]115it [08:43,  4.55s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:01<03:45,  1.98s/it]  3%|▎         | 3/115 [00:02<01:06,  1.67it/s]  5%|▌         | 6/115 [00:02<00:27,  3.96it/s]  8%|▊         | 9/115 [00:02<00:16,  6.50it/s] 10%|█         | 12/115 [00:02<00:10,  9.42it/s] 13%|█▎        | 15/115 [00:02<00:08, 12.45it/s] 16%|█▌        | 18/115 [00:02<00:06, 15.14it/s] 18%|█▊        | 21/115 [00:02<00:05, 17.63it/s] 21%|██        | 24/115 [00:03<00:04, 18.99it/s] 23%|██▎       | 27/115 [00:03<00:04, 21.09it/s] 26%|██▌       | 30/115 [00:03<00:03, 22.58it/s] 29%|██▊       | 33/115 [00:03<00:03, 22.24it/s] 31%|███▏      | 36/115 [00:03<00:03, 24.04it/s] 34%|███▍      | 39/115 [00:03<00:02, 25.37it/s] 37%|███▋      | 42/115 [00:03<00:02, 25.92it/s] 39%|███▉      | 45/115 [00:03<00:02, 26.30it/s] 42%|████▏     | 48/115 [00:03<00:02, 27.01it/s] 45%|████▌     | 52/115 [00:04<00:02, 28.35it/s] 48%|████▊     | 55/115 [00:04<00:02, 28.49it/s] 51%|█████▏    | 59/115 [00:04<00:01, 29.87it/s] 55%|█████▍    | 63/115 [00:04<00:01, 29.98it/s] 58%|█████▊    | 67/115 [00:04<00:01, 27.89it/s] 62%|██████▏   | 71/115 [00:04<00:01, 29.32it/s] 65%|██████▌   | 75/115 [00:04<00:01, 29.45it/s] 69%|██████▊   | 79/115 [00:04<00:01, 29.67it/s] 71%|███████▏  | 82/115 [00:05<00:01, 29.29it/s] 75%|███████▍  | 86/115 [00:05<00:00, 30.52it/s] 78%|███████▊  | 90/115 [00:05<00:00, 31.33it/s] 82%|████████▏ | 94/115 [00:05<00:00, 31.31it/s] 85%|████████▌ | 98/115 [00:05<00:00, 31.14it/s] 89%|████████▊ | 102/115 [00:05<00:00, 31.76it/s] 92%|█████████▏| 106/115 [00:05<00:00, 32.64it/s] 96%|█████████▌| 110/115 [00:05<00:00, 32.56it/s] 99%|█████████▉| 114/115 [00:06<00:00, 33.26it/s]100%|██████████| 115/115 [00:06<00:00, 18.14it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<04:19,  2.28s/it]  3%|▎         | 3/115 [00:02<01:15,  1.49it/s]  6%|▌         | 7/115 [00:02<00:25,  4.19it/s]  9%|▊         | 10/115 [00:02<00:16,  6.46it/s] 12%|█▏        | 14/115 [00:02<00:10, 10.05it/s] 16%|█▌        | 18/115 [00:03<00:07, 13.61it/s] 18%|█▊        | 21/115 [00:03<00:05, 16.19it/s] 21%|██        | 24/115 [00:03<00:07, 12.45it/s] 23%|██▎       | 27/115 [00:03<00:06, 13.37it/s] 26%|██▌       | 30/115 [00:03<00:05, 15.92it/s] 29%|██▊       | 33/115 [00:03<00:04, 17.24it/s] 32%|███▏      | 37/115 [00:04<00:03, 20.57it/s] 36%|███▌      | 41/115 [00:04<00:03, 23.60it/s] 39%|███▉      | 45/115 [00:04<00:02, 25.61it/s] 42%|████▏     | 48/115 [00:04<00:02, 25.81it/s] 44%|████▍     | 51/115 [00:04<00:02, 25.97it/s] 47%|████▋     | 54/115 [00:04<00:02, 25.99it/s] 50%|████▉     | 57/115 [00:04<00:02, 23.24it/s] 53%|█████▎    | 61/115 [00:04<00:02, 26.35it/s] 57%|█████▋    | 65/115 [00:05<00:01, 28.16it/s] 60%|██████    | 69/115 [00:05<00:01, 29.85it/s] 63%|██████▎   | 73/115 [00:05<00:01, 29.54it/s] 67%|██████▋   | 77/115 [00:05<00:01, 29.03it/s] 70%|███████   | 81/115 [00:05<00:01, 29.21it/s] 74%|███████▍  | 85/115 [00:05<00:01, 29.01it/s] 77%|███████▋  | 88/115 [00:05<00:00, 28.91it/s] 79%|███████▉  | 91/115 [00:05<00:00, 26.82it/s] 83%|████████▎ | 95/115 [00:06<00:00, 29.05it/s] 86%|████████▌ | 99/115 [00:06<00:00, 30.79it/s] 90%|████████▉ | 103/115 [00:06<00:00, 32.03it/s] 93%|█████████▎| 107/115 [00:06<00:00, 33.04it/s] 97%|█████████▋| 111/115 [00:06<00:00, 33.65it/s]100%|██████████| 115/115 [00:06<00:00, 34.99it/s]100%|██████████| 115/115 [00:06<00:00, 16.94it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6698235869407654


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 64.34995911692559
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.53694801565135
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 52.465189214409804


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.98236083984375
=========================          END          =========================
0it [00:00, ?it/s]1it [00:04,  4.48s/it]2it [00:09,  4.77s/it]3it [00:14,  4.69s/it]4it [00:18,  4.55s/it]5it [00:22,  4.45s/it]6it [00:26,  4.38s/it]7it [00:30,  4.09s/it]8it [00:34,  4.18s/it]9it [00:38,  4.18s/it]10it [00:43,  4.19s/it]11it [00:46,  4.07s/it]12it [00:51,  4.21s/it]13it [00:55,  4.16s/it]14it [00:59,  4.14s/it]15it [01:03,  4.09s/it]16it [01:07,  4.01s/it]17it [01:11,  4.15s/it]18it [01:16,  4.20s/it]19it [01:20,  4.08s/it]20it [01:24,  4.09s/it]21it [01:28,  4.15s/it]22it [01:33,  4.30s/it]23it [01:37,  4.41s/it]24it [01:41,  4.11s/it]25it [01:45,  4.13s/it]26it [01:49,  4.12s/it]27it [01:54,  4.27s/it]28it [01:57,  4.10s/it]29it [02:03,  4.51s/it]30it [02:07,  4.54s/it]31it [02:12,  4.57s/it]32it [02:17,  4.78s/it]33it [02:22,  4.74s/it]34it [02:27,  4.79s/it]35it [02:32,  4.79s/it]36it [02:37,  5.02s/it]37it [02:42,  5.07s/it]38it [02:47,  5.09s/it]39it [02:53,  5.11s/it]40it [02:58,  5.26s/it]41it [03:03,  5.13s/it]42it [03:07,  4.81s/it]43it [03:12,  4.72s/it]44it [03:16,  4.48s/it]45it [03:20,  4.48s/it]46it [03:25,  4.65s/it]47it [03:29,  4.52s/it]48it [03:34,  4.44s/it]49it [03:38,  4.48s/it]50it [03:43,  4.57s/it]51it [03:47,  4.46s/it]52it [03:52,  4.55s/it]53it [03:57,  4.59s/it]54it [04:01,  4.50s/it]55it [04:05,  4.37s/it]56it [04:09,  4.33s/it]57it [04:14,  4.34s/it]58it [04:18,  4.38s/it]59it [04:23,  4.52s/it]60it [04:28,  4.65s/it]61it [04:33,  4.73s/it]62it [04:37,  4.69s/it]63it [04:42,  4.65s/it]64it [04:46,  4.64s/it]65it [04:52,  4.77s/it]66it [04:56,  4.71s/it]67it [05:01,  4.83s/it]68it [05:06,  4.80s/it]69it [05:11,  4.75s/it]70it [05:16,  4.83s/it]71it [05:21,  4.90s/it]72it [05:26,  4.91s/it]73it [05:30,  4.82s/it]74it [05:35,  4.79s/it]75it [05:40,  4.84s/it]76it [05:45,  4.96s/it]77it [05:51,  5.10s/it]78it [05:55,  5.00s/it]79it [06:00,  4.82s/it]80it [06:04,  4.76s/it]81it [06:09,  4.66s/it]82it [06:14,  4.69s/it]83it [06:18,  4.61s/it]84it [06:22,  4.47s/it]85it [06:26,  4.29s/it]86it [06:31,  4.38s/it]87it [06:35,  4.36s/it]88it [06:39,  4.31s/it]89it [06:44,  4.49s/it]90it [06:49,  4.58s/it]91it [06:53,  4.50s/it]92it [06:57,  4.48s/it]93it [07:02,  4.38s/it]94it [07:05,  4.18s/it]95it [07:10,  4.43s/it]96it [07:15,  4.62s/it]97it [07:20,  4.69s/it]98it [07:25,  4.76s/it]99it [07:30,  4.78s/it]100it [07:35,  4.79s/it]101it [07:39,  4.72s/it]102it [07:44,  4.69s/it]103it [07:49,  4.89s/it]104it [07:54,  4.90s/it]105it [07:59,  4.83s/it]106it [08:04,  4.84s/it]107it [08:09,  5.02s/it]108it [08:14,  4.98s/it]109it [08:19,  4.91s/it]110it [08:23,  4.72s/it]111it [08:28,  4.76s/it]112it [08:33,  4.79s/it]113it [08:37,  4.69s/it]114it [08:42,  4.59s/it]115it [08:46,  4.54s/it]115it [08:46,  4.58s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<04:33,  2.40s/it]  2%|▏         | 2/115 [00:02<02:06,  1.12s/it]  5%|▌         | 6/115 [00:02<00:30,  3.55it/s]  9%|▊         | 10/115 [00:02<00:15,  6.62it/s] 12%|█▏        | 14/115 [00:03<00:10,  9.87it/s] 15%|█▍        | 17/115 [00:03<00:08, 12.13it/s] 17%|█▋        | 20/115 [00:03<00:06, 14.66it/s] 20%|██        | 23/115 [00:03<00:05, 17.36it/s] 23%|██▎       | 27/115 [00:03<00:04, 20.61it/s] 27%|██▋       | 31/115 [00:03<00:03, 23.66it/s] 30%|██▉       | 34/115 [00:03<00:03, 24.68it/s] 32%|███▏      | 37/115 [00:03<00:03, 25.44it/s] 35%|███▍      | 40/115 [00:03<00:03, 24.26it/s] 37%|███▋      | 43/115 [00:04<00:02, 25.25it/s] 40%|████      | 46/115 [00:04<00:02, 24.64it/s] 43%|████▎     | 49/115 [00:04<00:02, 24.56it/s] 45%|████▌     | 52/115 [00:04<00:02, 23.79it/s] 48%|████▊     | 55/115 [00:04<00:02, 22.60it/s] 50%|█████     | 58/115 [00:04<00:02, 23.37it/s] 53%|█████▎    | 61/115 [00:04<00:02, 24.70it/s] 56%|█████▌    | 64/115 [00:04<00:02, 22.45it/s] 58%|█████▊    | 67/115 [00:05<00:02, 21.53it/s] 61%|██████    | 70/115 [00:05<00:01, 22.52it/s] 63%|██████▎   | 73/115 [00:05<00:01, 23.73it/s] 66%|██████▌   | 76/115 [00:05<00:01, 24.75it/s] 69%|██████▊   | 79/115 [00:05<00:01, 25.11it/s] 71%|███████▏  | 82/115 [00:05<00:01, 21.28it/s] 75%|███████▍  | 86/115 [00:05<00:01, 24.28it/s] 78%|███████▊  | 90/115 [00:06<00:00, 26.12it/s] 82%|████████▏ | 94/115 [00:06<00:00, 27.70it/s] 85%|████████▌ | 98/115 [00:06<00:00, 28.91it/s] 88%|████████▊ | 101/115 [00:06<00:00, 29.11it/s] 91%|█████████▏| 105/115 [00:06<00:00, 29.83it/s] 95%|█████████▍| 109/115 [00:06<00:00, 31.47it/s] 98%|█████████▊| 113/115 [00:06<00:00, 32.61it/s]100%|██████████| 115/115 [00:07<00:00, 15.82it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:35,  2.94s/it]  2%|▏         | 2/115 [00:03<02:24,  1.28s/it]  5%|▌         | 6/115 [00:03<00:34,  3.15it/s]  9%|▊         | 10/115 [00:03<00:17,  6.01it/s] 11%|█▏        | 13/115 [00:03<00:12,  8.32it/s] 14%|█▍        | 16/115 [00:03<00:09, 10.68it/s] 17%|█▋        | 20/115 [00:03<00:06, 14.54it/s] 21%|██        | 24/115 [00:03<00:05, 18.14it/s] 24%|██▍       | 28/115 [00:03<00:04, 21.63it/s] 28%|██▊       | 32/115 [00:04<00:03, 24.24it/s] 31%|███▏      | 36/115 [00:04<00:03, 25.89it/s] 35%|███▍      | 40/115 [00:04<00:02, 26.85it/s] 38%|███▊      | 44/115 [00:04<00:02, 27.83it/s] 42%|████▏     | 48/115 [00:04<00:02, 28.12it/s] 44%|████▍     | 51/115 [00:04<00:02, 27.66it/s] 47%|████▋     | 54/115 [00:04<00:02, 28.15it/s] 50%|█████     | 58/115 [00:04<00:01, 28.90it/s] 53%|█████▎    | 61/115 [00:05<00:01, 29.08it/s] 57%|█████▋    | 65/115 [00:05<00:01, 30.30it/s] 60%|██████    | 69/115 [00:05<00:01, 31.08it/s] 63%|██████▎   | 73/115 [00:05<00:01, 29.64it/s] 67%|██████▋   | 77/115 [00:05<00:01, 30.17it/s] 70%|███████   | 81/115 [00:05<00:01, 31.15it/s] 74%|███████▍  | 85/115 [00:05<00:00, 30.22it/s] 77%|███████▋  | 89/115 [00:05<00:00, 30.73it/s] 81%|████████  | 93/115 [00:06<00:00, 31.36it/s] 84%|████████▍ | 97/115 [00:06<00:00, 32.24it/s] 88%|████████▊ | 101/115 [00:06<00:00, 31.75it/s] 91%|█████████▏| 105/115 [00:06<00:00, 32.36it/s] 95%|█████████▍| 109/115 [00:06<00:00, 33.24it/s] 98%|█████████▊| 113/115 [00:06<00:00, 33.07it/s]100%|██████████| 115/115 [00:06<00:00, 16.66it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6707583069801331


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 64.05014990460616
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.25803929196935
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 51.879978407817426


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 67.0758285522461
=========================          END          =========================
0it [00:00, ?it/s]1it [00:04,  4.73s/it]2it [00:09,  4.80s/it]3it [00:14,  4.73s/it]4it [00:18,  4.60s/it]5it [00:23,  4.64s/it]6it [00:27,  4.57s/it]7it [00:32,  4.54s/it]8it [00:36,  4.39s/it]9it [00:41,  4.50s/it]10it [00:46,  4.67s/it]11it [00:50,  4.65s/it]12it [00:54,  4.44s/it]13it [00:58,  4.36s/it]14it [01:02,  4.15s/it]15it [01:06,  4.13s/it]16it [01:10,  4.07s/it]17it [01:14,  3.96s/it]18it [01:18,  3.98s/it]19it [01:22,  4.03s/it]20it [01:26,  4.11s/it]21it [01:31,  4.21s/it]22it [01:35,  4.23s/it]23it [01:40,  4.34s/it]24it [01:43,  4.18s/it]25it [01:47,  4.15s/it]26it [01:52,  4.29s/it]27it [01:56,  4.23s/it]28it [02:00,  4.07s/it]29it [02:04,  4.11s/it]30it [02:08,  4.06s/it]31it [02:12,  4.08s/it]32it [02:16,  4.07s/it]33it [02:20,  3.87s/it]34it [02:23,  3.88s/it]35it [02:27,  3.86s/it]36it [02:31,  3.97s/it]37it [02:36,  4.06s/it]38it [02:40,  4.19s/it]39it [02:45,  4.32s/it]40it [02:50,  4.49s/it]41it [02:55,  4.62s/it]42it [02:59,  4.67s/it]43it [03:04,  4.71s/it]44it [03:09,  4.58s/it]45it [03:13,  4.46s/it]46it [03:18,  4.56s/it]47it [03:22,  4.69s/it]48it [03:27,  4.70s/it]49it [03:32,  4.73s/it]50it [03:36,  4.63s/it]51it [03:41,  4.52s/it]52it [03:45,  4.42s/it]53it [03:49,  4.48s/it]54it [03:54,  4.42s/it]55it [03:58,  4.48s/it]56it [04:03,  4.62s/it]57it [04:07,  4.27s/it]58it [04:11,  4.19s/it]59it [04:15,  4.17s/it]60it [04:19,  4.20s/it]61it [04:23,  4.04s/it]62it [04:27,  4.11s/it]63it [04:31,  3.96s/it]64it [04:34,  3.83s/it]65it [04:39,  4.03s/it]66it [04:42,  3.94s/it]67it [04:46,  3.83s/it]68it [04:50,  3.79s/it]69it [04:53,  3.65s/it]70it [04:57,  3.63s/it]71it [05:01,  3.96s/it]72it [05:05,  3.86s/it]73it [05:09,  3.96s/it]74it [05:14,  4.13s/it]75it [05:18,  4.22s/it]76it [05:23,  4.42s/it]77it [05:28,  4.53s/it]78it [05:33,  4.62s/it]79it [05:37,  4.65s/it]80it [05:42,  4.50s/it]81it [05:46,  4.57s/it]82it [05:51,  4.56s/it]83it [05:56,  4.71s/it]84it [06:00,  4.64s/it]85it [06:05,  4.59s/it]86it [06:10,  4.77s/it]87it [06:15,  4.81s/it]88it [06:20,  4.76s/it]89it [06:25,  4.87s/it]90it [06:30,  4.96s/it]91it [06:35,  4.94s/it]92it [06:39,  4.73s/it]93it [06:44,  4.74s/it]94it [06:48,  4.59s/it]95it [06:53,  4.69s/it]96it [06:58,  4.66s/it]97it [07:02,  4.59s/it]98it [07:06,  4.50s/it]99it [07:11,  4.50s/it]100it [07:15,  4.45s/it]101it [07:20,  4.58s/it]102it [07:25,  4.61s/it]103it [07:29,  4.48s/it]104it [07:34,  4.77s/it]105it [07:40,  4.97s/it]106it [07:44,  4.92s/it]107it [07:49,  4.84s/it]108it [07:54,  4.72s/it]109it [07:59,  4.80s/it]110it [08:03,  4.81s/it]111it [08:08,  4.84s/it]112it [08:14,  4.96s/it]113it [08:19,  4.97s/it]114it [08:23,  4.69s/it]115it [08:27,  4.63s/it]115it [08:27,  4.41s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<07:16,  3.83s/it]  3%|▎         | 4/115 [00:03<01:23,  1.33it/s]  7%|▋         | 8/115 [00:04<00:33,  3.17it/s] 10%|█         | 12/115 [00:04<00:19,  5.42it/s] 13%|█▎        | 15/115 [00:04<00:13,  7.40it/s] 16%|█▌        | 18/115 [00:04<00:10,  9.51it/s] 18%|█▊        | 21/115 [00:04<00:08, 11.23it/s] 21%|██        | 24/115 [00:04<00:06, 13.68it/s] 23%|██▎       | 27/115 [00:04<00:05, 16.01it/s] 27%|██▋       | 31/115 [00:04<00:04, 19.02it/s] 30%|██▉       | 34/115 [00:05<00:03, 20.28it/s] 32%|███▏      | 37/115 [00:05<00:03, 20.44it/s] 35%|███▍      | 40/115 [00:05<00:03, 20.84it/s] 37%|███▋      | 43/115 [00:05<00:03, 22.53it/s] 41%|████      | 47/115 [00:05<00:02, 25.61it/s] 44%|████▍     | 51/115 [00:05<00:02, 27.40it/s] 48%|████▊     | 55/115 [00:05<00:02, 29.31it/s] 51%|█████▏    | 59/115 [00:05<00:01, 29.21it/s] 54%|█████▍    | 62/115 [00:06<00:01, 28.80it/s] 57%|█████▋    | 65/115 [00:06<00:01, 26.75it/s] 59%|█████▉    | 68/115 [00:06<00:01, 26.53it/s] 62%|██████▏   | 71/115 [00:06<00:01, 26.29it/s] 65%|██████▌   | 75/115 [00:06<00:01, 27.37it/s] 68%|██████▊   | 78/115 [00:06<00:01, 26.89it/s] 71%|███████▏  | 82/115 [00:06<00:01, 27.95it/s] 75%|███████▍  | 86/115 [00:06<00:01, 28.34it/s] 77%|███████▋  | 89/115 [00:07<00:00, 28.70it/s] 80%|████████  | 92/115 [00:07<00:00, 28.24it/s] 83%|████████▎ | 95/115 [00:07<00:00, 28.25it/s] 86%|████████▌ | 99/115 [00:07<00:00, 30.14it/s] 90%|████████▉ | 103/115 [00:07<00:00, 29.85it/s] 92%|█████████▏| 106/115 [00:07<00:00, 26.12it/s] 95%|█████████▍| 109/115 [00:07<00:00, 25.25it/s] 97%|█████████▋| 112/115 [00:07<00:00, 25.58it/s]100%|██████████| 115/115 [00:08<00:00, 25.36it/s]100%|██████████| 115/115 [00:08<00:00, 13.45it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:04<09:19,  4.91s/it]  3%|▎         | 4/115 [00:05<01:47,  1.04it/s]  6%|▌         | 7/115 [00:05<00:50,  2.13it/s]  9%|▊         | 10/115 [00:05<00:29,  3.56it/s] 11%|█▏        | 13/115 [00:05<00:19,  5.37it/s] 14%|█▍        | 16/115 [00:05<00:13,  7.27it/s] 17%|█▋        | 20/115 [00:05<00:08, 10.57it/s] 20%|██        | 23/115 [00:05<00:07, 12.86it/s] 23%|██▎       | 26/115 [00:05<00:05, 15.46it/s] 25%|██▌       | 29/115 [00:05<00:04, 17.90it/s] 29%|██▊       | 33/115 [00:06<00:03, 21.71it/s] 31%|███▏      | 36/115 [00:06<00:03, 23.16it/s] 34%|███▍      | 39/115 [00:06<00:05, 15.01it/s] 37%|███▋      | 42/115 [00:06<00:04, 17.27it/s] 40%|████      | 46/115 [00:06<00:03, 20.01it/s] 43%|████▎     | 50/115 [00:06<00:02, 22.78it/s] 46%|████▌     | 53/115 [00:07<00:02, 23.21it/s] 49%|████▊     | 56/115 [00:07<00:03, 18.25it/s] 51%|█████▏    | 59/115 [00:07<00:02, 19.83it/s] 54%|█████▍    | 62/115 [00:07<00:02, 20.81it/s] 57%|█████▋    | 65/115 [00:07<00:02, 19.17it/s] 59%|█████▉    | 68/115 [00:07<00:02, 19.52it/s] 62%|██████▏   | 71/115 [00:08<00:02, 21.12it/s] 64%|██████▍   | 74/115 [00:08<00:01, 22.19it/s] 67%|██████▋   | 77/115 [00:08<00:01, 23.84it/s] 70%|██████▉   | 80/115 [00:08<00:01, 23.17it/s] 73%|███████▎  | 84/115 [00:08<00:01, 25.58it/s] 76%|███████▌  | 87/115 [00:08<00:01, 25.41it/s] 79%|███████▉  | 91/115 [00:08<00:00, 26.97it/s] 83%|████████▎ | 95/115 [00:08<00:00, 28.11it/s] 86%|████████▌ | 99/115 [00:09<00:00, 29.52it/s] 90%|████████▉ | 103/115 [00:09<00:00, 30.88it/s] 93%|█████████▎| 107/115 [00:09<00:00, 32.22it/s] 97%|█████████▋| 111/115 [00:09<00:00, 32.94it/s]100%|██████████| 115/115 [00:09<00:00, 31.29it/s]100%|██████████| 115/115 [00:09<00:00, 11.58it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6702463626861572


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 64.10466067048242
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.59486203891733
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 53.16841151914009


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 67.0246353149414
=========================          END          =========================
0it [00:00, ?it/s]1it [00:04,  4.48s/it]2it [00:08,  4.14s/it]3it [00:12,  4.07s/it]4it [00:16,  4.06s/it]5it [00:20,  4.25s/it]6it [00:24,  4.14s/it]7it [00:29,  4.26s/it]8it [00:34,  4.41s/it]9it [00:38,  4.27s/it]10it [00:42,  4.30s/it]11it [00:46,  4.15s/it]12it [00:49,  3.82s/it]13it [00:52,  3.68s/it]14it [00:55,  3.54s/it]15it [00:58,  3.35s/it]16it [01:02,  3.55s/it]17it [01:06,  3.54s/it]18it [01:10,  3.67s/it]19it [01:14,  3.78s/it]20it [01:17,  3.68s/it]21it [01:22,  3.87s/it]22it [01:26,  3.97s/it]23it [01:29,  3.87s/it]24it [01:33,  3.88s/it]25it [01:37,  3.88s/it]26it [01:42,  4.17s/it]27it [01:46,  4.12s/it]28it [01:50,  4.10s/it]29it [01:55,  4.35s/it]30it [02:00,  4.40s/it]31it [02:04,  4.42s/it]32it [02:08,  4.27s/it]33it [02:13,  4.38s/it]34it [02:17,  4.42s/it]35it [02:21,  4.38s/it]36it [02:26,  4.46s/it]37it [02:31,  4.63s/it]38it [02:35,  4.46s/it]39it [02:39,  4.36s/it]40it [02:43,  4.28s/it]41it [02:48,  4.29s/it]42it [02:52,  4.38s/it]43it [02:57,  4.37s/it]44it [03:01,  4.43s/it]45it [03:06,  4.59s/it]46it [03:11,  4.59s/it]47it [03:15,  4.44s/it]48it [03:19,  4.36s/it]49it [03:24,  4.63s/it]50it [03:30,  4.85s/it]51it [03:35,  4.98s/it]52it [03:40,  5.04s/it]53it [03:45,  4.96s/it]54it [03:50,  4.90s/it]55it [03:54,  4.77s/it]56it [03:59,  4.79s/it]57it [04:03,  4.65s/it]58it [04:07,  4.51s/it]59it [04:13,  4.67s/it]60it [04:17,  4.63s/it]61it [04:21,  4.51s/it]62it [04:26,  4.72s/it]63it [04:31,  4.69s/it]64it [04:36,  4.62s/it]65it [04:41,  4.71s/it]66it [04:45,  4.56s/it]67it [04:50,  4.65s/it]68it [04:54,  4.60s/it]69it [04:58,  4.47s/it]70it [05:03,  4.51s/it]71it [05:08,  4.66s/it]72it [05:12,  4.43s/it]73it [05:16,  4.41s/it]74it [05:21,  4.43s/it]75it [05:26,  4.64s/it]76it [05:31,  4.72s/it]77it [05:36,  4.81s/it]78it [05:40,  4.78s/it]79it [05:45,  4.81s/it]80it [05:50,  4.93s/it]81it [05:55,  4.81s/it]82it [06:00,  4.75s/it]83it [06:05,  4.83s/it]84it [06:10,  5.07s/it]85it [06:15,  5.09s/it]86it [06:20,  4.98s/it]87it [06:25,  4.91s/it]88it [06:30,  4.94s/it]89it [06:35,  5.11s/it]90it [06:41,  5.28s/it]91it [06:46,  5.20s/it]92it [06:51,  5.07s/it]93it [06:55,  4.88s/it]94it [06:59,  4.70s/it]95it [07:04,  4.70s/it]96it [07:08,  4.58s/it]97it [07:13,  4.50s/it]98it [07:18,  4.61s/it]99it [07:22,  4.66s/it]100it [07:27,  4.69s/it]101it [07:32,  4.70s/it]102it [07:37,  4.68s/it]103it [07:41,  4.68s/it]104it [07:46,  4.70s/it]105it [07:51,  4.70s/it]106it [07:54,  4.27s/it]107it [07:58,  4.07s/it]108it [08:02,  4.20s/it]109it [08:06,  4.13s/it]110it [08:10,  4.19s/it]111it [08:14,  4.06s/it]112it [08:18,  4.13s/it]113it [08:23,  4.12s/it]114it [08:26,  4.04s/it]115it [08:30,  3.93s/it]115it [08:30,  4.44s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:04<08:17,  4.36s/it]  2%|▏         | 2/115 [00:04<03:32,  1.88s/it]  4%|▍         | 5/115 [00:04<01:05,  1.67it/s]  6%|▌         | 7/115 [00:04<00:40,  2.64it/s]  9%|▊         | 10/115 [00:05<00:23,  4.49it/s] 11%|█▏        | 13/115 [00:05<00:15,  6.65it/s] 14%|█▍        | 16/115 [00:05<00:11,  8.94it/s] 17%|█▋        | 19/115 [00:05<00:08, 11.55it/s] 19%|█▉        | 22/115 [00:05<00:06, 14.16it/s] 22%|██▏       | 25/115 [00:05<00:05, 16.11it/s] 25%|██▌       | 29/115 [00:05<00:04, 19.42it/s] 28%|██▊       | 32/115 [00:05<00:03, 20.84it/s] 30%|███       | 35/115 [00:05<00:03, 22.81it/s] 33%|███▎      | 38/115 [00:06<00:03, 23.73it/s] 36%|███▌      | 41/115 [00:06<00:02, 24.75it/s] 38%|███▊      | 44/115 [00:06<00:02, 25.63it/s] 42%|████▏     | 48/115 [00:06<00:02, 26.61it/s] 44%|████▍     | 51/115 [00:06<00:02, 27.41it/s] 47%|████▋     | 54/115 [00:06<00:02, 27.41it/s] 50%|████▉     | 57/115 [00:06<00:02, 27.61it/s] 52%|█████▏    | 60/115 [00:06<00:02, 27.26it/s] 55%|█████▍    | 63/115 [00:06<00:01, 27.38it/s] 57%|█████▋    | 66/115 [00:07<00:01, 27.59it/s] 60%|██████    | 69/115 [00:07<00:01, 26.41it/s] 63%|██████▎   | 72/115 [00:07<00:01, 24.94it/s] 65%|██████▌   | 75/115 [00:07<00:01, 24.71it/s] 68%|██████▊   | 78/115 [00:07<00:01, 26.00it/s] 71%|███████▏  | 82/115 [00:07<00:01, 27.15it/s] 74%|███████▍  | 85/115 [00:07<00:01, 27.26it/s] 77%|███████▋  | 88/115 [00:07<00:00, 27.25it/s] 79%|███████▉  | 91/115 [00:08<00:00, 27.65it/s] 82%|████████▏ | 94/115 [00:08<00:00, 27.51it/s] 84%|████████▍ | 97/115 [00:08<00:00, 28.15it/s] 88%|████████▊ | 101/115 [00:08<00:00, 29.27it/s] 91%|█████████▏| 105/115 [00:08<00:00, 31.00it/s] 95%|█████████▍| 109/115 [00:08<00:00, 32.09it/s] 98%|█████████▊| 113/115 [00:08<00:00, 32.70it/s]100%|██████████| 115/115 [00:09<00:00, 12.47it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<07:00,  3.69s/it]  3%|▎         | 3/115 [00:03<01:53,  1.02s/it]  5%|▌         | 6/115 [00:03<00:45,  2.41it/s]  8%|▊         | 9/115 [00:04<00:25,  4.15it/s] 10%|█         | 12/115 [00:04<00:16,  6.34it/s] 13%|█▎        | 15/115 [00:04<00:11,  8.62it/s] 17%|█▋        | 19/115 [00:04<00:07, 12.30it/s] 20%|██        | 23/115 [00:04<00:05, 15.72it/s] 23%|██▎       | 26/115 [00:04<00:05, 17.79it/s] 25%|██▌       | 29/115 [00:04<00:04, 19.99it/s] 28%|██▊       | 32/115 [00:04<00:04, 20.64it/s] 31%|███▏      | 36/115 [00:05<00:03, 22.61it/s] 35%|███▍      | 40/115 [00:05<00:03, 24.83it/s] 38%|███▊      | 44/115 [00:05<00:02, 27.14it/s] 42%|████▏     | 48/115 [00:05<00:02, 28.41it/s] 45%|████▌     | 52/115 [00:05<00:02, 29.27it/s] 49%|████▊     | 56/115 [00:05<00:01, 30.25it/s] 52%|█████▏    | 60/115 [00:05<00:01, 30.41it/s] 56%|█████▌    | 64/115 [00:05<00:01, 30.85it/s] 59%|█████▉    | 68/115 [00:06<00:01, 27.61it/s] 62%|██████▏   | 71/115 [00:06<00:01, 25.58it/s] 65%|██████▌   | 75/115 [00:06<00:01, 27.17it/s] 69%|██████▊   | 79/115 [00:06<00:01, 28.35it/s] 72%|███████▏  | 83/115 [00:06<00:01, 29.46it/s] 75%|███████▍  | 86/115 [00:06<00:01, 28.29it/s] 78%|███████▊  | 90/115 [00:06<00:00, 30.01it/s] 82%|████████▏ | 94/115 [00:07<00:00, 31.44it/s] 85%|████████▌ | 98/115 [00:07<00:00, 32.63it/s] 89%|████████▊ | 102/115 [00:07<00:00, 33.47it/s] 92%|█████████▏| 106/115 [00:07<00:00, 34.08it/s] 96%|█████████▌| 110/115 [00:07<00:00, 34.51it/s] 99%|█████████▉| 114/115 [00:07<00:00, 34.86it/s]100%|██████████| 115/115 [00:08<00:00, 14.17it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6667775511741638


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 63.205233033524124
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.12866007929836
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 51.65937799521383


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.6777572631836
=========================          END          =========================
0it [00:00, ?it/s]1it [00:04,  4.37s/it]2it [00:09,  4.83s/it]3it [00:14,  4.84s/it]4it [00:19,  4.97s/it]5it [00:24,  5.00s/it]6it [00:29,  5.01s/it]7it [00:34,  4.92s/it]8it [00:39,  4.94s/it]9it [00:44,  5.01s/it]10it [00:49,  5.05s/it]11it [00:54,  4.96s/it]12it [00:59,  4.92s/it]13it [01:04,  4.91s/it]14it [01:09,  5.03s/it]15it [01:14,  4.97s/it]16it [01:19,  4.98s/it]17it [01:24,  5.07s/it]18it [01:29,  4.91s/it]19it [01:33,  4.89s/it]20it [01:39,  5.11s/it]21it [01:44,  5.00s/it]22it [01:49,  4.98s/it]23it [01:54,  5.03s/it]24it [01:59,  5.04s/it]25it [02:04,  5.09s/it]26it [02:09,  5.11s/it]27it [02:15,  5.14s/it]28it [02:20,  5.17s/it]29it [02:25,  5.14s/it]30it [02:29,  4.96s/it]31it [02:34,  4.95s/it]32it [02:39,  4.82s/it]33it [02:44,  4.87s/it]34it [02:49,  4.88s/it]35it [02:54,  4.89s/it]36it [02:58,  4.71s/it]37it [03:02,  4.63s/it]38it [03:07,  4.56s/it]39it [03:11,  4.54s/it]40it [03:16,  4.57s/it]41it [03:21,  4.68s/it]42it [03:25,  4.53s/it]43it [03:29,  4.42s/it]44it [03:34,  4.45s/it]45it [03:39,  4.62s/it]46it [03:44,  4.75s/it]47it [03:49,  4.99s/it]48it [03:54,  4.98s/it]49it [03:59,  4.98s/it]50it [04:04,  4.86s/it]51it [04:09,  4.87s/it]52it [04:14,  5.05s/it]53it [04:20,  5.22s/it]54it [04:26,  5.38s/it]55it [04:30,  5.23s/it]56it [04:36,  5.31s/it]57it [04:41,  5.25s/it]58it [04:46,  5.29s/it]59it [04:51,  5.14s/it]60it [04:56,  5.11s/it]61it [05:01,  4.97s/it]62it [05:06,  4.90s/it]63it [05:11,  5.13s/it]64it [05:16,  5.09s/it]65it [05:22,  5.26s/it]66it [05:27,  5.33s/it]67it [05:33,  5.28s/it]68it [05:38,  5.26s/it]69it [05:43,  5.17s/it]70it [05:48,  5.22s/it]71it [05:54,  5.32s/it]72it [05:59,  5.32s/it]73it [06:04,  5.30s/it]74it [06:10,  5.31s/it]75it [06:13,  4.86s/it]76it [06:17,  4.58s/it]77it [06:21,  4.41s/it]78it [06:26,  4.48s/it]79it [06:30,  4.44s/it]80it [06:34,  4.25s/it]81it [06:38,  4.15s/it]82it [06:42,  4.21s/it]83it [06:47,  4.38s/it]84it [06:52,  4.38s/it]85it [06:55,  4.17s/it]86it [06:59,  4.04s/it]87it [07:03,  4.09s/it]88it [07:09,  4.54s/it]89it [07:14,  4.83s/it]90it [07:20,  5.05s/it]91it [07:25,  5.15s/it]92it [07:31,  5.20s/it]93it [07:36,  5.24s/it]94it [07:41,  5.18s/it]95it [07:46,  5.09s/it]96it [07:51,  5.14s/it]97it [07:56,  5.22s/it]98it [08:01,  5.12s/it]99it [08:07,  5.17s/it]100it [08:11,  4.96s/it]101it [08:16,  4.91s/it]102it [08:21,  5.00s/it]103it [08:26,  5.04s/it]104it [08:32,  5.11s/it]105it [08:37,  5.21s/it]106it [08:42,  5.24s/it]107it [08:48,  5.26s/it]108it [08:52,  5.16s/it]109it [08:58,  5.14s/it]110it [09:02,  5.07s/it]111it [09:08,  5.13s/it]112it [09:13,  5.03s/it]113it [09:18,  5.02s/it]114it [09:23,  5.06s/it]115it [09:28,  5.14s/it]115it [09:28,  4.94s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<06:23,  3.36s/it]  3%|▎         | 4/115 [00:03<01:13,  1.51it/s]  7%|▋         | 8/115 [00:03<00:30,  3.54it/s] 10%|▉         | 11/115 [00:03<00:19,  5.34it/s] 12%|█▏        | 14/115 [00:03<00:13,  7.54it/s] 15%|█▍        | 17/115 [00:03<00:09,  9.83it/s] 18%|█▊        | 21/115 [00:04<00:06, 13.61it/s] 21%|██        | 24/115 [00:04<00:05, 15.48it/s] 24%|██▍       | 28/115 [00:04<00:04, 18.43it/s] 27%|██▋       | 31/115 [00:04<00:04, 20.63it/s] 30%|██▉       | 34/115 [00:04<00:03, 21.83it/s] 32%|███▏      | 37/115 [00:04<00:03, 23.54it/s] 35%|███▍      | 40/115 [00:04<00:03, 22.08it/s] 38%|███▊      | 44/115 [00:04<00:03, 23.47it/s] 42%|████▏     | 48/115 [00:05<00:02, 26.04it/s] 44%|████▍     | 51/115 [00:05<00:02, 26.38it/s] 47%|████▋     | 54/115 [00:05<00:02, 27.04it/s] 50%|█████     | 58/115 [00:05<00:02, 28.42it/s] 54%|█████▍    | 62/115 [00:05<00:01, 28.57it/s] 57%|█████▋    | 65/115 [00:05<00:01, 26.87it/s] 60%|██████    | 69/115 [00:05<00:01, 28.48it/s] 63%|██████▎   | 72/115 [00:05<00:01, 27.61it/s] 65%|██████▌   | 75/115 [00:06<00:01, 24.20it/s] 68%|██████▊   | 78/115 [00:06<00:01, 21.74it/s] 70%|███████   | 81/115 [00:06<00:01, 21.68it/s] 74%|███████▍  | 85/115 [00:06<00:01, 24.68it/s] 77%|███████▋  | 88/115 [00:06<00:01, 25.39it/s] 80%|████████  | 92/115 [00:06<00:00, 27.46it/s] 83%|████████▎ | 96/115 [00:06<00:00, 28.87it/s] 87%|████████▋ | 100/115 [00:07<00:00, 30.07it/s] 90%|█████████ | 104/115 [00:07<00:00, 30.96it/s] 94%|█████████▍| 108/115 [00:07<00:00, 32.16it/s] 97%|█████████▋| 112/115 [00:07<00:00, 31.12it/s]100%|██████████| 115/115 [00:07<00:00, 14.45it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691125869751
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<07:33,  3.98s/it]  2%|▏         | 2/115 [00:04<03:12,  1.71s/it]  3%|▎         | 3/115 [00:04<01:51,  1.01it/s]  6%|▌         | 7/115 [00:04<00:32,  3.37it/s]  9%|▊         | 10/115 [00:04<00:19,  5.48it/s] 11%|█▏        | 13/115 [00:04<00:13,  7.82it/s] 15%|█▍        | 17/115 [00:04<00:08, 11.51it/s] 17%|█▋        | 20/115 [00:04<00:06, 14.24it/s] 21%|██        | 24/115 [00:04<00:05, 17.97it/s] 24%|██▍       | 28/115 [00:05<00:04, 21.19it/s] 28%|██▊       | 32/115 [00:05<00:03, 23.99it/s] 31%|███▏      | 36/115 [00:05<00:03, 25.18it/s] 34%|███▍      | 39/115 [00:05<00:03, 25.21it/s] 37%|███▋      | 43/115 [00:05<00:02, 27.36it/s] 41%|████      | 47/115 [00:05<00:02, 29.33it/s] 44%|████▍     | 51/115 [00:05<00:02, 28.32it/s] 47%|████▋     | 54/115 [00:05<00:02, 27.45it/s] 50%|████▉     | 57/115 [00:06<00:02, 26.98it/s] 52%|█████▏    | 60/115 [00:06<00:01, 27.69it/s] 55%|█████▍    | 63/115 [00:06<00:01, 26.65it/s] 57%|█████▋    | 66/115 [00:06<00:02, 22.63it/s] 60%|██████    | 69/115 [00:06<00:01, 23.73it/s] 63%|██████▎   | 72/115 [00:06<00:01, 22.46it/s] 65%|██████▌   | 75/115 [00:06<00:02, 19.73it/s] 68%|██████▊   | 78/115 [00:07<00:01, 20.96it/s] 70%|███████   | 81/115 [00:07<00:01, 22.55it/s] 73%|███████▎  | 84/115 [00:07<00:01, 22.24it/s] 76%|███████▌  | 87/115 [00:07<00:01, 23.45it/s] 78%|███████▊  | 90/115 [00:07<00:01, 24.84it/s] 81%|████████  | 93/115 [00:07<00:00, 25.77it/s] 84%|████████▍ | 97/115 [00:07<00:00, 28.58it/s] 88%|████████▊ | 101/115 [00:07<00:00, 30.51it/s] 91%|█████████▏| 105/115 [00:07<00:00, 31.84it/s] 95%|█████████▍| 109/115 [00:08<00:00, 26.33it/s] 98%|█████████▊| 113/115 [00:08<00:00, 28.50it/s]100%|██████████| 115/115 [00:08<00:00, 13.01it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6668980717658997


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77690887451172
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 63.123466884709735
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.23913873757706
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 51.587649597291495


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.68980407714844
=========================          END          =========================
0it [00:00, ?it/s]1it [00:03,  3.71s/it]2it [00:07,  3.70s/it]3it [00:11,  3.90s/it]4it [00:15,  4.00s/it]5it [00:19,  4.00s/it]6it [00:23,  4.01s/it]7it [00:28,  4.11s/it]8it [00:32,  4.24s/it]9it [00:36,  4.26s/it]10it [00:41,  4.43s/it]11it [00:46,  4.62s/it]12it [00:51,  4.66s/it]13it [00:55,  4.55s/it]14it [00:59,  4.35s/it]15it [01:03,  4.29s/it]16it [01:08,  4.44s/it]17it [01:13,  4.51s/it]18it [01:17,  4.39s/it]19it [01:21,  4.39s/it]20it [01:26,  4.35s/it]21it [01:29,  4.18s/it]22it [01:34,  4.30s/it]23it [01:39,  4.42s/it]24it [01:43,  4.45s/it]25it [01:47,  4.40s/it]26it [01:51,  4.27s/it]27it [01:56,  4.41s/it]28it [02:01,  4.50s/it]29it [02:06,  4.66s/it]30it [02:11,  4.75s/it]31it [02:15,  4.71s/it]32it [02:20,  4.76s/it]33it [02:25,  4.78s/it]34it [02:30,  4.75s/it]35it [02:35,  4.79s/it]36it [02:40,  4.81s/it]37it [02:45,  4.90s/it]38it [02:50,  4.92s/it]39it [02:55,  5.03s/it]40it [03:00,  5.06s/it]41it [03:04,  4.87s/it]42it [03:10,  4.95s/it]43it [03:15,  5.01s/it]44it [03:20,  4.95s/it]45it [03:24,  4.95s/it]46it [03:30,  4.99s/it]47it [03:34,  4.88s/it]48it [03:40,  5.01s/it]49it [03:44,  4.96s/it]50it [03:49,  4.90s/it]51it [03:54,  5.00s/it]52it [04:00,  5.10s/it]53it [04:05,  5.08s/it]54it [04:10,  5.13s/it]55it [04:15,  5.10s/it]56it [04:20,  4.98s/it]57it [04:24,  4.85s/it]58it [04:29,  4.87s/it]59it [04:34,  4.98s/it]60it [04:39,  4.99s/it]61it [04:44,  4.92s/it]62it [04:49,  4.96s/it]63it [04:54,  4.99s/it]64it [04:59,  4.90s/it]65it [05:03,  4.74s/it]66it [05:08,  4.63s/it]67it [05:12,  4.44s/it]68it [05:16,  4.31s/it]69it [05:20,  4.36s/it]70it [05:24,  4.25s/it]71it [05:29,  4.38s/it]72it [05:33,  4.30s/it]73it [05:38,  4.38s/it]74it [05:42,  4.38s/it]75it [05:46,  4.30s/it]76it [05:49,  4.01s/it]77it [05:52,  3.66s/it]78it [05:55,  3.46s/it]79it [05:58,  3.33s/it]80it [06:01,  3.25s/it]81it [06:05,  3.29s/it]82it [06:08,  3.18s/it]83it [06:11,  3.11s/it]84it [06:13,  2.95s/it]85it [06:16,  2.93s/it]86it [06:19,  2.79s/it]87it [06:21,  2.72s/it]88it [06:24,  2.73s/it]89it [06:27,  2.85s/it]90it [06:30,  2.84s/it]91it [06:33,  2.93s/it]92it [06:36,  2.88s/it]93it [06:39,  2.90s/it]94it [06:41,  2.87s/it]95it [06:44,  2.77s/it]96it [06:47,  2.79s/it]97it [06:50,  2.78s/it]98it [06:52,  2.66s/it]99it [06:55,  2.75s/it]100it [06:58,  2.82s/it]101it [07:01,  3.03s/it]102it [07:05,  3.12s/it]103it [07:08,  3.16s/it]104it [07:10,  2.97s/it]105it [07:13,  2.88s/it]106it [07:16,  2.78s/it]107it [07:18,  2.50s/it]108it [07:20,  2.53s/it]109it [07:23,  2.61s/it]110it [07:26,  2.69s/it]111it [07:29,  2.72s/it]112it [07:31,  2.63s/it]113it [07:34,  2.81s/it]114it [07:38,  3.02s/it]115it [07:42,  3.24s/it]115it [07:42,  4.02s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<07:34,  3.99s/it]  3%|▎         | 4/115 [00:04<01:27,  1.27it/s]  6%|▌         | 7/115 [00:04<00:42,  2.52it/s]  9%|▊         | 10/115 [00:04<00:25,  4.15it/s] 11%|█▏        | 13/115 [00:04<00:16,  6.15it/s] 14%|█▍        | 16/115 [00:04<00:11,  8.44it/s] 17%|█▋        | 19/115 [00:04<00:08, 11.01it/s] 20%|██        | 23/115 [00:04<00:06, 14.80it/s] 23%|██▎       | 27/115 [00:04<00:04, 18.31it/s] 26%|██▌       | 30/115 [00:05<00:04, 20.41it/s] 29%|██▊       | 33/115 [00:05<00:03, 22.16it/s] 32%|███▏      | 37/115 [00:05<00:03, 24.23it/s] 35%|███▍      | 40/115 [00:05<00:03, 23.68it/s] 38%|███▊      | 44/115 [00:05<00:02, 25.69it/s] 41%|████      | 47/115 [00:05<00:02, 25.65it/s] 44%|████▍     | 51/115 [00:05<00:02, 27.62it/s] 48%|████▊     | 55/115 [00:05<00:02, 28.70it/s] 51%|█████▏    | 59/115 [00:06<00:01, 30.07it/s] 55%|█████▍    | 63/115 [00:06<00:01, 29.03it/s] 57%|█████▋    | 66/115 [00:06<00:01, 28.77it/s] 61%|██████    | 70/115 [00:06<00:01, 29.60it/s] 63%|██████▎   | 73/115 [00:06<00:01, 28.42it/s] 66%|██████▌   | 76/115 [00:06<00:01, 25.74it/s] 70%|██████▉   | 80/115 [00:06<00:01, 26.54it/s] 73%|███████▎  | 84/115 [00:06<00:01, 27.89it/s] 77%|███████▋  | 88/115 [00:07<00:00, 28.61it/s] 80%|████████  | 92/115 [00:07<00:00, 29.26it/s] 83%|████████▎ | 96/115 [00:07<00:00, 30.23it/s] 87%|████████▋ | 100/115 [00:07<00:00, 31.47it/s] 90%|█████████ | 104/115 [00:07<00:00, 32.07it/s] 94%|█████████▍| 108/115 [00:07<00:00, 32.04it/s] 97%|█████████▋| 112/115 [00:07<00:00, 32.17it/s]100%|██████████| 115/115 [00:08<00:00, 13.86it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<06:59,  3.68s/it]  2%|▏         | 2/115 [00:03<03:08,  1.67s/it]  4%|▍         | 5/115 [00:04<00:55,  1.98it/s]  7%|▋         | 8/115 [00:04<00:29,  3.64it/s] 10%|▉         | 11/115 [00:04<00:18,  5.75it/s] 12%|█▏        | 14/115 [00:04<00:12,  7.85it/s] 15%|█▍        | 17/115 [00:04<00:09, 10.20it/s] 17%|█▋        | 20/115 [00:04<00:07, 13.01it/s] 20%|██        | 23/115 [00:04<00:05, 15.61it/s] 23%|██▎       | 26/115 [00:04<00:05, 17.56it/s] 25%|██▌       | 29/115 [00:05<00:04, 17.55it/s] 29%|██▊       | 33/115 [00:05<00:04, 20.31it/s] 31%|███▏      | 36/115 [00:05<00:03, 21.01it/s] 34%|███▍      | 39/115 [00:05<00:03, 21.79it/s] 37%|███▋      | 42/115 [00:05<00:03, 23.43it/s] 40%|████      | 46/115 [00:05<00:02, 25.03it/s] 43%|████▎     | 49/115 [00:05<00:02, 26.05it/s] 45%|████▌     | 52/115 [00:05<00:02, 27.00it/s] 48%|████▊     | 55/115 [00:06<00:02, 27.03it/s] 50%|█████     | 58/115 [00:06<00:02, 27.37it/s] 53%|█████▎    | 61/115 [00:06<00:02, 26.92it/s] 56%|█████▌    | 64/115 [00:06<00:01, 27.16it/s] 58%|█████▊    | 67/115 [00:06<00:01, 27.26it/s] 61%|██████    | 70/115 [00:06<00:01, 27.76it/s] 63%|██████▎   | 73/115 [00:06<00:01, 26.99it/s] 67%|██████▋   | 77/115 [00:06<00:01, 27.96it/s] 70%|██████▉   | 80/115 [00:06<00:01, 28.00it/s] 72%|███████▏  | 83/115 [00:07<00:01, 27.69it/s] 75%|███████▍  | 86/115 [00:07<00:01, 27.69it/s] 78%|███████▊  | 90/115 [00:07<00:00, 28.55it/s] 82%|████████▏ | 94/115 [00:07<00:00, 30.05it/s] 85%|████████▌ | 98/115 [00:07<00:00, 31.46it/s] 89%|████████▊ | 102/115 [00:07<00:00, 32.27it/s] 92%|█████████▏| 106/115 [00:07<00:00, 32.03it/s] 96%|█████████▌| 110/115 [00:07<00:00, 32.96it/s] 99%|█████████▉| 114/115 [00:08<00:00, 33.56it/s]100%|██████████| 115/115 [00:08<00:00, 13.27it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6658706665039062


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 63.75034069228672
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.6252505231478
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 52.5232759309747


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.58706665039062
=========================          END          =========================
0it [00:00, ?it/s]1it [00:03,  3.64s/it]2it [00:07,  3.53s/it]3it [00:10,  3.48s/it]4it [00:13,  3.44s/it]5it [00:16,  3.28s/it]6it [00:20,  3.45s/it]7it [00:24,  3.66s/it]8it [00:28,  3.78s/it]9it [00:32,  3.87s/it]10it [00:36,  3.94s/it]11it [00:40,  3.88s/it]12it [00:44,  3.75s/it]13it [00:48,  3.85s/it]14it [00:52,  3.83s/it]15it [00:55,  3.86s/it]16it [00:59,  3.87s/it]17it [01:03,  3.88s/it]18it [01:06,  3.68s/it]19it [01:09,  3.40s/it]20it [01:12,  3.28s/it]21it [01:15,  3.09s/it]22it [01:18,  2.99s/it]23it [01:21,  3.20s/it]24it [01:24,  3.19s/it]25it [01:28,  3.19s/it]26it [01:31,  3.34s/it]27it [01:34,  3.27s/it]28it [01:38,  3.32s/it]29it [01:41,  3.38s/it]30it [01:46,  3.61s/it]31it [01:49,  3.59s/it]32it [01:53,  3.60s/it]33it [01:56,  3.46s/it]34it [01:59,  3.25s/it]35it [02:01,  2.95s/it]36it [02:04,  2.88s/it]37it [02:06,  2.82s/it]38it [02:09,  2.71s/it]39it [02:11,  2.71s/it]40it [02:14,  2.69s/it]41it [02:17,  2.67s/it]42it [02:19,  2.49s/it]43it [02:21,  2.44s/it]44it [02:24,  2.54s/it]45it [02:26,  2.56s/it]46it [02:29,  2.61s/it]47it [02:32,  2.72s/it]48it [02:35,  2.64s/it]49it [02:37,  2.63s/it]50it [02:40,  2.73s/it]51it [02:43,  2.68s/it]52it [02:45,  2.67s/it]53it [02:48,  2.60s/it]54it [02:50,  2.62s/it]55it [02:53,  2.67s/it]56it [02:56,  2.67s/it]57it [02:59,  2.68s/it]58it [03:01,  2.61s/it]59it [03:04,  2.72s/it]60it [03:07,  2.72s/it]61it [03:10,  2.78s/it]62it [03:13,  2.80s/it]63it [03:15,  2.77s/it]64it [03:18,  2.79s/it]65it [03:21,  2.80s/it]66it [03:24,  2.80s/it]67it [03:27,  2.86s/it]68it [03:29,  2.82s/it]69it [03:32,  2.78s/it]70it [03:35,  2.77s/it]71it [03:38,  2.86s/it]72it [03:40,  2.66s/it]73it [03:42,  2.48s/it]74it [03:45,  2.47s/it]75it [03:47,  2.47s/it]76it [03:49,  2.37s/it]77it [03:52,  2.35s/it]78it [03:54,  2.26s/it]79it [03:56,  2.37s/it]80it [03:59,  2.41s/it]81it [04:02,  2.53s/it]82it [04:04,  2.40s/it]83it [04:06,  2.41s/it]84it [04:09,  2.42s/it]85it [04:11,  2.38s/it]86it [04:13,  2.39s/it]87it [04:16,  2.36s/it]88it [04:18,  2.42s/it]89it [04:21,  2.51s/it]90it [04:23,  2.36s/it]91it [04:25,  2.34s/it]92it [04:28,  2.53s/it]93it [04:30,  2.40s/it]94it [04:32,  2.24s/it]95it [04:34,  2.11s/it]96it [04:36,  2.06s/it]97it [04:38,  2.06s/it]98it [04:40,  2.02s/it]99it [04:42,  1.98s/it]100it [04:43,  1.86s/it]101it [04:44,  1.65s/it]102it [04:46,  1.72s/it]103it [04:48,  1.63s/it]104it [04:49,  1.55s/it]105it [04:51,  1.55s/it]106it [04:51,  1.16s/it]107it [04:52,  1.12s/it]108it [04:53,  1.11s/it]109it [04:54,  1.10s/it]110it [04:56,  1.26s/it]111it [04:57,  1.33s/it]112it [04:59,  1.41s/it]113it [05:01,  1.53s/it]114it [05:02,  1.54s/it]115it [05:04,  1.55s/it]115it [05:04,  2.65s/it]
Number of selected candidates = 42
---> Each Classifier' shapes
	 GT_classifier = 37
	 ViLang_guessed = 42
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:03<05:52,  3.09s/it]  2%|▏         | 2/115 [00:03<02:33,  1.36s/it]  5%|▌         | 6/115 [00:03<00:36,  2.97it/s]  8%|▊         | 9/115 [00:03<00:21,  5.00it/s] 11%|█▏        | 13/115 [00:03<00:12,  8.25it/s] 15%|█▍        | 17/115 [00:03<00:08, 11.70it/s] 18%|█▊        | 21/115 [00:03<00:06, 15.42it/s] 22%|██▏       | 25/115 [00:03<00:04, 18.83it/s] 25%|██▌       | 29/115 [00:04<00:03, 21.94it/s] 29%|██▊       | 33/115 [00:04<00:03, 24.50it/s] 32%|███▏      | 37/115 [00:04<00:05, 14.84it/s] 36%|███▌      | 41/115 [00:04<00:04, 17.91it/s] 38%|███▊      | 44/115 [00:06<00:12,  5.92it/s] 42%|████▏     | 48/115 [00:06<00:08,  8.05it/s] 45%|████▌     | 52/115 [00:06<00:05, 10.59it/s] 49%|████▊     | 56/115 [00:06<00:04, 13.51it/s] 52%|█████▏    | 60/115 [00:06<00:03, 16.46it/s] 56%|█████▌    | 64/115 [00:06<00:02, 19.35it/s] 59%|█████▉    | 68/115 [00:07<00:02, 22.13it/s] 63%|██████▎   | 72/115 [00:07<00:01, 24.07it/s] 66%|██████▌   | 76/115 [00:07<00:01, 26.15it/s] 70%|██████▉   | 80/115 [00:07<00:01, 27.69it/s] 73%|███████▎  | 84/115 [00:07<00:01, 28.31it/s] 77%|███████▋  | 88/115 [00:07<00:00, 29.22it/s] 80%|████████  | 92/115 [00:07<00:00, 29.08it/s] 83%|████████▎ | 96/115 [00:07<00:00, 30.00it/s] 87%|████████▋ | 100/115 [00:08<00:00, 27.82it/s] 90%|█████████ | 104/115 [00:08<00:00, 29.75it/s] 94%|█████████▍| 108/115 [00:08<00:00, 31.26it/s] 97%|█████████▋| 112/115 [00:08<00:00, 19.85it/s]100%|██████████| 115/115 [00:09<00:00, 12.68it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.8777691721916199
---> Evaluating
  0%|          | 0/115 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  1%|          | 1/115 [00:02<05:19,  2.80s/it]  3%|▎         | 4/115 [00:02<01:01,  1.80it/s]  7%|▋         | 8/115 [00:03<00:25,  4.21it/s] 10%|█         | 12/115 [00:03<00:14,  7.06it/s] 14%|█▍        | 16/115 [00:03<00:09, 10.20it/s] 17%|█▋        | 19/115 [00:03<00:07, 12.70it/s] 20%|██        | 23/115 [00:03<00:05, 16.49it/s] 23%|██▎       | 27/115 [00:03<00:04, 20.05it/s] 27%|██▋       | 31/115 [00:03<00:03, 22.93it/s] 30%|███       | 35/115 [00:03<00:03, 25.06it/s] 34%|███▍      | 39/115 [00:03<00:02, 26.81it/s] 37%|███▋      | 43/115 [00:04<00:02, 28.31it/s] 41%|████      | 47/115 [00:04<00:02, 28.60it/s] 44%|████▍     | 51/115 [00:04<00:02, 29.94it/s] 48%|████▊     | 55/115 [00:04<00:01, 30.49it/s] 51%|█████▏    | 59/115 [00:04<00:01, 29.61it/s] 55%|█████▍    | 63/115 [00:04<00:01, 29.59it/s] 58%|█████▊    | 67/115 [00:04<00:01, 29.40it/s] 62%|██████▏   | 71/115 [00:05<00:01, 29.68it/s] 65%|██████▌   | 75/115 [00:05<00:01, 29.71it/s] 68%|██████▊   | 78/115 [00:05<00:01, 28.55it/s] 71%|███████▏  | 82/115 [00:05<00:01, 30.08it/s] 75%|███████▍  | 86/115 [00:05<00:00, 31.39it/s] 78%|███████▊  | 90/115 [00:05<00:00, 31.04it/s] 82%|████████▏ | 94/115 [00:05<00:00, 32.18it/s] 85%|████████▌ | 98/115 [00:05<00:00, 33.07it/s] 89%|████████▊ | 102/115 [00:06<00:00, 32.99it/s] 92%|█████████▏| 106/115 [00:06<00:00, 33.64it/s] 96%|█████████▌| 110/115 [00:06<00:00, 33.43it/s] 99%|█████████▉| 114/115 [00:06<00:00, 33.68it/s]100%|██████████| 115/115 [00:06<00:00, 17.45it/s]
Loading all-mpnet-base-v2...
Encoding...
pred_feats.shape torch.Size([3669, 768])
gt_feats.shape torch.Size([3669, 768])
Semantic similarity score = 0.6652992963790894


========================= UPPERBOUND: CLIP ZERO-SHOT-based Final Results =========================


[Clustering]
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Acc: 81.62987189970019
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Nmi: 86.627985136889
Total UPPERBOUND: CLIP ZERO-SHOT-based Clustering Ari: 71.87957232634696


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 87.77691650390625
=========================          END          =========================


========================= OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Final Results =========================


[Clustering]
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Acc: 62.85091305532843
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Nmi: 77.05841115570368
Total OURS: VILANGGUESSED W/ ALPHA=0.7, N_TTA=10-based Clustering Ari: 51.16643669497767


[ssACC (semantic similarity ACC]
ssACC_sbert_base: 66.5299301147461
=========================          END          =========================


========================= ViLang Final Results of 10 runs, w/ random imgs per class=========================


[Clustering]
Clustering ACC: 63.70400654129191
Semantic ACC:   66.8340072631836
=========================          END          =========================
